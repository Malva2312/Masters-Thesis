
@article{li_comparison_2022,
	title = {Comparison of Traditional Radiomics, Deep Learning Radiomics and Fusion Methods for Axillary Lymph Node Metastasis Prediction in Breast Cancer},
	volume = {30},
	issn = {1878-4046},
	url = {http://dx.doi.org/10.1016/j.acra.2022.10.015},
	doi = {10.1016/j.acra.2022.10.015},
	abstract = {{RATIONALE} {AND} {OBJECTIVES}: Accurate identification of axillary lymph node ({ALN}) status in breast cancer patients is important for determining treatment options and avoiding axillary overtreatments. Our study aims to comprehensively compare the performance of the traditional radiomics model, deep learning radiomics model, and the fusion models in evaluating breast cancer {ALN} status based on dynamic contrast-enhanced-magnetic resonance imaging ({DCE}-{MRI}) images. {MATERIALS} {AND} {METHODS}: The handcrafted radiomics features and deep features were extracted from 3062 {DCE}-{MRI} images. The feature selection was performed by applying mutual information and feature recursive elimination algorithms. The traditional radiomics model and deep learning radiomics model were built using the optimal features and machine learning classifiers, respectively. The fusion models for distinguishing axillary lymph node status were constructed using two fusion strategies. The performance of the models with {MRI}-reported lymphadenopathy or suspicious nodes to evaluate axillary lymph node status was also compared. {RESULTS}: The decision fusion model, with the integration of the radiomics features and deep learning features at the decision level, achieved an area under the curve ({AUC}) of 0.91 (95\% confidence interval ({CI}): 0.879-0.937), which was higher than that of the traditional radiomics model and deep learning radiomics model. The results of the decision fusion model with clinical characteristic yielded an {AUC} of 0.93 (95\% {CI}: 0.899-0.951), which was also superior to other models incorporating clinical characteristic. {CONCLUSION}: This study demonstrates the effectiveness of the fusion models for predicting axillary lymph node metastasis in breast cancer.},
	pages = {1281--1287},
	number = {7},
	journaltitle = {Acad Radiol},
	author = {Li, Xue and Yang, Lifeng and Jiao, Xiong},
	date = {2022-11-11},
	langid = {english},
	note = {Place: United States},
	keywords = {Axillary lymph node metastasis, Breast cancer, Information fusion, Radiomics},
}

@article{ma_novel_2023,
	title = {A novel fusion algorithm for benign-malignant lung nodule classification on {CT} images},
	volume = {23},
	issn = {1471-2466},
	url = {https://doi.org/10.1186/s12890-023-02708-w},
	doi = {10.1186/s12890-023-02708-w},
	abstract = {The accurate recognition of malignant lung nodules on {CT} images is critical in lung cancer screening, which can offer patients the best chance of cure and significant reductions in mortality from lung cancer. Convolutional Neural Network ({CNN}) has been proven as a powerful method in medical image analysis. Radiomics which is believed to be of interest based on expert opinion can describe high-throughput extraction from {CT} images. Graph Convolutional Network explores the global context and makes the inference on both graph node features and relational structures. In this paper, we propose a novel fusion algorithm, {RGD}, for benign-malignant lung nodule classification by incorporating Radiomics study and Graph learning into the multiple Deep {CNNs} to form a more complete and distinctive feature representation, and ensemble the predictions for robust decision-making. The proposed method was conducted on the publicly available {LIDC}-{IDRI} dataset in a 10-fold cross-validation experiment and it obtained an average accuracy of 93.25\%, a sensitivity of 89.22\%, a specificity of 95.82\%, precision of 92.46\%, F1 Score of 0.9114 and {AUC} of 0.9629. Experimental results illustrate that the {RGD} model achieves superior performance compared with the state-of-the-art methods. Moreover, the effectiveness of the fusion strategy has been confirmed by extensive ablation studies. In the future, the proposed model which performs well on the pulmonary nodule classification on {CT} images will be applied to increase confidence in the clinical diagnosis of lung cancer.},
	pages = {474},
	number = {1},
	journaltitle = {{BMC} Pulmonary Medicine},
	author = {Ma, Ling and Wan, Chuangye and Hao, Kexin and Cai, Annan and Liu, Lizhi},
	date = {2023-11-28},
	keywords = {Information fusion, Computed tomography ({CT}), Deep convolutional neural network, Graph convolutional network, Lung cancer, Lung nodule classification},
	file = {PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\49NJLSJS\\Ma et al. - 2023 - A novel fusion algorithm for benign-malignant lung nodule classification on CT images.pdf:application/pdf},
}

@article{huang_fusing_2022,
	title = {Fusing hand-crafted and deep-learning features in a convolutional neural network model to identify prostate cancer in pathology images},
	volume = {12},
	issn = {2234-943X},
	url = {http://dx.doi.org/10.3389/fonc.2022.994950},
	doi = {10.3389/fonc.2022.994950},
	abstract = {Prostate cancer can be diagnosed by prostate biopsy using transectal ultrasound guidance. The high number of pathology images from biopsy tissues is a burden on pathologists, and analysis is subjective and susceptible to inter-rater variability. The use of machine learning techniques could make prostate histopathology diagnostics more precise, consistent, and efficient overall. This paper presents a new classification fusion network model that was created by fusing eight advanced image features: seven hand-crafted features and one deep-learning feature. These features are the scale-invariant feature transform ({SIFT}), speeded up robust feature ({SURF}), oriented features from accelerated segment test ({FAST}) and rotated binary robust independent elementary features ({BRIEF}) ({ORB}) of local features, shape and texture features of the cell nuclei, the histogram of oriented gradients ({HOG}) feature of the cavities, a color feature, and a convolution deep-learning feature. Matching, integrated, and fusion networks are the three essential components of the proposed deep-learning network. The integrated network consists of both a backbone and an additional network. When classifying 1100 prostate pathology images using this fusion network with different backbones ({ResNet}-18/50, {VGG}-11/16, and {DenseNet}-121/201), we discovered that the proposed model with the {ResNet}-18 backbone achieved the best performance in terms of the accuracy (95.54\%), specificity (93.64\%), and sensitivity (97.27\%) as well as the area under the receiver operating characteristic curve (98.34\%). However, each of the assessment criteria for these separate features had a value lower than 90\%, which demonstrates that the suggested model combines differently derived characteristics in an effective manner. Moreover, a Grad-{CAM}++ heatmap was used to observe the differences between the proposed model and {ResNet}-18 in terms of the regions of interest. This map showed that the proposed model was better at focusing on cancerous cells than {ResNet}-18. Hence, the proposed classification fusion network, which combines hand-crafted features and a deep-learning feature, is useful for computer-aided diagnoses based on pathology images of prostate cancer. Because of the similarities in the feature engineering and deep learning for different types of pathology images, the proposed method could be used for other pathology images, such as those of breast, thyroid cancer.},
	pages = {994950},
	journaltitle = {Front Oncol},
	author = {Huang, Xinrui and Li, Zhaotong and Zhang, Minghui and Gao, Song},
	date = {2022-09-27},
	note = {Place: Switzerland},
	keywords = {classification, convolutional neural network model, feature fusion, pathology image, prostate cancer},
}

@article{saba_lung_2019,
	title = {Lung Nodule Detection based on Ensemble of Hand Crafted and Deep Features},
	volume = {43},
	issn = {1573-689X},
	url = {https://doi.org/10.1007/s10916-019-1455-6},
	doi = {10.1007/s10916-019-1455-6},
	abstract = {Lung cancer is considered as a deadliest disease worldwide due to which 1.76 million deaths occurred in the year 2018. Keeping in view its dreadful effect on humans, cancer detection at a premature stage is a more significant requirement to reduce the probability of mortality rate. This manuscript depicts an approach of finding lung nodule at an initial stage that comprises of three major phases: (1) lung nodule segmentation using Otsu threshold followed by morphological operation; (2) extraction of geometrical, texture and deep learning features for selecting optimal features; (3) The optimal features are fused serially for classification of lung nodule into two categories that is malignant and benign. The lung image database consortium image database resource initiative ({LIDC}-{IDRI}) is used for experimentation. The experimental outcomes show better performance of presented approach as compared with the existing methods.},
	pages = {332},
	number = {12},
	journaltitle = {Journal of Medical Systems},
	author = {Saba, Tanzila and Sameh, Ahmed and Khan, Fatima and Shad, Shafqat Ali and Sharif, Muhammad},
	date = {2019-11-08},
}

@article{yang_deep_2020,
	title = {A deep metric learning approach for histopathological image retrieval},
	volume = {179},
	issn = {1046-2023},
	url = {https://www.sciencedirect.com/science/article/pii/S1046202320300815},
	doi = {https://doi.org/10.1016/j.ymeth.2020.05.015},
	abstract = {To distinguish ambiguous images during specimen slides viewing, pathologists usually spend lots of time to seek guidance from conﬁrmed similar images or cases, which is ineﬃcient. Therefore, several histopathological image retrieval methods have been proposed for pathologists to easily obtain images sharing similar content with the query images. However, these methods cannot ensure a reasonable similarity metric, and some of them need lots of annotated images to train a feature extractor to represent images. Motivated by this circumstance, we propose the ﬁrst deep metric learning-based histopathological image retrieval method in this paper and construct a deep neural network based on the mixed attention mechanism to learn an embedding function under the supervision of image category information. With the learned embedding function, original images are mapped into the predeﬁned metric space where similar images from the same category are close to each other, so that the distance between image pairs in the metric space can be regarded as a reasonable metric for image similarity. We evaluate the proposed method on two histopathological image retrieval datasets: our self-established dataset and a public dataset called Kimia Path24, on which the proposed method achieves recall in top-1 recommendation (Recall@1) of 84.04\% and 97.89\% respectively. Moreover, further experiments conﬁrm that the proposed method can achieve comparable performance to several published methods with less training data, which hedges the shortage of annotated medical image data to some extent. Code is available at https://github.com/ easonyang1996/{DML}\_HistoImgRetrieval.},
	pages = {14--25},
	journaltitle = {Methods},
	author = {Yang, Pengshuai and Zhai, Yupeng and Li, Lin and Lv, Hairong and Wang, Jigang and Zhu, Chengzhan and Jiang, Rui},
	urldate = {2025-02-04},
	date = {2020-07},
	langid = {english},
	keywords = {Content base image retrieval, Deep metric learning, Histopathological image analysis},
	file = {PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\KTT6JBJ9\\Yang et al. - 2020 - A deep metric learning approach for histopathological image retrieval.pdf:application/pdf},
}

@article{nasrullah_automated_2019,
	title = {Automated Lung Nodule Detection and Classification Using Deep Learning Combined with Multiple Strategies},
	volume = {19},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1424-8220},
	url = {https://pubmed.ncbi.nlm.nih.gov/31466261/},
	doi = {10.3390/s19173722},
	abstract = {Lung cancer is one of the major causes of cancer-related deaths due to its aggressive nature and delayed detections at advanced stages. Early detection of lung cancer is very important for the survival of an individual, and is a signiﬁcant challenging problem. Generally, chest radiographs (X-ray) and computed tomography ({CT}) scans are used initially for the diagnosis of the malignant nodules; however, the possible existence of benign nodules leads to erroneous decisions. At early stages, the benign and the malignant nodules show very close resemblance to each other. In this paper, a novel deep learning-based model with multiple strategies is proposed for the precise diagnosis of the malignant nodules. Due to the recent achievements of deep convolutional neural networks ({CNN}) in image analysis, we have used two deep three-dimensional (3D) customized mixed link network ({CMixNet}) architectures for lung nodule detection and classiﬁcation, respectively. Nodule detections were performed through faster R-{CNN} on eﬃciently-learned features from {CMixNet} and U-Net like encoder–decoder architecture. Classiﬁcation of the nodules was performed through a gradient boosting machine ({GBM}) on the learned features from the designed 3D {CMixNet} structure. To reduce false positives and misdiagnosis results due to diﬀerent types of errors, the ﬁnal decision was performed in connection with physiological symptoms and clinical biomarkers. With the advent of the internet of things ({IoT}) and electro-medical technology, wireless body area networks ({WBANs}) provide continuous monitoring of patients, which helps in diagnosis of chronic diseases—especially metastatic cancers. The deep learning model for nodules’ detection and classiﬁcation, combined with clinical factors, helps in the reduction of misdiagnosis and false positive ({FP}) results in early-stage lung cancer diagnosis. The proposed system was evaluated on {LIDC}-{IDRI} datasets in the form of sensitivity (94\%) and speciﬁcity (91\%), and better results were obatined compared to the existing methods.},
	pages = {3722},
	number = {17},
	journaltitle = {Sensors (Basel, Switzerland)},
	shortjournal = {Sensors},
	author = {Nasrullah, Nasrullah and Sang, Jun and Alam, Mohammad S. and Mateen, Muhammad and Cai, Bin and Hu, Haibo},
	urldate = {2025-02-04},
	date = {2019-08-28},
	langid = {english},
	keywords = {*Diagnosis, *Wireless Technology, Computer, Computer-Assisted, Computer-Assisted/methods, Databases, Deep Learning, Early Detection of Cancer, Factual, Humans, Image Processing, Internet of Things, Lung Neoplasms/*diagnosis/diagnostic imaging/pathology, Lung/diagnostic imaging/physiology, Neoplasms/*diagnosis/diagnostic imaging/pathology, Neural Networks, Radiographic Image Interpretation, Tomography, X-Ray Computed},
	file = {PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\L48A8M3J\\Nasrullah et al. - 2019 - Automated Lung Nodule Detection and Classification Using Deep Learning Combined with Multiple Strate.pdf:application/pdf},
}

@article{sanjeevaiah_k_content-based_2023,
	title = {Content-Based Image Retrieval Using Hybrid Densenet121-Bilstm and Harris Hawks Optimization Algorithm},
	volume = {11},
	rights = {http://creativecommons.org/licenses/by/3.0/deed.en\_US},
	issn = {2166-7160, 2166-7179},
	url = {https://services.igi-global.com/resolvedoi/resolve.aspx?doi=10.4018/IJSI.315661},
	doi = {10.4018/IJSI.315661},
	shorttitle = {Content-Based Image Retrieval Using Hybrid Densenet121-Bilstm and Harris Hawks Optimization Algorithm},
	abstract = {In the field of digital data management, content-based image retrieval ({CBIR}) has become one of the most important research areas, and it is used in many fields. This system searches a database of images to retrieve most visually comparable photos to a query image. It is based on features derived directly from the image data, rather than on keywords or annotations. Currently, deep learning approaches have demonstrated a strong interest in picture recognition, particularly in extracting information about the features of the image. Therefore, a Densenet-121 is employed in this work to extract high-level and deep characteristics from the images. Afterwards, the training images are retrieved from the dataset and compared to the query image using a Bidirectional {LSTM} ({BiLSTM}) classifier to obtain the relevant images. The investigations are conducted using a publicly available dataset named Corel, and the f-measure, recall, and precision metrics are used for performance assessment. Investigation outcomes show that the proposed technique outperforms the existing image retrieval techniques.},
	pages = {1--15},
	number = {1},
	journaltitle = {International Journal of Software Innovation},
	author = {{Sanjeevaiah K.} and Reddy, Tatireddy Subba and Karthik, Sajja and Kumar, Mahesh and {Vivek D.}},
	urldate = {2025-02-04},
	date = {2023-01},
	langid = {english},
	file = {PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\M5E65VK8\\Sanjeevaiah K. et al. - 2022 - Content-Based Image Retrieval Using Hybrid Densenet121-Bilstm and Harris Hawks Optimization Algorith.pdf:application/pdf},
}

@online{united_nations_17_2015,
	title = {{THE} 17 {GOALS} {\textbar} Sustainable Development},
	url = {https://sdgs.un.org/goals},
	author = {{United Nations}},
	urldate = {2024-10-06},
	date = {2015},
	file = {THE 17 GOALS | Sustainable Development:D\:\\Faculdade\\ZoteroStorage\\storage\\9UWG66US\\goals.html:text/html},
}

@online{world_health_organization_top_2024,
	title = {The Top 10 Causes of Death},
	url = {https://www.who.int/news-room/fact-sheets/detail/the-top-10-causes-of-death},
	author = {{World Health Organization}},
	urldate = {2024-10-03},
	date = {2024},
	langid = {english},
	file = {Snapshot:D\:\\Faculdade\\ZoteroStorage\\storage\\RH735VS5\\the-top-10-causes-of-death.html:text/html},
}

@misc{international_agency_for_research_on_cancer_trachea_2024,
	title = {Trachea, Bronchus and Lung Cancer Fact Sheet},
	url = {https://gco.iarc.who.int/media/globocan/factsheets/cancers/15-trachea-bronchus-and-lung-fact-sheet.pdf},
	author = {{International Agency for Research on Cancer}},
	date = {2024},
	file = {15-trachea-bronchus-and-lung-fact-sheet:D\:\\Faculdade\\ZoteroStorage\\storage\\KMDX733D\\15-trachea-bronchus-and-lung-fact-sheet.pdf:application/pdf;Texto Completo:D\:\\Faculdade\\ZoteroStorage\\storage\\L3SGXRK6\\Cancer - 2024 - Trachea, Bronchus and Lung Cancer Fact Sheet.pdf:application/pdf},
}

@article{wu_ai-enhanced_2024,
	title = {{AI}-Enhanced {CAD} in Low-Dose {CT}: Balancing Accuracy, Efficiency, and Overdiagnosis in Lung Cancer Screening},
	volume = {16},
	issn = {1759-7714 (Electronic)},
	url = {https://pubmed.ncbi.nlm.nih.gov/39600243/},
	doi = {10.1111/1759-7714.15499},
	pages = {e15499},
	number = {1},
	journaltitle = {Thoracic Cancer},
	author = {Wu, Yun-Ju and Wu, Fu-Zong},
	date = {2024-11},
	langid = {english},
	note = {Place: Singapore
Publisher: Department of Radiology, Kaohsiung Veterans General Hospital, Kaohsiung, Taiwan.; Department of Software Engineering and Management, National Kaohsiung Normal University, Kaohsiung, Taiwan.; Department of Radiology, Kaohsiung Veterans General Hospital, Kaohsiung, Taiwan.},
	file = {PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\FLSPL5HY\\Wu e Wu - 2025 - AI ‐Enhanced CA.pdf:application/pdf},
}

@inproceedings{munoz_3d-morphomics_2022,
	location = {Cham},
	title = {3D-Morphomics, Morphological Features on {CT} Scans for Lung Nodule Malignancy Diagnosis},
	isbn = {978-3-031-17979-2},
	url = {http://arxiv.org/abs/2207.13830},
	doi = {10.48550/arXiv.2207.13830},
	abstract = {Pathologies systematically induce morphological changes, thus providing a major but yet insufficiently quantified source of observables for diagnosis. The study develops a predictive model of the pathological states based on morphological features (3D-morphomics) on Computed Tomography ({CT}) volumes. A complete workflow for mesh extraction and simplification of an organ's surface is developed, and coupled with an automatic extraction of morphological features given by the distribution of mean curvature and mesh energy. An {XGBoost} supervised classifier is then trained and tested on the 3D-morphomics to predict the pathological states. This framework is applied to the prediction of the malignancy of lung's nodules. On a subset of {NLST} database with malignancy confirmed biopsy, using 3D-morphomics only, the classification model of lung nodules into malignant vs. benign achieves 0.964 of {AUC}. Three other sets of classical features are trained and tested, (1) clinical relevant features gives an {AUC} of 0.58, (2) 111 radiomics gives an {AUC} of 0.976, (3) radiologist ground truth ({GT}) containing the nodule size, attenuation and spiculation qualitative annotations gives an {AUC} of 0.979. We also test the Brock model and obtain an {AUC} of 0.826. Combining 3D-morphomics and radiomics features achieves state-of-the-art results with an {AUC} of 0.978 where the 3D-morphomics have some of the highest predictive powers. As a validation on a public independent cohort, models are applied to the {LIDC} dataset, the 3D-morphomics achieves an {AUC} of 0.906 and the 3D-morphomics+radiomics achieves an {AUC} of 0.958, which ranks second in the challenge among deep models. It establishes the curvature distributions as efficient features for predicting lung nodule malignancy and a new method that can be applied directly to arbitrary computer aided diagnosis task.},
	pages = {3--13},
	booktitle = {Cancer Prevention Through Early Detection},
	publisher = {Springer Nature Switzerland},
	author = {Munoz, Elias and Baudot, Pierre and Le, Van-Khoa and Voyton, Charles and Renoust, Benjamin and Francis, Danny and Groza, Vladimir and Brisset, Jean-Christophe and Geremia, Ezequiel and Iannessi, Antoine and Liu, Yan and Huet, Benoit},
	editor = {Ali, Sharib and van der Sommen, Fons and Papie\{{\textbackslash}textbackslash\}.z, Bartłomiej Władysław and van Eijnatten, Maureen and Jin, Yueming and Kolenbrander, Iris},
	date = {2022},
	langid = {english},
	note = {Section: 0},
	keywords = {Radiomics, Computational anatomy, Computed tomography, Computer aided diagnosis, Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing, Lung cancer screening, Mesh, Quantitative Biology - Quantitative Methods},
	file = {Full Text PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\BLW6G4UQ\\Munoz et al. - 2022 - 3D-Morphomics, Morphological Features on CT Scans for Lung Nodule Malignancy Diagnosis.pdf:application/pdf;PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\8I78SZ5W\\Munoz et al. - 2022 - 3D-Morphomics, Morphological Features on CT scans for lung nodule malignancy diagnosis.pdf:application/pdf;Snapshot:D\:\\Faculdade\\ZoteroStorage\\storage\\JU5LPQ25\\2207.html:text/html},
}

@misc{mathumetha_feature_2024,
	title = {Feature Extraction Methods and Deep Learning Models for Detection of Cancerous Lung Nodules at an Early Stage – Recent Trends and Challenges},
	doi = {10.2139/ssrn.4756114},
	publisher = {{SSRN}},
	author = {Mathumetha, P. and Sivakumar, R. and Chintanpalli, Ananthakrishna},
	date = {2024},
	langid = {english},
	note = {Place: Vellore, India
Publisher: Vellore Institute of Technology},
	file = {PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\X53MGWNK\\Mathumetha et al. - 2024 - Feature Extraction Methods and Deep Learning Models for Detection of Cancerous Lung Nodules at an Ea.pdf:application/pdf},
}

@article{ali_efficient_2020,
	title = {Efficient Lung Nodule Classification Using Transferable Texture Convolutional Neural Network},
	volume = {8},
	rights = {https://creativecommons.org/licenses/by/4.0/legalcode},
	url = {https://ieeexplore.ieee.org/document/9204580/},
	doi = {10.1109/ACCESS.2020.3026080},
	pages = {175859--175870},
	journaltitle = {{IEEE} Access},
	author = {Ali, Imdad and Muzammil, Muhammad and Haq, Ihsan Ul and Amir, Muhammad and Abdullah, Suheel},
	date = {2020},
	langid = {english},
	keywords = {Databases, Computed tomography, Biomedical imaging, Cancer, cancer detection, {CNN}, Com..., computer aided diagnosis, Feature extraction, image classification, {LIDC}-{IDRI}, Lung, lung nodule, {LUNGx} challenge, machine learning, Task analysis, transfer learning},
	file = {PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\FK5HU8Y5\\Ali et al. - 2020 - Efficient Lung Nodule Classification Using Transferable Texture Convolutional Neural Network.pdf:application/pdf},
}

@article{ali_deep_2021,
	title = {Deep Feature Selection and Decision Level Fusion for Lungs Nodule Classification},
	volume = {9},
	rights = {https://creativecommons.org/licenses/by/4.0/legalcode},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/9335996/},
	doi = {10.1109/ACCESS.2021.3054735},
	pages = {18962--18973},
	journaltitle = {{IEEE} Access},
	author = {Ali, Imdad and Muzammil, Muhammad and Haq, Ihsan Ul and Amir, Muhammad and Abdullah, Suheel},
	date = {2021},
	langid = {english},
	keywords = {Lung cancer, Computed tomography, computer aided diagnosis, Feature extraction, Lung, lung nodule, {LUNGx} challenge, {AdaBoostM}2, biomedical image processing, deep convolutional neural network, deep features, {DICOM}, Solid model..., Solid modeling, support vector machine, Support vector machines},
	file = {PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\TB639G37\\Ali et al. - 2021 - Deep Feature Selection and Decision Level Fusion for Lungs Nodule Classification.pdf:application/pdf},
}

@article{alksas_novel_2023,
	title = {A novel higher order appearance texture analysis to diagnose lung cancer based on a modified local ternary pattern},
	volume = {240},
	issn = {0169-2607},
	url = {https://www.sciencedirect.com/science/article/pii/S0169260723003577},
	doi = {https://doi.org/10.1016/j.cmpb.2023.107692},
	abstract = {Background and Objective Lung cancer is an important cause of death and morbidity around the world. Two of the primary computed tomography ({CT}) imaging markers that can be used to differentiate malignant and benign lung nodules are the inhomogeneity of the nodules’ texture and nodular morphology. The objective of this paper is to present a new model that can capture the inhomogeneity of the detected lung nodules as well as their morphology. Methods We modified the local ternary pattern to use three different levels (instead of two) and a new pattern identification algorithm to capture the nodule’s inhomogeneity and morphology in a more accurate and flexible way. This modification aims to address the wide Hounsfield unit value range of the detected nodules which decreases the ability of the traditional local binary/ternary pattern to accurately classify nodules’ inhomogeneity. The cut-off values defining these three levels of the novel technique are estimated empirically from the training data. Subsequently, the extracted imaging markers are fed to a hyper-tuned stacked generalization-based classification architecture to classify the nodules as malignant or benign. The proposed system was evaluated on in vivo datasets of 679 {CT} scans (364 malignant nodules and 315 benign nodules) from the benchmark Lung Image Database Consortium and Image Database Resource Initiative ({LIDC}-{IDRI}) and an external dataset of 100 {CT} scans (50 malignant and 50 benign). The performance of the classifier was quantitatively assessed using a Leave-one-out cross-validation approach and externally validated using the unseen external dataset based on sensitivity, specificity, and accuracy. Results The overall accuracy of the system is 96.17\% with 97.14\% sensitivity and 95.33\% specificity. The area under the receiver-operating characteristic curve was 0.98, which highlights the robustness of the system. Using the unseen external dataset for validating the system led to consistent results showing the generalization abilities of the proposed approach. Moreover, applying the original local binary/ternary pattern or using other classification structures achieved inferior performance when compared against the proposed approach. Conclusions These experimental results demonstrate the feasibility of the proposed model as a novel tool to assist physicians and radiologists for lung nodules’ early assessment based on the new comprehensive imaging markers.},
	pages = {107692},
	journaltitle = {Computer Methods and Programs in Biomedicine},
	author = {Alksas, Ahmed and Shaffie, Ahmed and Ghazal, Mohammed and Taher, Fatma and Khelifi, Adel and Yaghi, Maha and Soliman, Ahmed and Bogaert, Eric {VAN} and El-Baz, Ayman},
	date = {2023-10},
	langid = {english},
	keywords = {Lung cancer, {CT}, Higher order appearance, {LBP}, Modified local ternary pattern, Stacked generalization classification, Texture analysis},
	file = {Alksas2023:D\:\\Faculdade\\ZoteroStorage\\storage\\BLS5SFIF\\Alksas2023.pdf:application/pdf},
}

@misc{armato_iii_data_2015,
	title = {Data From {LIDC}-{IDRI}},
	url = {https://doi.org/10.7937/K9/TCIA.2015.LO9QL9SX},
	publisher = {The Cancer Imaging Archive},
	author = {Armato {III}, Samuel G. and {McLennan}, Geoffrey and Bidaut, Luc and {McNitt}-Gray, Michael F. and Meyer, Charles R. and Reeves, Anthony P. and Zhao, Binsheng and Aberle, Denise R. and Henschke, Claudia I. and Hoffman, Eric A. and Kazerooni, Ella A. and {MacMahon}, Heber and Van Beek, Edwin J. R. and Yankelevitz, David and Biancardi, Anna M. and Bland, Paul H. and Brown, Martha S. and Engelmann, Robert M. and Laderach, Gregory E. and Max, David and Pais, Rosalia C. and Qing, Dan P. Y. and Roberts, Richard Y. and Smith, Andrew R. and Starkey, Adam and Batra, Prashant and Caligiuri, Philip and Farooqi, Aamer and Gladish, Gregory W. and Jude, Christopher M. and Munden, Reginald F. and Petkovska, Iva and Quint, Leland E. and Schwartz, Lawrence H. and Sundaram, Balaji and Dodd, Lori E. and Fenimore, Christopher and Gur, David and Petrick, Nicholas and Freymann, John and Kirby, Justin and Hughes, Bethany and Casteele, Arnaud Van and Gupte, Sachin and Sallam, Medhat and Heath, Michael D. and Kuhn, Michael H. and Dharaiya, Ekta and Burns, Ryan and Fryd, Deborah S. and Salganicoff, Marc and Anand, Vinay and Shreter, Uri and Vastagh, Gabor and Croft, Bryan Y. and Clarke, Laurence P.},
	date = {2015},
	doi = {10.7937/K9/TCIA.2015.LO9QL9SX},
	note = {Published: Dataset},
}

@article{avola_multimodal_2022,
	title = {Multimodal Feature Fusion and Knowledge-Driven Learning via Experts Consult for Thyroid Nodule Classification},
	volume = {32},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	issn = {1051-8215, 1558-2205},
	url = {https://ieeexplore.ieee.org/document/9409170/},
	doi = {10.1109/TCSVT.2021.3074414},
	pages = {2527--2534},
	number = {5},
	journaltitle = {{IEEE} Transactions on Circuits and Systems for Video Technology},
	shortjournal = {{IEEE} Trans. Circuits Syst. Video Technol.},
	author = {Avola, Danilo and Cinque, Luigi and Fagioli, Alessio and Filetti, Sebastiano and Grani, Giorgio and Rodolà, Emanuele},
	date = {2022-05},
	langid = {english},
	keywords = {feature fusion, Task analysis, transfer learning, computer-aided diagnosis, deep learning, Discrete wavelet transforms, ensemble learning, Knowledge engineering, Medical diagnostic ima..., Medical diagnostic imaging, Neural networks, Thyroid, Thyroid nodule classification, Training},
	file = {PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\RLHZH3QS\\Avola et al. - 2022 - Multimodal Feature Fusion and Knowledge-Driven Learning via Experts Consult for Thyroid Nodule Class.pdf:application/pdf;Versão Submetida:D\:\\Faculdade\\ZoteroStorage\\storage\\55RG9KUU\\Avola et al. - 2022 - Multimodal Feature Fusion and Knowledge-Driven Learning via Experts Consult for Thyroid Nodule Class.pdf:application/pdf},
}

@article{bahmer_benefits_2011,
	title = {Benefits and Harms of {CT} Screening for Lung Cancer: A Systematic Review},
	volume = {307},
	url = {https://jamanetwork.com/journals/jama/article-abstract/1163892},
	doi = {10.1001/jama.2012.5521},
	pages = {2418--2429},
	number = {22},
	journaltitle = {{JAMA}},
	author = {Bahmer, Kirsten M. and Schoenfeld, Andrew J. and Aberle, Denise R.},
	date = {2011},
	file = {Versão Aceite:D\:\\Faculdade\\ZoteroStorage\\storage\\ZFW5THT9\\Bahmer et al. - 2011 - Benefits and Harms of CT Screening for Lung Cancer A Systematic Review.pdf:application/pdf},
}

@article{farag_feature_2017,
	title = {Feature fusion for lung nodule classification},
	volume = {12},
	issn = {1861-6410, 1861-6429},
	url = {http://link.springer.com/10.1007/s11548-017-1626-1},
	doi = {10.1007/s11548-017-1626-1},
	abstract = {{PURPOSE}: This article examines feature-based nodule description for the purpose of nodule classification in chest computed tomography scanning. {METHODS}: Three features based on (i) Gabor filter, (ii) multi-resolution local binary pattern ({LBP}) texture features and (iii) signed distance fused with {LBP} which generates a combinational shape and texture feature are utilized to provide feature descriptors of malignant and benign nodules and non-nodule regions of interest. Support vector machines ({SVMs}) and k-nearest neighbor ({kNN}) classifiers in serial and two-tier cascade frameworks are optimized and analyzed for optimal classification results of nodules. {RESULTS}: A total of 1191 nodule and non-nodule samples from the Lung Image Data Consortium database is used for analysis. Classification using {SVM} and {kNN} classifiers is examined. The classification results from the two-tier cascade {SVM} using Gabor features showed overall better results for identifying non-nodules, malignant and benign nodules with average area under the receiver operating characteristics ({AUC}-{ROC}) curves of 0.99 and average f1-score of 0.975 over the two tiers. {CONCLUSION}: In the results, higher overall {AUCs} and f1-scores were obtained for the non-nodules cases using any of the three features, showing the greatest distinguishability over nodules (benign/malignant). {SVM} and {kNN} classifiers were used for benign, malignant and non-nodule classification, where Gabor proved to be the most effective of the features for classification. The cascaded framework showed the greatest distinguishability between benign and malignant nodules.},
	pages = {1809--1818},
	number = {10},
	journaltitle = {Int J Comput Assist Radiol Surg},
	shortjournal = {Int J {CARS}},
	author = {Farag, Amal A and Ali, Asem and Elshazly, Salwa and Farag, Aly A},
	date = {2017-10},
	langid = {english},
	note = {Place: Germany},
	keywords = {Computed tomography, {LBP}, Classification, Features extraction, Gabor, Lung nodules},
	file = {PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\EVGI4784\\Farag et al. - 2017 - Feature fusion for lung nodule classification.pdf:application/pdf},
}

@article{ginneken_comparing_2010,
	title = {Comparing and combining algorithms for computer-aided detection of pulmonary nodules in computed tomography scans: The {ANODE}09 study},
	volume = {14},
	issn = {1361-8415},
	url = {https://www.sciencedirect.com/science/article/pii/S1361841510000587},
	doi = {https://doi.org/10.1016/j.media.2010.05.005},
	abstract = {Numerous publications and commercial systems are available that deal with automatic detection of pulmonary nodules in thoracic computed tomography scans, but a comparative study where many systems are applied to the same data set has not yet been performed. This paper introduces {ANODE}09 ( http://anode09.isi.uu.nl), a database of 55 scans from a lung cancer screening program and a web-based framework for objective evaluation of nodule detection algorithms. Any team can upload results to facilitate benchmarking. The performance of six algorithms for which results are available are compared; five from academic groups and one commercially available system. A method to combine the output of multiple systems is proposed. Results show a substantial performance difference between algorithms, and demonstrate that combining the output of algorithms leads to marked performance improvements.},
	pages = {707--722},
	number = {6},
	journaltitle = {Medical Image Analysis},
	author = {Ginneken, Bram van and Armato, Samuel G. and Hoop, Bartjan de and Vorst, Saskia van Amelsvoort-van de and Duindam, Thomas and Niemeijer, Meindert and Murphy, Keelin and Schilham, Arnold and Retico, Alessandra and Fantacci, Maria Evelina and Camarlinghi, Niccolò and Bagagli, Francesco and Gori, Ilaria and Hara, Takeshi and Fujita, Hiroshi and Gargano, Gianfranco and Bellotti, Roberto and Tangaro, Sabina and Bolaños, Lourdes and Carlo, Francesco De and Cerello, Piergiorgio and Cheran, Sorin Cristian and Torres, Ernesto Lopez and Prokop, Mathias},
	date = {2010},
	keywords = {Lung cancer, Computed tomography, Lung nodules, Computer-aided detection},
}

@article{gu_survey_2021,
	title = {A survey of computer-aided diagnosis of lung nodules from {CT} scans using deep learning},
	volume = {137},
	issn = {0010-4825},
	url = {https://www.sciencedirect.com/science/article/pii/S0010482521006004},
	doi = {https://doi.org/10.1016/j.compbiomed.2021.104806},
	abstract = {Lung cancer has one of the highest mortalities of all cancers. According to the National Lung Screening Trial, patients who underwent low-dose computed tomography ({CT}) scanning once a year for 3 years showed a 20\% decline in lung cancer mortality. To further improve the survival rate of lung cancer patients, computer-aided diagnosis ({CAD}) technology shows great potential. In this paper, we summarize existing {CAD} approaches applying deep learning to {CT} scan data for pre-processing, lung segmentation, false positive reduction, lung nodule detection, segmentation, classification and retrieval. Selected papers are drawn from academic journals and conferences up to November 2020. We discuss the development of deep learning, describe several important aspects of lung nodule {CAD} systems and assess the performance of the selected studies on various datasets, which include {LIDC}-{IDRI}, {LUNA}16, {LIDC}, {DSB}2017, {NLST}, {TianChi}, and {ELCAP}. Overall, in the detection studies reviewed, the sensitivity of these techniques is found to range from 61.61\% to 98.10\%, and the value of the {FPs} per scan is between 0.125 and 32. In the selected classification studies, the accuracy ranges from 75.01\% to 97.58\%. The precision of the selected retrieval studies is between 71.43\% and 87.29\%. Based on performance, deep learning based {CAD} technologies for detection and classification of pulmonary nodules achieve satisfactory results. However, there are still many challenges and limitations remaining including over-fitting, lack of interpretability and insufficient annotated data. This review helps researchers and radiologists to better understand {CAD} technology for pulmonary nodule detection, segmentation, classification and retrieval. We summarize the performance of current techniques, consider the challenges, and propose directions for future high-impact research.},
	pages = {104806},
	journaltitle = {Computers in Biology and Medicine},
	author = {Gu, Yu and Chi, Jingqian and Liu, Jiaqi and Yang, Lidong and Zhang, Baohua and Yu, Dahua and Zhao, Ying and Lu, Xiaoqi},
	date = {2021-10},
	langid = {english},
	keywords = {Lung cancer, Lung nodule classification, Computer-aided diagnosis ({CAD}) technology, {CT} images, Deep learning, Lung nodule detection},
	file = {PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\B6AM8JKM\\Gu et al. - 2021 - A survey of computer-aided diagnosis of lung nodules from CT scans using deep learning.pdf:application/pdf},
}

@article{halder_lung_2020,
	title = {Lung Nodule Detection from Feature Engineering to Deep Learning in Thoracic {CT} Images: a Comprehensive Review},
	volume = {33},
	issn = {1618-727X},
	url = {https://doi.org/10.1007/s10278-020-00320-6},
	doi = {10.1007/s10278-020-00320-6},
	abstract = {This paper presents a systematic review of the literature focused on the lung nodule detection in chest computed tomography ({CT}) images. Manual detection of lung nodules by the radiologist is a sequential and time-consuming process. The detection is subjective and depends on the radiologist’s experiences. Owing to the variation in shapes and appearances of a lung nodule, it is very difficult to identify the proper location of the nodule from a huge number of slices generated by the {CT} scanner. Small nodules ({\textless}10mm in diameter) may be missed by this manual detection process. Therefore, computer-aided diagnosis ({CAD}) system acts as a “second opinion” for the radiologists, by making final decision quickly with higher accuracy and greater confidence. The goal of this survey work is to present the current state of the artworks and their progress towards lung nodule detection to the researchers and readers in this domain. This review paper has covered the published works from 2009 to April 2018. Different nodule detection approaches are described elaborately in this work. Recently, it is observed that deep learning ({DL})-based approaches are applied extensively for nodule detection and characterization. Therefore, emphasis has been given to convolutional neural network ({CNN})-based {DL} approaches by describing different {CNN}-based networks.},
	pages = {655--677},
	number = {3},
	journaltitle = {Journal of Digital Imaging},
	shortjournal = {J Digit Imaging},
	author = {Halder, Amitava and Dey, Debangshu and Sadhu, Anup K.},
	date = {2020-06-01},
	langid = {english},
	file = {Full Text PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\53NBQW65\\Halder et al. - 2020 - Lung Nodule Detection from Feature Engineering to Deep Learning in Thoracic CT Images a Comprehensi.pdf:application/pdf;PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\SYXAG9EH\\Halder et al. - 2020 - Lung Nodule Detection from Feature Engineering to Deep Learning in Thoracic CT Images a Comprehensi.pdf:application/pdf},
}

@article{iqbal_fusion_2023,
	title = {Fusion of Textural and Visual Information for Medical Image Modality Retrieval Using Deep Learning-Based Feature Engineering},
	volume = {11},
	rights = {https://creativecommons.org/licenses/by-nc-nd/4.0/},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/10234403/},
	doi = {10.1109/ACCESS.2023.3310245},
	pages = {93238--93253},
	journaltitle = {{IEEE} Access},
	author = {Iqbal, Saeed and Qureshi, Adnan N. and Alhussein, Musaed and Choudhry, Imran Arshad and Aurangzeb, Khursheed and Khan, Tariq M.},
	date = {2023},
	langid = {english},
	keywords = {Databases, Biomedical imaging, Feature extraction, deep learning, Medical diagnostic imaging, Deep learning, convolutional neural network, Convolutional neural networks, feature engineering, Image retrieval, Medical image retrieval, Medical services, modality retrieval, textural information, visual information, Visualization},
	file = {PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\U2YYXV7C\\Iqbal et al. - 2023 - Fusion of Textural and Visual Information for Medical Image Modality Retrieval Using Deep Learning-B.pdf:application/pdf},
}

@article{kirby_lungx_2016,
	title = {{LUNGx} Challenge for computerized lung nodule classification},
	volume = {3},
	url = {https://doi.org/10.1117/1.JMI.3.4.044506},
	doi = {10.1117/1.JMI.3.4.044506},
	abstract = {The purpose of this work is to describe the {LUNGx} Challenge for the computerized classification of lung nodules on diagnostic computed tomography ({CT}) scans as benign or malignant and report the performance of participants’ computerized methods along with that of six radiologists who participated in an observer study performing the same Challenge task on the same dataset. The Challenge provided sets of calibration and testing scans, established a performance assessment process, and created an infrastructure for case dissemination and result submission. Ten groups applied their own methods to 73 lung nodules (37 benign and 36 malignant) that were selected to achieve approximate size matching between the two cohorts. Area under the receiver operating characteristic curve ({AUC}) values for these methods ranged from 0.50 to 0.68; only three methods performed statistically better than random guessing. The radiologists’ {AUC} values ranged from 0.70 to 0.85; three radiologists performed statistically better than the best-performing computer method. The {LUNGx} Challenge compared the performance of computerized methods in the task of differentiating benign from malignant lung nodules on {CT} scans, placed in the context of the performance of radiologists on the same task. The continued public availability of the Challenge cases will provide a valuable resource for the medical imaging research community.},
	pages = {044506},
	number = {4},
	journaltitle = {Journal of Medical Imaging},
	author = {Kirby, Justin S. and Armato, Samuel G. and Drukker, Karen and Li, Feng and Hadjiiski, Lubomir and Tourassi, Georgia D. and Clarke, Laurence P. and Engelmann, Roger M. and Giger, Maryellen L. and Redmond, George and Farahani, Keyvan},
	date = {2016},
	note = {Publisher: {SPIE}},
	keywords = {classification, Computed tomography, Cancer, Lung, lung nodule, computer-aided diagnosis, Algorithm development, Calibration, challenge, computed tomography, Computer aided design, Computer aided diagnosis and therapy, Diagnostics, image analysis, Medical imaging, Medical research},
}

@article{li_research_2022,
	title = {Research on lung nodule recognition algorithm based on deep feature fusion and {MKL}-{SVM}-{IPSO}},
	volume = {12},
	issn = {2045-2322},
	url = {https://doi.org/10.1038/s41598-022-22442-3},
	doi = {10.1038/s41598-022-22442-3},
	abstract = {Lung {CAD} system can provide auxiliary third-party opinions for doctors, improve the accuracy of lung nodule recognition. The selection and fusion of nodule features and the advancement of recognition algorithms are crucial improving lung {CAD} systems. Based on the {HDL} model, this paper mainly focuses on the three key algorithms of feature extraction, feature fusion and nodule recognition of lung {CAD} system. First, {CBAM} is embedded into {VGG}16 and {VGG}19, and feature extraction models {AE}-{VGG}16 and {AE}-{VGG}19 are constructed, so that the network can pay more attention to the key feature information in nodule description. Then, feature dimensionality reduction based on {PCA} and feature fusion based on {CCA} are sequentially performed on the extracted depth features to obtain low-dimensional fusion features. Finally, the fusion features are input into the proposed {MKL}-{SVM}-{IPSO} model based on the improved Particle Swarm Optimization algorithm to speed up the training speed, get the global optimal parameter group. The public dataset {LUNA}16 was selected for the experiment. The results show that the accuracy of lung nodule recognition of the proposed lung {CAD} system can reach 99.56\%, and the sensitivity and F1-score can reach 99.3\% and 0.9965, respectively, which can reduce the possibility of false detection and missed detection of nodules.},
	pages = {17403},
	number = {1},
	journaltitle = {Scientific Reports},
	shortjournal = {Sci Rep},
	author = {Li, Yang and Zheng, Hewei and Huang, Xiaoyu and Chang, Jiayue and Hou, Debiao and Lu, Huimin},
	date = {2022-10-18},
	langid = {english},
	file = {Full Text PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\3TMBTGMC\\Li et al. - 2022 - Research on lung nodule recognition algorithm based on deep feature fusion and MKL-SVM-IPSO.pdf:application/pdf},
}

@article{liu_artificial_2022,
	title = {Artificial Intelligence ({AI}) for Lung Nodules, From the {AJR} Special Series on {AI} Applications},
	volume = {219},
	issn = {0361-803X, 1546-3141},
	url = {https://doi.org/10.2214/AJR.22.27487},
	doi = {10.2214/AJR.22.27487},
	abstract = {Please see the Editorial Comment by Vicky Goh discussing this article. Interest in artificial intelligence ({AI}) applications for lung nodules continues to grow among radiologists, particularly with the expanding eligibility criteria and clinical utilization of lung cancer screening {CT}. {AI} has been heavily investigated for detecting and characterizing lung nodules and for guiding prognostic assessment. {AI} tools have also been used for image postprocessing (e.g., rib suppression on radiography or vessel suppression on {CT}) and for noninterpretive aspects of reporting and workflow, including management of nodule follow-up. Despite growing interest in and rapid development of {AI} tools and {FDA} approval of {AI} tools for pulmonary nodule evaluation, integration into clinical practice has been limited. Challenges to clinical adoption have included concerns about generalizability, regulatory issues, technical hurdles in implementation, and human skepticism. Further validation of {AI} tools for clinical use and demonstration of benefit in terms of patient-oriented outcomes also are needed. This article provides an overview of potential applications of {AI} tools in the imaging evaluation of lung nodules and discusses the challenges faced by practices interested in clinical implementation of such tools.},
	pages = {703--712},
	number = {5},
	journaltitle = {American Journal of Roentgenology},
	author = {Liu, Jonathan A. and Yang, Issac Y. and Tsai, Emily B.},
	date = {2022-11},
	langid = {english},
	pmid = {35544377},
	file = {PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\MGKDQ4YJ\\Liu et al. - 2022 - Artificial Intelligence (AI) for Lung Nodules, From the AJR Special Series on AI Applications.pdf:application/pdf},
}

@inproceedings{liu_classification_2023,
	title = {Classification of Benign and Malignant Pulmonary Nodules Based on Mixed Features},
	doi = {10.23919/CCC58697.2023.10240557},
	abstract = {Lung cancer is a pervasive malignancy that remains the leading cause of cancer-related mortality worldwide[1]. Accurate diagnosis of benign and malignant lung nodules is crucial for the prevention and treatment of lung cancer. However, traditional methods of manually designed features face challenges in extracting and analyzing deep-level features using mathematical models. Meanwhile, methods using convolutional neural networks can extract deep-level features, but lack interpretability and are not as effective as manually designed feature methods for shallow visual features. To address these challenges, we propose a lung nodule classification method that combines shallow visual and deep learning features. We construct shallow visual and deep learning networks to extract and classify shallow visual features and deep learning features, respectively. Finally, we use a multi-model fusion strategy to achieve benign and malignant classification of lung nodules. In particular, we employ a neural network architecture search to build a deep learning network with better interpretability and performance. We conducted extensive experiments on the {LIDC}-{IDRI} dataset and compared our method with the state-of-the-art research. Our results show that our method outperforms existing methods with an accuracy and F1 score of 91.21\% and 91.04, respectively. demonstrating the effectiveness and superiority of our algorithm.},
	pages = {8803--8808},
	booktitle = {2023 42nd Chinese Control Conference ({CCC})},
	author = {Liu, Shaojun and Wang, Shujing and Wang, Qixiang and Luo, Junhua},
	date = {2023-07},
	note = {{ISSN}: 1934-1768},
	keywords = {Lung cancer, Feature extraction, Lung, Neural networks, Deep learning, Visualization, benign and malignant classification, Mathematical models, mixed features, Pulmonary nodules},
}

@article{liu_study_2022,
	title = {Study on the Prediction Method of Long-term Benign and Malignant Pulmonary Lesions Based on {LSTM}},
	volume = {10},
	issn = {2296-4185},
	url = {https://www.frontiersin.org/articles/10.3389/fbioe.2022.791424/full},
	doi = {10.3389/fbioe.2022.791424},
	abstract = {In order to more accurately and comprehensively characterize the changes and development rules of lesion characteristics in pulmonary medical images in different periods, the study was conducted to predict the evolution of pulmonary nodules in the longitudinal dimension of time, and a benign and malignant prediction model of pulmonary lesions in different periods was constructed under multiscale three-dimensional (3D) feature fusion. According to the sequence of computed tomography ({CT}) images of patients at different stages, 3D interpolation was conducted to generate 3D lung {CT} images. The 3D features of different size lesions in the lungs were extracted using 3D convolutional neural networks for fusion features. A time-modulated long short-term memory was constructed to predict the benign and malignant lesions by using the improved time-length memory method to learn the feature vectors of lung lesions with temporal and spatial characteristics in different periods. The experiment shows that the area under the curve of the proposed method is 92.71\%, which is higher than that of the traditional method.},
	pages = {791424},
	journaltitle = {Frontiers in Bioengineering and Biotechnology},
	shortjournal = {Front. Bioeng. Biotechnol.},
	author = {Liu, Xindong and Wang, Mengnan and Aftab, Rukhma},
	date = {2022-03-02},
	langid = {english},
	file = {PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\IZSWHZR2\\Liu et al. - 2022 - Study on the Prediction Method of Long-term Benign and Malignant Pulmonary Lesions Based on LSTM.pdf:application/pdf},
}

@article{mahmoud_chest_2022,
	title = {Chest Radiographs Images Retrieval Using Deep Learning Networks},
	volume = {11},
	rights = {https://creativecommons.org/licenses/by-sa/4.0},
	issn = {2302-9285, 2089-3191},
	url = {https://beei.org/index.php/EEI/article/view/3478},
	doi = {10.11591/eei.v11i3.3478},
	pages = {1358--1369},
	number = {3},
	journaltitle = {Bulletin of Electrical Engineering and Informatics},
	shortjournal = {Bulletin {EEI}},
	author = {Mahmoud, Sawsan and Al-Jubouri, Hanan and Abdulabbas, Tawfeeq},
	date = {2022-06-01},
	langid = {english},
	file = {PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\7VLVJDVP\\Mahmoud et al. - 2022 - Chest Radiographs Images Retrieval Using Deep Learning Networks.pdf:application/pdf},
}

@article{naqi_multistage_2018,
	title = {Multistage segmentation model and {SVM}-ensemble for precise lung nodule detection},
	volume = {13},
	issn = {1861-6429},
	url = {https://doi.org/10.1007/s11548-018-1715-9},
	doi = {10.1007/s11548-018-1715-9},
	abstract = {Lung cancer detection at its initial stages increases the survival chances of patients. Automatic detection of lung nodules facilitates radiologists during the diagnosis. However, there is a challenge of false positives in automated systems which may lead to wrong findings. Precise segmentation facilitates to accurately extract nodules from lung {CT} images in order to improve performance of the diagnostic method.},
	pages = {1083--1095},
	number = {7},
	journaltitle = {International Journal of Computer Assisted Radiology and Surgery},
	author = {Naqi, Syed Muhammad and Sharif, Muhammad and Yasmin, Mussarat},
	date = {2018-07-01},
}

@article{muzammil_pulmonary_2021,
	title = {Pulmonary Nodule Classification Using Feature and Ensemble Learning-Based Fusion Techniques},
	volume = {9},
	rights = {https://creativecommons.org/licenses/by/4.0/legalcode},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/9507437/},
	doi = {10.1109/ACCESS.2021.3102707},
	pages = {113415--113427},
	journaltitle = {{IEEE} Access},
	author = {Muzammil, Muhammad and Ali, Imdad and Haq, Ihsan Ul and Amir, Muhammad and Abdullah, Suheel},
	date = {2021},
	langid = {english},
	keywords = {Deep convolutional neural network, Lung cancer, Computed tomography, Cancer, computer aided diagnosis, Feature extraction, Lung, deep features, support vector machine, Support vector machines, computed tomography, Dee..., deep feature fusion, ensemble learner, {LUNA}16 challenge, nodule classification, pulmonary nodule, Tumors},
	file = {PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\LPK26Y2U\\Muzammil et al. - 2021 - Pulmonary Nodule Classification Using Feature and Ensemble Learning-Based Fusion Techniques.pdf:application/pdf},
}

@misc{national_lung_screening_trial_research_team_data_2013,
	title = {Data from the National Lung Screening Trial ({NLST})},
	url = {https://doi.org/10.7937/TCIA.HMQ8-J677},
	publisher = {The Cancer Imaging Archive},
	author = {{National Lung Screening Trial Research Team}},
	date = {2013},
	doi = {10.7937/TCIA.HMQ8-J677},
	note = {Published: Dataset},
}

@article{national_lung_screening_trial_research_team_reduced_2011,
	title = {Reduced Lung-Cancer Mortality with Low-Dose Computed Tomographic Screening},
	volume = {365},
	issn = {0028-4793, 1533-4406},
	url = {https://europepmc.org/articles/PMC4356534},
	doi = {10.1056/nejmoa1102873},
	abstract = {\&lt;h4\&gt;Background\&lt;/h4\&gt;The aggressive and heterogeneous nature of lung cancer has thwarted efforts to reduce mortality from this cancer through the use of screening. The advent of low-dose helical computed tomography ({CT}) altered the landscape of lung-cancer screening, with studies indicating that low-dose {CT} detects many tumors at early stages. The National Lung Screening Trial ({NLST}) was conducted to determine whether screening with low-dose {CT} could reduce mortality from lung cancer.\&lt;h4\&gt;Methods\&lt;/h4\&gt;From August 2002 through April 2004, we enrolled 53,454 persons at high risk for lung cancer at 33 U.S. medical centers. Participants were randomly assigned to undergo three annual screenings with either low-dose {CT} (26,722 participants) or single-view posteroanterior chest radiography (26,732). Data were collected on cases of lung cancer and deaths from lung cancer that occurred through December 31, 2009.\&lt;h4\&gt;Results\&lt;/h4\&gt;The rate of adherence to screening was more than 90\%. The rate of positive screening tests was 24.2\% with low-dose {CT} and 6.9\% with radiography over all three rounds. A total of 96.4\% of the positive screening results in the low-dose {CT} group and 94.5\% in the radiography group were false positive results. The incidence of lung cancer was 645 cases per 100,000 person-years (1060 cancers) in the low-dose {CT} group, as compared with 572 cases per 100,000 person-years (941 cancers) in the radiography group (rate ratio, 1.13; 95\% confidence interval [{CI}], 1.03 to 1.23). There were 247 deaths from lung cancer per 100,000 person-years in the low-dose {CT} group and 309 deaths per 100,000 person-years in the radiography group, representing a relative reduction in mortality from lung cancer with low-dose {CT} screening of 20.0\% (95\% {CI}, 6.8 to 26.7; P=0.004). The rate of death from any cause was reduced in the low-dose {CT} group, as compared with the radiography group, by 6.7\% (95\% {CI}, 1.2 to 13.6; P=0.02).\&lt;h4\&gt;Conclusions\&lt;/h4\&gt;Screening with the use of low-dose {CT} reduces mortality from lung cancer. (Funded by the National Cancer Institute; National Lung Screening Trial {ClinicalTrials}.gov number, {NCT}00047385.).},
	pages = {395--409},
	number = {5},
	journaltitle = {The New England journal of medicine},
	shortjournal = {N Engl J Med},
	author = {{National Lung Screening Trial Research Team} and Aberle, Denise R and Adams, Amanda M and Berg, Christine D and Black, William C and Clapp, Jonathan D and Fagerstrom, Richard M and Gareen, Ilana F and Gatsonis, Constantine and Marcus, Pamela M and Sicks, JoRean D},
	date = {2011-08-04},
	langid = {english},
	file = {nihms320819:D\:\\Faculdade\\ZoteroStorage\\storage\\L55L2G72\\nihms320819.pdf:application/pdf;Texto Completo:D\:\\Faculdade\\ZoteroStorage\\storage\\JZM7PB4Z\\National Lung Screening Trial Research Team et al. - 2011 - Reduced lung-cancer mortality with low-dose computed tomographic screening.pdf:application/pdf},
}

@article{saihood_multi-orientation_2023,
	title = {Multi-Orientation Local Texture Features for Guided Attention-Based Fusion in Lung Nodule Classification},
	volume = {11},
	rights = {https://creativecommons.org/licenses/by-nc-nd/4.0/},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/10046305/},
	doi = {10.1109/ACCESS.2023.3243104},
	pages = {17555--17568},
	journaltitle = {{IEEE} Access},
	author = {Saihood, Ahmed and Karshenas, Hossein and Naghsh-Nilchi, Ahmad Reza},
	date = {2023},
	langid = {english},
	keywords = {Computed tomography, Cancer, Feature extraction, Deep learning, co-occurrence pattern, Data mining, Data mining..., long-range dependency, Lung cancer classification, Lungs, non-local guided attention, Recurrent neural networks, texture feature descriptor, Three-dimensional displays},
	file = {PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\9C67PIA7\\Saihood et al. - 2023 - Multi-Orientation Local Texture Features for Guided Attention-Based Fusion in Lung Nodule Classifica.pdf:application/pdf},
}

@misc{setio_luna16_2016,
	title = {{LUNA}16: A Challenge for Automatic Nodule Detection in Low-Dose {CT} Scans},
	url = {https://luna16.grand-challenge.org/},
	author = {Setio, Arnaud Arindra Adiyoso and Traverso, Andrea and de Bel, Tom and Berens, Maria S. and van den Bogaard, Casper and Cerello, Piergiorgio and Chen, Huanjun and Dou, Qi and Fantacci, Maria Enrica and Geurts, Bart and van der Gugten, Rogier and Jacobs, Colin and Jirapatnakul, Aruch and Litjens, Geert and Maldonado, Sergio Gomez and Mucherino, Sacha and Pedersen, Jesper Hjorth and Penzkofer, Tobias and Scholten, Eduard T. and Stieren, Michelle and Tan, Freek and Walsh, Sean and Wei, Xiaochen and van Ginneken, Bram and van Klaveren, René and van der Laak, Jeroen and Schaefer-Prokop, Cornelia and Prokop, Mathias and Meijer, Fred and Ardila, David and Farre, Xavier Ribo and Ypsilantis, Panagiotis P. and Montuenga, Luis M. and Sánchez-Salcedo, Alejandro and Nogueira, Jose Garcia and Pu, Jian and Niemeijer, Meindert},
	date = {2016},
}

@article{shaffie_computer-assisted_2022,
	title = {Computer-assisted image processing system for early assessment of lung nodule malignancy},
	volume = {14},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2072-6694},
	url = {https://www.mdpi.com/2072-6694/14/5/1117},
	doi = {10.3390/cancers14051117},
	abstract = {Lung cancer is one of the most dreadful cancers, and its detection in the early stage is very important and challenging. This manuscript proposes a new computer-aided diagnosis system for lung cancer diagnosis from chest computed tomography scans. The proposed system extracts two different kinds of features, namely, appearance features and shape features. For the appearance features, a Histogram of oriented gradients, a Multi-view analytical Local Binary Pattern, and a Markov Gibbs Random Field are developed to give a good description of the lung nodule texture, which is one of the main distinguishing characteristics between benign and malignant nodules. For the shape features, Multi-view Peripheral Sum Curvature Scale Space, Spherical Harmonics Expansion, and a group of some fundamental morphological features are implemented to describe the outer contour complexity of the nodules, which is main factor in lung nodule diagnosis. Each feature is fed into a stacked auto-encoder followed by a soft-max classifier to generate the initial malignancy probability. Finally, all these probabilities are combined together and fed to the last network to give the final diagnosis. The system is validated using 727 nodules which are subset from the Lung Image Database Consortium ({LIDC}) dataset. The system shows very high performance measures and achieves 92.55\%, 91.70\%, and 93.40\% for the accuracy, sensitivity, and specificity, respectively. This high performance shows the ability of the system to distinguish between the malignant and benign nodules precisely.},
	pages = {1117},
	number = {5},
	journaltitle = {Cancers (Basel)},
	shortjournal = {Cancers},
	author = {Shaffie, Ahmed and Soliman, Ahmed and Eledkawy, Amr and van Berkel, Victor and El-Baz, Ayman},
	date = {2022-02-22},
	langid = {english},
	note = {Publisher: {MDPI} {AG}},
	keywords = {{LBP}, autoencoder, {CSS}, {CT} image, {HOG}, lung cancer, {MGRF}, spherical harmonics},
	file = {PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\AGIK8VS3\\Shaffie et al. - 2022 - Computer-Assisted Image Processing System for Early Assessment of Lung Nodule Malignancy.pdf:application/pdf},
}

@article{shaffie_generalized_2018,
	title = {A Generalized Deep Learning-Based Diagnostic System for Early Diagnosis of Various Types of Pulmonary Nodules},
	volume = {17},
	issn = {1533-0346, 1533-0338},
	url = {https://journals.sagepub.com/doi/10.1177/1533033818798800},
	doi = {10.1177/1533033818798800},
	abstract = {A novel framework for the classification of lung nodules using computed tomography scans is proposed in this article. To get an accurate diagnosis of the detected lung nodules, the proposed framework integrates the following 2 groups of features: (1) appearance features modeled using the higher order Markov Gibbs random field model that has the ability to describe the spatial inhomogeneities inside the lung nodule and (2) geometric features that describe the shape geometry of the lung nodules. The novelty of this article is to accurately model the appearance of the detected lung nodules using a new developed seventhorder Markov Gibbs random field model that has the ability to model the existing spatial inhomogeneities for both small and large detected lung nodules, in addition to the integration with the extracted geometric features. Finally, a deep autoencoder classifier is fed by the above 2 feature groups to distinguish between the malignant and benign nodules. To evaluate the proposed framework, we used the publicly available data from the Lung Image Database Consortium. We used a total of 727 nodules that were collected from 467 patients. The proposed system demonstrates the promise to be a valuable tool for the detection of lung cancer evidenced by achieving a nodule classification accuracy of 91.20\%.},
	pages = {1533033818798800},
	journaltitle = {Technol. Cancer Res. Treat.},
	shortjournal = {Technol Cancer Res Treat},
	author = {Shaffie, Ahmed and Soliman, Ahmed and Fraiwan, Luay and Ghazal, Mohammed and Taher, Fatma and Dunlap, Neal and Wang, Brian and Van Berkel, Victor and Keynton, Robert and Elmaghraby, Adel and El-Baz, Ayman},
	urldate = {2025-02-04},
	date = {2018-01-01},
	langid = {english},
	note = {Publisher: {SAGE} Publications},
	keywords = {computer-aided diagnosis, computed tomography, pulmonary nodule, autoencoder, lung cancer, higher order {MGRF}},
	file = {PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\6MPUHLZ4\\Shaffie et al. - 2018 - A Generalized Deep Learning-Based Diagnostic System for Early Diagnosis of Various Types of Pulmonar.pdf:application/pdf},
}

@inproceedings{shaffie_novel_2021,
	location = {Nice, France},
	title = {A Novel Framework for Accurate and Non-Invasive Pulmonary Nodule Diagnosis by Integrating Texture and Contour Descriptors},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	isbn = {978-1-6654-1246-9},
	url = {https://ieeexplore.ieee.org/document/9433830/},
	doi = {10.1109/ISBI48211.2021.9433830},
	eventtitle = {2021 {IEEE} 18th International Symposium on Biomedical Imaging ({ISBI})},
	pages = {1883--1886},
	booktitle = {2021 {IEEE} 18th International Symposium on Biomedical Imaging ({ISBI})},
	publisher = {{IEEE}},
	author = {Shaffie, Ahmed and Soliman, Ahmed and Khalifeh, Hadil Abu and Ghazal, Mohammed and Taher, Fatma and Elmaghraby, Adel and El-Baz, Ayman},
	date = {2021-04-13},
	langid = {english},
	note = {Section: 0},
	keywords = {Lung cancer, Computed tomography, Lung, Solid modeling, {CAD}, Computer Tomography, M..., Markov Gibbs Random Field, Sensitivity and specificity, Shape, Tools, Various-views {MACSS}},
	file = {PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\UE3RT22Z\\Shaffie et al. - 2021 - A Novel Framework for Accurate and Non-Invasive Pulmonary Nodule Diagnosis by Integrating Texture an.pdf:application/pdf},
}

@article{xie_fusing_2018,
	title = {Fusing texture, shape and deep model-learned information at decision level for automated classification of lung nodules on chest {CT}},
	volume = {42},
	issn = {1566-2535},
	url = {https://www.sciencedirect.com/science/article/pii/S1566253516301063},
	doi = {https://doi.org/10.1016/j.inffus.2017.10.005},
	abstract = {The separation of malignant from benign lung nodules on chest computed tomography ({CT}) is important for the early detection of lung cancer, since early detection and management offer the best chance for cure. Although deep learning methods have recently produced a marked improvement in image classification there are still challenges as these methods contain myriad parameters and require large-scale training sets that are not usually available for most routine medical imaging studies. In this paper, we propose an algorithm for lung nodule classification that fuses the texture, shape and deep model-learned information (Fuse-{TSD}) at the decision level. This algorithm employs a gray level co-occurrence matrix ({GLCM})-based texture descriptor, a Fourier shape descriptor to characterize the heterogeneity of nodules and a deep convolutional neural network ({DCNN}) to automatically learn the feature representation of nodules on a slice-by-slice basis. It trains an {AdaBoosted} back propagation neural network ({BPNN}) using each feature type and fuses the decisions made by three classifiers to differentiate nodules. We evaluated this algorithm against three approaches on the {LIDC}-{IDRI} dataset. When the nodules with a composite malignancy rate 3 were discarded, regarded as benign or regarded as malignant, our Fuse-{TSD} algorithm achieved an {AUC} of 96.65\%, 94.45\% and 81.24\%, respectively, which was substantially higher than the {AUC} obtained by other approaches.},
	pages = {102--110},
	journaltitle = {Information Fusion},
	author = {Xie, Yutong and Zhang, Jianpeng and Xia, Yong and Fulham, Michael and Zhang, Yanning},
	date = {2018-07},
	langid = {english},
	keywords = {Lung nodule classification, {AdaBoost}, Back propagation neural network ({BPNN}), Chest {CT}, Deep convolutional neural network ({DCNN}), information fusion},
	file = {PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\TDHILT5X\\Xie et al. - 2018 - Fusing texture, shape and deep model-learned information at decision level for automated classificat.pdf:application/pdf},
}

@article{yuan_multi-modal_2023,
	title = {Multi-Modal Feature Fusion-Based Multi-Branch Classification Network for Pulmonary Nodule Malignancy Suspiciousness Diagnosis},
	volume = {36},
	issn = {1618-727X},
	url = {https://doi.org/10.1007/s10278-022-00747-z},
	doi = {10.1007/s10278-022-00747-z},
	abstract = {Detecting and identifying malignant nodules on chest computed tomography ({CT}) plays an important role in the early diagnosis and timely treatment of lung cancer, which can greatly reduce the number of deaths worldwide. In view of the existing methods in pulmonary nodule diagnosis, the importance of clinical radiological structured data (laboratory examination, radiological data) is ignored for the accuracy judgment of patients’ condition. Hence, a multi-modal fusion multi-branch classification network is constructed to detect and classify pulmonary nodules in this work: (1) Radiological data of pulmonary nodules are used to construct structured features of length 9. (2) A multi-branch fusion-based effective attention mechanism network is designed for 3D {CT} Patch unstructured data, which uses 3D {ECA}-{ResNet} to dynamically adjust the extracted features. In addition, feature maps with different receptive fields from multi-layer are fully fused to obtain representative multi-scale unstructured features. (3) Multi-modal feature fusion of structured data and unstructured data is performed to distinguish benign and malignant nodules. Numerous experimental results show that this advanced network can effectively classify the benign and malignant pulmonary nodules for clinical diagnosis, which achieves the highest accuracy (94.89\%), sensitivity (94.91\%), and F1-score (94.65\%) and lowest false positive rate (5.55\%).},
	pages = {617--626},
	number = {2},
	journaltitle = {Journal of Digital Imaging},
	shortjournal = {J Digit Imaging},
	author = {Yuan, Haiying and Wu, Yanrui and Dai, Mengfan},
	date = {2023-04-01},
	langid = {english},
	file = {Full Text PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\LUJ8S6U2\\Yuan et al. - 2023 - Multi-Modal Feature Fusion-Based Multi-Branch Classification Network for Pulmonary Nodule Malignancy.pdf:application/pdf;PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\HX4M7Z3A\\Yuan et al. - 2023 - Multi-Modal Feature Fusion-Based Multi-Branch Classification Network for Pulmonary Nodule Malignancy.pdf:application/pdf},
}

@article{zhao_new_2015,
	title = {A New Method of Detecting Pulmonary Nodules with {PET}/{CT} Based on an Improved Watershed Algorithm},
	volume = {10},
	issn = {1932-6203},
	url = {https://doi.org/10.1371/journal.pone.0123694},
	doi = {10.1371/journal.pone.0123694},
	abstract = {Background Integrated 18F-fluorodeoxyglucose positron emission tomography/computed tomography (18F-{FDG} {PET}/{CT}) is widely performed for staging solitary pulmonary nodules ({SPNs}). However, the diagnostic efficacy of {SPNs} based on {PET}/{CT} is not optimal. Here, we propose a method of detection based on {PET}/{CT} that can differentiate malignant and benign {SPNs} with few false-positives. Method Our proposed method combines the features of positron-emission tomography ({PET}) and computed tomography ({CT}). A dynamic threshold segmentation method was used to identify lung parenchyma in {CT} images and suspicious areas in {PET} images. Then, an improved watershed method was used to mark suspicious areas on the {CT} image. Next, the support vector machine ({SVM}) method was used to classify {SPNs} based on textural features of {CT} images and metabolic features of {PET} images to validate the proposed method. Results Our proposed method was more efficient than traditional methods and methods based on the {CT} or {PET} features alone (sensitivity 95.6\%; average of 2.9 false positives per scan).},
	pages = {1--15},
	number = {4},
	journaltitle = {{PLOS} {ONE}},
	author = {Zhao, Juanjuan and Ji, Guohua and Qiang, Yan and Han, Xiaohong and Pei, Bo and Shi, Zhenghao},
	date = {2015-04-08},
	langid = {english},
	note = {Publisher: Public Library of Science},
	file = {PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\3XVDC7MJ\\Zhao et al. - 2015 - A New Method of Detecting Pulmonary Nodules with PETCT Based on an Improved Watershed Algorithm.pdf:application/pdf},
}

@article{zhao_combining_2020,
	title = {Combining multi-scale feature fusion with multi-attribute grading, a {CNN} model for benign and malignant classification of pulmonary nodules},
	volume = {33},
	issn = {1618-727X},
	url = {https://doi.org/10.1007/s10278-020-00333-1},
	doi = {10.1007/s10278-020-00333-1},
	abstract = {Lung cancer has the highest mortality rate of all cancers, and early detection can improve survival rates. In the recent years, low-dose {CT} has been widely used to detect lung cancer. However, the diagnosis is limited by the subjective experience of doctors. Therefore, the main purpose of this study is to use convolutional neural network to realize the benign and malignant classification of pulmonary nodules in {CT} images. We collected 1004 cases of pulmonary nodules from {LIDC}-{IDRI} dataset, among which 554 cases were benign and 450 cases were malignant. According to the doctors' annotates on the center coordinates of the nodules, two 3D {CT} image patches of pulmonary nodules with different scales were extracted. In this study, our work focuses on two aspects. Firstly, we constructed a multi-stream multi-task network ({MSMT}), which combined multi-scale feature with multi-attribute classification for the first time, and applied it to the classification of benign and malignant pulmonary nodules. Secondly, we proposed a new loss function to balance the relationship between different attributes. The final experimental results showed that our model was effective compared with the same type of study. The area under {ROC} curve, accuracy, sensitivity, and specificity were 0.979, 93.92\%, 92.60\%, and 96.25\%, respectively.},
	pages = {869--878},
	number = {4},
	journaltitle = {Journal of Digital Imaging},
	author = {Zhao, Jumin and Zhang, Chen and Li, Dengao and Niu, Jing},
	date = {2020-08-01},
}

@article{zhao_pulmonary_2022,
	title = {Pulmonary Nodule Detection Based on Multiscale Feature Fusion},
	volume = {2022},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1748-6718, 1748-670X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1155/2022/8903037},
	doi = {https://doi.org/10.1155/2022/8903037},
	abstract = {As cancer with the highest morbidity and mortality in the world, lung cancer is characterized by pulmonary nodules in the early stage. The detection of pulmonary nodules is an important method for the early detection of lung cancer, which can greatly improve the survival rate of lung cancer patients. However, the accuracy of conventional detection methods for lung nodules is low. With the development of medical imaging technology, deep learning plays an increasingly important role in medical image detection, and pulmonary nodules can be accurately detected by {CT} images. Based on the above, a pulmonary nodule detection method based on deep learning is proposed. In the candidate nodule detection stage, the multiscale features and Faster R-{CNN}, a general-purpose detection framework based on deep learning, were combined together to improve the detection of small-sized lung nodules. In the false-positive nodule filtration stage, a 3D convolutional neural network based on multiscale fusion is designed to reduce false-positive nodules. The experiment results show that the candidate nodule detection model based on Faster R-{CNN} integrating multiscale features has achieved a sensitivity of 98.6\%, 10\% higher than that of the other single-scale model, the proposed method achieved a sensitivity of 90.5\% at the level of 4 false-positive nodules per scan, and the {CPM} score reached 0.829. The results are higher than methods in other works of literature. It can be seen that the detection method of pulmonary nodules based on multiscale fusion has a higher detection rate for small nodules and improves the classification performance of true and false-positive pulmonary nodules. This will help doctors when making a lung cancer diagnosis.},
	pages = {1--13},
	number = {1},
	journaltitle = {Computational and Mathematical Methods in Medicine},
	author = {Zhao, Yue and Wang, Zhongyang and Liu, Xinyao and Chen, Qi and Li, Chuangang and Zhao, Hongshuo and Wang, Zhiqiong},
	date = {2022-12-21},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1155/2022/8903037},
	file = {PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\ID7PGKMM\\Zhao et al. - 2022 - Pulmonary Nodule Detection Based on Multiscale Feature Fusion.pdf:application/pdf},
}

@article{lin_radiomics_2022,
	title = {A radiomics approach for lung nodule detection in thoracic {CT} images based on the dynamic patterns of morphological variation},
	volume = {32},
	issn = {1432-1084},
	url = {https://doi.org/10.1007/s00330-021-08456-x},
	doi = {10.1007/s00330-021-08456-x},
	abstract = {To propose and evaluate a set of radiomic features, called morphological dynamics features, for pulmonary nodule detection, which were rooted in the dynamic patterns of morphological variation and needless precise lesion segmentation.},
	pages = {3767--3777},
	number = {6},
	journaltitle = {European Radiology},
	shortjournal = {Eur Radiol},
	author = {Lin, Fan-Ya and Chang, Yeun-Chung and Huang, Hsuan-Yu and Li, Chia-Chen and Chen, Yi-Chang and Chen, Chung-Ming},
	urldate = {2025-02-04},
	date = {2022-06-01},
	langid = {english},
	keywords = {Lung, Deep learning, Machine learning, Multiple pulmonary nodules, X-ray computed tomography},
	file = {Full Text PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\FGQPAIQP\\Lin et al. - 2022 - A radiomics approach for lung nodule detection in thoracic CT images based on the dynamic patterns o.pdf:application/pdf},
}

@article{agrawal_content-based_2022,
	title = {Content-based medical image retrieval system for lung diseases using deep {CNNs}},
	volume = {14},
	issn = {2511-2104, 2511-2112},
	url = {https://doi.org/10.1007/s41870-022-01007-7},
	doi = {10.1007/s41870-022-01007-7},
	abstract = {Content-based image retrieval ({CBIR}) systems are designed to retrieve images that are relevant, based on detailed analysis of latent image characteristics, thus eliminating the dependency of natural language tags, text descriptions, or keywords associated with the images. A {CBIR} system maintains high-level image visuals in the form of feature vectors, which the retrieval engine leverages for similarity-based matching and ranking for a given query image. In this paper, a {CBIR} system is proposed for the retrieval of medical images ({CBMIR}) for enabling the early detection and classification of lung diseases based on lung X-ray images. The proposed {CBMIR} system is built on the predictive power of deep neural models for the identification and classification of disease-specific features using transfer learning based models trained on standard {COVID}-19 Chest X-ray image datasets. Experimental evaluation on the standard dataset revealed that the proposed approach achieved an improvement of 49.71\% in terms of precision, averaging across various distance metrics. Also, an improvement of 26.55\% was observed in the area under precision-recall curve ({AUPRC}) values across all subclasses.},
	pages = {3619--3627},
	number = {7},
	journaltitle = {International Journal of Information Technology},
	shortjournal = {Int. j. inf. tecnol.},
	author = {Agrawal, Shubham and Chowdhary, Aastha and Agarwala, Saurabh and Mayya, Veena and Kamath S., Sowmya},
	date = {2022-12-01},
	langid = {english},
	file = {PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\X2XUXMU3\\Agrawal et al. - 2022 - Content-based medical image retrieval system for lung diseases using deep CNNs.pdf:application/pdf},
}

@article{masood_automated_2020,
	title = {Automated Decision Support System for Lung Cancer Detection and Classification via Enhanced {RFCN} With Multilayer Fusion {RPN}},
	volume = {16},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	issn = {1551-3203, 1941-0050},
	url = {https://ieeexplore.ieee.org/document/9006938/},
	doi = {10.1109/TII.2020.2972918},
	abstract = {Detection of lung cancer at early stages is critical, in most of the cases radiologists read computed tomography ({CT}) images to prescribe follow-up treatment. The conventional method for detecting nodule presence in {CT} images is tedious. In this article, we propose an enhanced multidimensional region-based fully convolutional network ({mRFCN}) based automated decision support system for lung nodule detection and classiﬁcation. The {mRFCN} is used as an image classiﬁer backbone for feature extraction along with the novel multilayer fusion region proposal network ({mLRPN}) with position-sensitive score maps being explored. We applied a median intensity projection to leverage three-dimensional information from {CT} scans and introduced deconvolutional layer to adopt proposed {mLRPN} in our architecture to automatically select the potential region of interest. Our system has been trained and evaluated using {LIDC} dataset, and the experimental results showed promising detection performance in comparison to the state-of-the-art nodule detection/classiﬁcation methods, achieving a sensitivity of 98.1\% and classiﬁcation accuracy of 97.91\%.},
	pages = {7791--7801},
	number = {12},
	journaltitle = {{IEEE} Transactions on Industrial Informatics},
	shortjournal = {{IEEE} Trans. Ind. Inf.},
	author = {Masood, Anum and Sheng, Bin and Yang, Po and Li, Ping and Li, Huating and Kim, Jinman and Feng, David Dagan},
	urldate = {2025-02-04},
	date = {2020-12},
	langid = {english},
	keywords = {Computed tomography, Cancer, Feature extraction, Lung, Training, nodule classification, lung cancer, Computer-aided systems, convolutional neural network ({CNN}), Informatics, Proposals},
	file = {PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\C6ED7GVG\\Masood et al. - 2020 - Automated Decision Support System for Lung Cancer Detection and Classification via Enhanced RFCN Wit.pdf:application/pdf},
}

@article{alizadeh_novel_2023,
	title = {A novel Siamese deep hashing model for histopathology image retrieval},
	volume = {225},
	issn = {0957-4174},
	url = {https://www.sciencedirect.com/science/article/pii/S0957417423006711},
	doi = {https://doi.org/10.1016/j.eswa.2023.120169},
	abstract = {Content-based histopathology image retrieval can be a useful technique for help in diagnosing various diseases. The process of retrieving images is often time-consuming and challenging due to the need for high-dimensional features when trying to model complex content. Hashing methods can therefore be employed to resolve the challenge by producing binary codes of different lengths. Deep hashing methods are frequently superior to traditional machine learning approaches but are affected by the size of training sets. In addition, back-propagation learning can further complicate the generation of binary values. Hence, this paper proposes a novel Siamese deep hashing model, named histopathology Siamese deep hashing ({HSDH}), for histopathology image retrieval. Two designed deep hashing models with shared weights and structures are used to generate hash codes. A Hamming distance layer is then applied to evaluate the similarity of the generated values. A highly effective loss function is also introduced that incorporates a modified version of the standard contrastive loss function with an error estimation term to improve both the training and retrieval phases. In the retrieval phase, the trained model compares a query image with all the training images and ranks the most similar images. According to the experimental results on two publicly available databases, {BreakHis} and Kather, the {HSDH} model outperforms other state-of-the-art hashing-based methods in histopathology image retrieval.},
	pages = {120169},
	journaltitle = {Expert Systems with Applications},
	author = {Alizadeh, Seyed Mohammad and Helfroush, Mohammad Sadegh and Müller, Henning},
	date = {2023-09},
	langid = {english},
	keywords = {Convolutional neural networks, Deep hashing, Histopathology image retrieval, Pairwise similarity, Siamese networks},
	file = {PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\YLIKAKWF\\Mohammad Alizadeh et al. - 2023 - A novel Siamese deep hashing model for histopathology image retrieval.pdf:application/pdf},
}

@article{sohan_systematic_2023,
	title = {A Systematic Review on Federated Learning in Medical Image Analysis},
	volume = {11},
	rights = {https://creativecommons.org/licenses/by/4.0/legalcode},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/10077569/},
	doi = {10.1109/ACCESS.2023.3260027},
	abstract = {Federated Learning ({FL}) obtained a lot of attention to the academic and industrial stakeholders from the beginning of its invention. The eye-catching feature of {FL} is handling data in a decentralized manner which creates a privacy preserving environment in Artificial Intelligence ({AI}) applications. As we know medical data includes marginal private information of patients which demands excessive data protection from disclosure to unexpected destinations. In this paper, we performed a Systematic Literature Review ({SLR}) of published research articles on {FL} based medical image analysis. Firstly, we have collected articles from different databases followed by {PRISMA} guidelines, then synthesized data from the selected articles, and finally we provided a comprehensive overview on the topic. In order to do that we extracted core information associated with the implementation of {FL} in medical imaging from the articles. In our findings we briefly presented characteristics of federated data and models, performance achieved by the models and exclusively results comparison with traditional {ML} models. In addition, we discussed the open issues and challenges of implementing {FL} and mentioned our recommendations for future direction of this particular research field. We believe this {SLR} has successfully summarized the state-of-the-art {FL} methods for medical image analysis using deep learning.},
	pages = {28628--28644},
	journaltitle = {{IEEE} Access},
	shortjournal = {{IEEE} Access},
	author = {Sohan, Md Fahimuzzman and Basalamah, Anas},
	urldate = {2025-02-04},
	date = {2023},
	langid = {english},
	keywords = {Biomedical imaging, machine learning, Task analysis, Medical diagnostic imaging, Data models, data privacy, Federated learning, Hospitals, Image analysis, medical image analysis, Servers, systematic literature review},
	file = {PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\D9J9TJ2C\\Sohan e Basalamah - 2023 - A Systematic Review on Federated Learning in Medical Image Analysis.pdf:application/pdf},
}

@article{survarachakan_deep_2022,
	title = {Deep learning for image-based liver analysis — A comprehensive review focusing on malignant lesions},
	volume = {130},
	issn = {0933-3657},
	url = {https://www.sciencedirect.com/science/article/pii/S0933365722000963},
	doi = {https://doi.org/10.1016/j.artmed.2022.102331},
	abstract = {Deep learning-based methods, in particular, convolutional neural networks and fully convolutional networks are now widely used in the medical image analysis domain. The scope of this review focuses on the analysis using deep learning of focal liver lesions, with a special interest in hepatocellular carcinoma and metastatic cancer; and structures like the parenchyma or the vascular system. Here, we address several neural network architectures used for analyzing the anatomical structures and lesions in the liver from various imaging modalities such as computed tomography, magnetic resonance imaging and ultrasound. Image analysis tasks like segmentation, object detection and classification for the liver, liver vessels and liver lesions are discussed. Based on the qualitative search, 91 papers were filtered out for the survey, including journal publications and conference proceedings. The papers reviewed in this work are grouped into eight categories based on the methodologies used. By comparing the evaluation metrics, hybrid models performed better for both the liver and the lesion segmentation tasks, ensemble classifiers performed better for the vessel segmentation tasks and combined approach performed better for both the lesion classification and detection tasks. The performance was measured based on the Dice score for the segmentation, and accuracy for the classification and detection tasks, which are the most commonly used metrics.},
	pages = {102331},
	journaltitle = {Artificial Intelligence in Medicine},
	shortjournal = {Artificial Intelligence in Medicine},
	author = {Survarachakan, Shanmugapriya and Prasad, Pravda Jith Ray and Naseem, Rabia and Pérez De Frutos, Javier and Kumar, Rahul Prasanna and Langø, Thomas and Alaya Cheikh, Faouzi and Elle, Ole Jakob and Lindseth, Frank},
	urldate = {2025-02-04},
	date = {2022-08},
	langid = {english},
	keywords = {Deep-learning, Hepatic vessels, Lesions, Liver, Segmentation},
	file = {PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\524ABR4R\\Survarachakan et al. - 2022 - Deep learning for image-based liver analysis — A comprehensive review focusing on malignant lesions.pdf:application/pdf},
}

@article{yaacob_application_2023,
	title = {Application of Artificial Intelligence Techniques for Brain–Computer Interface in Mental Fatigue Detection: A Systematic Review (2011–2022)},
	volume = {11},
	rights = {https://creativecommons.org/licenses/by-nc-nd/4.0/},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/10185973/},
	doi = {10.1109/ACCESS.2023.3296382},
	pages = {74736--74758},
	journaltitle = {{IEEE} Access},
	author = {Yaacob, Hamwira and Hossain, Farhad and Shari, Sharunizam and Khare, Smith K. and Ooi, Chui Ping and Acharya, U. Rajendra},
	date = {2023},
	langid = {english},
	keywords = {Brain-computer interface ({BCI}), Brain-computer interfaces, Electrodes, electroencephalogram ({EEG}), Electroencephalography, Fatigue, Hardware, Mental disorders, mental fatigue detection, {PRISMA}, Sleep, Systematics},
	file = {PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\R2VPUS3L\\Yaacob et al. - 2023 - Application of Artificial Intelligence Techniques for Brain–Computer Interface in Mental Fatigue Det.pdf:application/pdf},
}

@article{sousa_single_2023,
	title = {Single Modality vs. Multimodality: What Works Best for Lung Cancer Screening?},
	volume = {23},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/23/12/5597},
	doi = {10.3390/s23125597},
	shorttitle = {Single Modality vs. Multimodality},
	abstract = {In a clinical context, physicians usually take into account information from more than one data modality when making decisions regarding cancer diagnosis and treatment planning. Artiﬁcial intelligence-based methods should mimic the clinical method and take into consideration different sources of data that allow a more comprehensive analysis of the patient and, as a consequence, a more accurate diagnosis. Lung cancer evaluation, in particular, can beneﬁt from this approach since this pathology presents high mortality rates due to its late diagnosis. However, many related works make use of a single data source, namely imaging data. Therefore, this work aims to study the prediction of lung cancer when using more than one data modality. The National Lung Screening Trial dataset that contains data from different sources, speciﬁcally, computed tomography ({CT}) scans and clinical data, was used for the study, the development and comparison of single-modality and multimodality models, that may explore the predictive capability of these two types of data to their full potential. A {ResNet}18 network was trained to classify 3D {CT} nodule regions of interest ({ROI}), whereas a random forest algorithm was used to classify the clinical data, with the former achieving an area under the {ROC} curve ({AUC}) of 0.7897 and the latter 0.5241. Regarding the multimodality approaches, three strategies, based on intermediate and late fusion, were implemented to combine the information from the 3D {CT} nodule {ROIs} and the clinical data. From those, the best model—a fully connected layer that receives as input a combination of clinical data and deep imaging features, given by a {ResNet}18 inference model—presented an {AUC} of 0.8021. Lung cancer is a complex disease, characterized by a multitude of biological and physiological phenomena and inﬂuenced by multiple factors. It is thus imperative that the models are capable of responding to that need. The results obtained showed that the combination of different types may have the potential to produce more comprehensive analyses of the disease by the models.},
	pages = {5597},
	number = {12},
	journaltitle = {Sensors},
	shortjournal = {Sensors},
	author = {Sousa, Joana Vale and Matos, Pedro and Silva, Francisco and Freitas, Pedro and Oliveira, Hélder P. and Pereira, Tania},
	urldate = {2025-02-04},
	date = {2023-06-15},
	langid = {english},
	file = {PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\MSW5QYPN\\Sousa et al. - 2023 - Single Modality vs. Multimodality What Works Best for Lung Cancer Screening.pdf:application/pdf},
}

@article{wang_retccl_2023,
	title = {{RetCCL}: Clustering-guided contrastive learning for whole-slide image retrieval},
	volume = {83},
	issn = {1361-8415},
	url = {https://www.sciencedirect.com/science/article/pii/S1361841522002730},
	doi = {https://doi.org/10.1016/j.media.2022.102645},
	abstract = {Benefiting from the large-scale archiving of digitized whole-slide images ({WSIs}), computer-aided diagnosis has been well developed to assist pathologists in decision-making. Content-based {WSI} retrieval can be a new approach to find highly correlated {WSIs} in a historically diagnosed {WSI} archive, which has the potential usages for assisted clinical diagnosis, medical research, and trainee education. During {WSI} retrieval, it is particularly challenging to encode the semantic content of histopathological images and to measure the similarity between images for interpretable results due to the gigapixel size of {WSIs}. In this work, we propose a Retrieval with Clustering-guided Contrastive Learning ({RetCCL}) framework for robust and accurate {WSI}-level image retrieval, which integrates a novel self-supervised feature learning method and a global ranking and aggregation algorithm for much improved performance. The proposed feature learning method makes use of existing large-scale unlabeled histopathological image data, which helps learn universal features that could be used directly for subsequent {WSI} retrieval tasks without extra fine-tuning. The proposed {WSI} retrieval method not only returns a set of {WSIs} similar to a query {WSI}, but also highlights patches or sub-regions of each {WSI} that share high similarity with patches of the query {WSI}, which helps pathologists interpret the searching results. Our {WSI} retrieval framework has been evaluated on the tasks of anatomical site retrieval and cancer subtype retrieval using over 22,000 slides, and the performance exceeds other state-of-the-art methods significantly (around 10\% for the anatomic site retrieval in terms of average {mMV}@10). Besides, the patch retrieval using our learned feature representation offers a performance improvement of 24\% on the {TissueNet} dataset in terms of {mMV}@5 compared with using {ImageNet} pre-trained features, which further demonstrates the effectiveness of the proposed {CCL} feature learning method.},
	pages = {102645},
	journaltitle = {Medical Image Analysis},
	author = {Wang, Xiyue and Du, Yuexi and Yang, Sen and Zhang, Jun and Wang, Minghui and Zhang, Jing and Yang, Wei and Huang, Junzhou and Han, Xiao},
	date = {2023},
	keywords = {Feature extraction, Image retrieval, Histopathology, Self-supervised learning},
}

@article{singh_federated_2023,
	title = {Federated Learning to Safeguard Patients Data: A Medical Image Retrieval Case},
	volume = {7},
	issn = {2504-2289},
	url = {https://www.mdpi.com/2504-2289/7/1/18},
	doi = {10.3390/bdcc7010018},
	abstract = {Healthcare data are distributed and confidential, making it difficult to use centralized automatic diagnostic techniques. For example, different hospitals hold the electronic health records ({EHRs}) of different patient populations; however, transferring this data between hospitals is difficult due to the sensitive nature of the information. This presents a significant obstacle to the development of efficient and generalizable analytical methods that require a large amount of diverse Big Data. Federated learning allows multiple institutions to work together to develop a machine learning algorithm without sharing their data. We conducted a systematic study to analyze the current state of {FL} in the healthcare industry and explore both the limitations of this technology and its potential. Organizations share the parameters of their models with each other. This allows them to reap the benefits of a model developed with a richer data set while protecting the confidentiality of their data. Standard methods for large-scale machine learning, distributed optimization, and privacy-friendly data analytics need to be fundamentally rethought to address the new problems posed by training on diverse networks that may contain large amounts of data. In this article, we discuss the particular qualities and difficulties of federated learning, provide a comprehensive overview of current approaches, and outline several directions for future work that are relevant to a variety of research communities. These issues are important to many different research communities.},
	number = {1},
	journaltitle = {Big Data and Cognitive Computing},
	author = {Singh, Gurtaj and Violi, Vincenzo and Fisichella, Marco},
	date = {2023},
}

@article{noauthor_notitle_nodate,
}

@article{rodrigues_efficient-proto-caps_2025,
	title = {Efficient-Proto-Caps: A Parameter-Efficient and Interpretable Capsule Network for Lung Nodule Characterization},
	volume = {13},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2025.3555428},
	pages = {56616--56630},
	journaltitle = {{IEEE} Access},
	shortjournal = {{IEEE} Access},
	author = {Rodrigues, Eduardo M. and Gouveia, Margarida and Oliveira, Hélder P. and Pereira, Tania},
	date = {2025},
	keywords = {Computed tomography, Medical diagnostic imaging, Training, Visualization, Lungs, medical image analysis, capsule network, Computational modeling, Explainable artificial intelligence, lung nodule characterization, Pipelines, prototype learning, Prototypes, Routing, Standards},
	file = {Full Text PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\JY99CUYG\\Rodrigues et al. - 2025 - Efficient-Proto-Caps A Parameter-Efficient and Interpretable Capsule Network for Lung Nodule Charac.pdf:application/pdf},
}

@article{minna_focus_2002,
	title = {Focus on lung cancer},
	volume = {1},
	issn = {1535-6108},
	url = {https://doi.org/10.1016/S1535-6108(02)00027-2},
	doi = {10.1016/S1535-6108(02)00027-2},
	pages = {49--52},
	number = {1},
	journaltitle = {Cancer Cell},
	author = {Minna, John D and Roth, Jack A and Gazdar, Adi F},
	urldate = {2025-06-14},
	date = {2002-02-01},
	note = {Publisher: Elsevier},
}

@article{travis_pathology_2011,
	title = {Pathology of Lung Cancer},
	volume = {32},
	issn = {0272-5231},
	url = {https://doi.org/10.1016/j.ccm.2011.08.005},
	doi = {10.1016/j.ccm.2011.08.005},
	abstract = {This article reviews current concepts in pathologic classification of lung cancer based on the 2004 World Health Organization classification of lung tumors and the 2011 International Association for the Study of Lung Cancer ({IASLC})/American Thoracic Society ({ATS})/European Respiratory Society ({ERS}) classification of lung adenocarcinoma. Preinvasive lesions are discussed. The major changes in lung disease diagnosis affected by the {IASLC}/{ATS}/{ERS} classification are presented. For adenocarcinomas diagnosed in small biopsies, specific terminology and diagnostic criteria are proposed along with recommendations for strategic management of tissue and {EGFR} mutation testing in patients with advanced adenocarcinoma. Histologic criteria are also presented for other tumors.},
	pages = {669--692},
	number = {4},
	journaltitle = {Clinics in Chest Medicine},
	author = {Travis, William D.},
	urldate = {2025-06-14},
	date = {2011-12-01},
	note = {Publisher: Elsevier},
}

@article{watanabe_tnm_2003,
	title = {{TNM} Classification for Lung Cancer},
	volume = {9},
	number = {6},
	journaltitle = {{TNM} Classification for Lung Cancer},
	author = {Watanabe, Yoh},
	date = {2003},
	langid = {english},
	file = {PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\D2U587IR\\Watanabe - 2003 - Review TNM Classification for Lung Cancer.pdf:application/pdf},
}

@article{baum_incidental_2024,
	title = {Incidental Pulmonary Nodules: Differential Diagnosis and Clinical Management},
	volume = {121},
	issn = {1866-0452},
	url = {http://dx.doi.org/10.3238/arztebl.m2024.0177},
	doi = {10.3238/arztebl.m2024.0177},
	abstract = {{BACKGROUND}: According to data from the {USA}, the incidence of incidentally discovered pulmonary nodules is 5.8 per 100 000 person- years for women and 5.2 per 100 000 person-years for men. Their management as recommended in the pertinent guidelines can substantially improve clinical outcomes. More than 95\% of all pulmonary nodules revealed by computerized tomography ({CT}) are benign, but many cases are not managed in conformity with the guidelines. In this article, we summarize the appropriate clinical approach and provide an overview of the pertinent diagnostic studies and when they should be performed. {METHODS}: This review is based on relevant publications retrieved by a selective search in {PubMed}. The authors examined Englishlanguage recommendations issued since 2010 for the management of pulmonary nodules, supplemented by comments from the German lung cancer guideline. {RESULTS}: In general, the risk that an incidentally discovered pulmonary nodule is malignant is low but rises markedly with increasing size and the presence of risk factors. When such a nodule is detected, the further recommendation, depending on size, is either for follow-up examinations with chest {CT} or else for an extended evaluation with positron emission tomography-{CT} and biopsy for histology. The diagnostic evaluation should include consideration of any earlier imaging studies that may be available as an indication of possible growth over time. Single nodules measuring less than 6 mm, in patients with few or no risk factors, do not require any follow-up. Lung cancer is diagnosed in just under 10\% of patients with a nodule measuring more than 8 mm. {CONCLUSION}: The recommendations of the guidelines for the management of incidentally discovered pulmonary nodules are intended to prevent both overand undertreatment. If a tumor is suspected, further care should be provided by an interdisciplinary team.},
	pages = {853--860},
	number = {25},
	journaltitle = {Dtsch Arztebl Int},
	author = {Baum, Philip and Schlamp, Kai and Klotz, Laura V and Eichhorn, Martin E and Herth, Felix and Winter, Hauke},
	date = {2024-12-13},
	note = {Place: Germany},
	file = {PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\XZ4FI7WD\\Baum et al. - 2024 - Incidental Pulmonary Nodules Differential Diagnosis and Clinical Management.pdf:application/pdf},
}

@article{loverdos_lung_2019,
	title = {Lung nodules: A comprehensive review on current approach and management},
	volume = {14},
	issn = {1817-1737},
	url = {https://journals.lww.com/aotm/fulltext/2019/14040/lung_nodules__a_comprehensive_review_on_current.2.aspx},
	abstract = {In daily clinical practice, radiologists and pulmonologists are faced with incidental radiographic findings of pulmonary nodules. Deciding how to manage these findings is very important as many of them may be benign and require no further action, but others may represent early disease and importantly early-stage lung cancer and require prompt diagnosis and definitive treatment. As the diagnosis of pulmonary nodules includes invasive procedures which can be relatively minimal, such as bronchoscopy or transthoracic aspiration or biopsy, but also more invasive procedures such as thoracic surgical biopsies, and as these procedures are linked to anxiety and to cost, it is important to have clearly defined algorithms for the description, management, and follow-up of these nodules. Clear algorithms for the imaging protocols and the management of positive findings should also exist in lung cancer screening programs, which are already established in the {USA} and which will hopefully be established worldwide. This article reviews current knowledge on nodule definition, diagnostic evaluation, and management based on literature data and mainly recent guidelines.},
	number = {4},
	journaltitle = {Annals of Thoracic Medicine},
	author = {Loverdos, Konstantinos and Fotiadis, Andreas and Kontogianni, Chrysoula and Iliopoulou, Marianthi and Gaga, Mina},
	date = {2019},
	keywords = {Low-dose computed tomography, lung cancer screening, lung nodule management, lung nodules},
}

@article{larici_lung_2017,
	title = {Lung nodules: size still matters},
	volume = {26},
	url = {https://publications.ersnet.org//content/errev/26/146/170025.abstract},
	doi = {10.1183/16000617.0025-2017},
	abstract = {The incidence of indeterminate pulmonary nodules has risen constantly over the past few years. Determination of lung nodule malignancy is pivotal, because the early diagnosis of lung cancer could lead to a definitive intervention. According to the current international guidelines, size and growth rate represent the main indicators to determine the nature of a pulmonary nodule. However, there are some limitations in evaluating and characterising nodules when only their dimensions are taken into account. There is no single method for measuring nodules, and intrinsic errors, which can determine variations in nodule measurement and in growth assessment, do exist when performing measurements either manually or with automated or semi-automated methods. When considering subsolid nodules the presence and size of a solid component is the major determinant of malignancy and nodule management, as reported in the latest guidelines. Nevertheless, other nodule morphological characteristics have been associated with an increased risk of malignancy. In addition, the clinical context should not be overlooked in determining the probability of malignancy. Predictive models have been proposed as a potential means to overcome the limitations of a sized-based assessment of the malignancy risk for indeterminate pulmonary nodules. Size and growth rate remain the main determinants of nodule management http://ow.ly/{mtDB}30gugUg},
	pages = {170025},
	number = {146},
	journaltitle = {European Respiratory Review},
	shortjournal = {Eur Respir Rev},
	author = {Larici, Anna Rita and Farchione, Alessandra and Franchi, Paola and Ciliberto, Mario and Cicchetti, Giuseppe and Calandriello, Lucio and del Ciello, Annemilia and Bonomo, Lorenzo},
	date = {2017-12-20},
}

@article{mazonakis_computed_2016,
	title = {Computed tomography: What and how does it measure?},
	volume = {85},
	issn = {0720-048X},
	url = {https://www.sciencedirect.com/science/article/pii/S0720048X16300754},
	doi = {10.1016/j.ejrad.2016.03.002},
	abstract = {The current study provides a comprehensive review about the use and the clinical applications of computed tomography ({CT}) associated with the in vivo evaluation of the human body composition. The high-resolution {CT} images allow the accurate separation of the various body compartments at the tissue/organ level including adipose tissue, skeletal muscle, bones and organs. The further ability of the imaging modality to distinguish the cortical from the trabecular bone and the visceral from the susbcutaneous fat is of great value in clinical studies. {CT} may also give important information about the components of the subcutaneous adipose tissue and the muscle or liver fat infiltration. The efficient determination of the skeletal muscle attenuation and bone mineral density, that related with metabolic disorders, is feasible with the aid of {CT} data. The area and volume of each human body compartment may be estimated with high accuracy and reproducibility from {CT} scans. These estimations may be carried out using the methods of manual planimetry, semi-automatic segmentation of the tissue of interest, stereological point-counting approach and geometrical models based either on linear or area measurements. The advantages and disadvantages of the aforementioned methods for the quantification of the human body composition are presented and discussed.},
	pages = {1499--1504},
	number = {8},
	journaltitle = {European Journal of Radiology},
	shortjournal = {European Journal of Radiology},
	author = {Mazonakis, Michalis and Damilakis, John},
	date = {2016-08-01},
	keywords = {Computed tomography, Human body compartments, Measurement methods, Βody composition},
}

@report{cantatore_introduction_2011,
	location = {Kgs.Lyngby},
	title = {Introduction to computed tomography},
	institution = {{DTU} Mechanical Engineering},
	type = {Report},
	author = {Cantatore, Angela and Müller, Pavel},
	date = {2011},
	note = {Publication Title: Introduction to computed tomography},
}

@article{abbasian_ardakani_interpretation_2022,
	title = {Interpretation of radiomics features–A pictorial review},
	volume = {215},
	issn = {0169-2607},
	url = {https://www.sciencedirect.com/science/article/pii/S0169260721006830},
	doi = {10.1016/j.cmpb.2021.106609},
	abstract = {Radiomics is a newcomer field that has opened new windows for precision medicine. It is related to extraction of a large number of quantitative features from medical images, which may be difficult to detect visually. Underlying tumor biology can change physical properties of tissues, which affect patterns of image pixels and radiomics features. The main advantage of radiomics is that it can characterize the whole tumor non-invasively, even after a single sampling from an image. Therefore, it can be linked to a “digital biopsy”. Physicians need to know about radiomics features to determine how their values correlate with the appearance of lesions and diseases. Indeed, physicians need practical references to conceive of basics and concepts of each radiomics feature without knowing their sophisticated mathematical formulas. In this review, commonly used radiomics features are illustrated with practical examples to help physicians in their routine diagnostic procedures.},
	pages = {106609},
	journaltitle = {Computer Methods and Programs in Biomedicine},
	shortjournal = {Computer Methods and Programs in Biomedicine},
	author = {Abbasian Ardakani, Ali and Bureau, Nathalie J and Ciaccio, Edward J. and Acharya, U Rajendra},
	date = {2022-03-01},
	keywords = {Radiomics, Texture analysis, Machine learning, Artificial intelligence, Personalized medicine},
}

@article{van_griethuysen_computational_2017,
	title = {Computational Radiomics System to Decode the Radiographic Phenotype},
	volume = {77},
	issn = {0008-5472, 1538-7445},
	url = {https://aacrjournals.org/cancerres/article/77/21/e104/662617/Computational-Radiomics-System-to-Decode-the},
	doi = {10.1158/0008-5472.CAN-17-0339},
	abstract = {Abstract
            Radiomics aims to quantify phenotypic characteristics on medical imaging through the use of automated algorithms. Radiomic artificial intelligence ({AI}) technology, either based on engineered hard-coded algorithms or deep learning methods, can be used to develop noninvasive imaging-based biomarkers. However, lack of standardized algorithm definitions and image processing severely hampers reproducibility and comparability of results. To address this issue, we developed {PyRadiomics}, a flexible open-source platform capable of extracting a large panel of engineered features from medical images. {PyRadiomics} is implemented in Python and can be used standalone or using 3D Slicer. Here, we discuss the workflow and architecture of {PyRadiomics} and demonstrate its application in characterizing lung lesions. Source code, documentation, and examples are publicly available at www.radiomics.io. With this platform, we aim to establish a reference standard for radiomic analyses, provide a tested and maintained resource, and to grow the community of radiomic developers addressing critical needs in cancer research. Cancer Res; 77(21); e104–7. ©2017 {AACR}.},
	pages = {e104--e107},
	number = {21},
	journaltitle = {Cancer Research},
	author = {Van Griethuysen, Joost J.M. and Fedorov, Andriy and Parmar, Chintan and Hosny, Ahmed and Aucoin, Nicole and Narayan, Vivek and Beets-Tan, Regina G.H. and Fillion-Robin, Jean-Christophe and Pieper, Steve and Aerts, Hugo J.W.L.},
	urldate = {2025-06-16},
	date = {2017-11-01},
	langid = {english},
	file = {Full Text PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\9ZMGKR5A\\Van Griethuysen et al. - 2017 - Computational Radiomics System to Decode the Radiographic Phenotype.pdf:application/pdf},
}

@inproceedings{kaur_review_2021,
	title = {A Review of Local Binary Pattern Based texture feature extraction},
	url = {https://ieeexplore.ieee.org/document/9596485/},
	doi = {10.1109/ICRITO51393.2021.9596485},
	abstract = {In the sphere of image processing, image data investigation is required related to a specific application in order to extract the suggestive information and reach defined and crisp culminations. One of the most significant phase in image processing is feature extraction which is the third step following image acquisition and segmentation. The procedure of reconstructing the input image into a group of features is named as feature extraction. These features construe the textural characteristics of the image. Texture feature extraction is one such significant part of feature extraction that on majority influences the results of classification. A texture is principally based on recognizing the object or region of interest in an image. The Local Binary Pattern feature descriptor will be the pith of discussion of this paper. {LBP} is a texture operator that operates on an image by labeling its pixels by thresholding neighborhood of each pixel. Various quality journals have been referred in order to provide an insight into the trends in pattern recognition using {LBP}.},
	eventtitle = {2021 9th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) ({ICRITO})},
	pages = {1--4},
	booktitle = {2021 9th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) ({ICRITO})},
	author = {Kaur, Navneet and Nazir, Nahida and {Manik}},
	urldate = {2025-06-16},
	date = {2021-09},
	keywords = {Feature extraction, Image segmentation, Local Binary Pattern, Market research, Measurement, Reliability, Silver, texture features, Thresholding (Imaging)},
	file = {Full Text PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\AAQKDIKL\\Kaur et al. - 2021 - A Review of Local Binary Pattern Based texture feature extraction.pdf:application/pdf},
}

@inproceedings{pietikainen_image_2005,
	location = {Berlin, Heidelberg},
	title = {Image Analysis with Local Binary Patterns},
	isbn = {978-3-540-31566-7},
	abstract = {The local binary pattern approach has evolved to represent a significant breakthrough in texture analysis, outperforming earlier methods in many applications. Perhaps the most important property of the {LBP} operator in real-world applications is its tolerance against illumination changes. Another equally important is its computational simplicity, which makes it possible to analyze images in challenging real-time settings. Recently, we have begun to study image analysis tasks which have not been generally considered texture analysis problems. Our excellent results suggest that that texture and the ideas behind the {LBP} methodology could have a much wider role in image analysis and computer vision than was thought before.},
	pages = {115--118},
	booktitle = {Image Analysis},
	publisher = {Springer Berlin Heidelberg},
	author = {Pietikäinen, Matti},
	editor = {Kalviainen, Heikki and Parkkinen, Jussi and Kaarna, Arto},
	date = {2005},
}

@article{pietikainen_local_2010,
	title = {Local Binary Patterns},
	volume = {5},
	doi = {10.4249/scholarpedia.9775},
	pages = {9775},
	number = {3},
	journaltitle = {Scholarpedia},
	author = {Pietikäinen, M.},
	date = {2010},
}

@article{zulpe_glcm_2012,
	title = {{GLCM} Textural Features for Brain Tumor Classification},
	volume = {9},
	abstract = {Automatic recognition system for medical images is challenging task in the field of medical image processing. Medical images acquired from different modalities such as Computed Tomography ({CT}), Magnetic Resonance Imaging ({MRI}), etc which are used for the diagnosis purpose. In the medical field, brain tumor classification is very important phase for the further treatment. Human interpretation of large number of {MRI} slices (Normal or Abnormal) may leads to misclassification hence there is need of such a automated recognition system, which can classify the type of the brain tumor. In this research work, we used four different classes of brain tumors and extracted the {GLCM} based textural features of each class, and applied to twolayered Feed forward Neural Network, which gives 97.5\% classification rate.},
	number = {3},
	journaltitle = {International Journal of Computer Science Issues},
	author = {Zulpe, Nitish and Pawar, Vrushsen},
	date = {2012},
	langid = {english},
	file = {PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\WZRALBL4\\Zulpe e Pawar - 2012 - GLCM Textural Features for Brain Tumor Classification.pdf:application/pdf},
}

@article{haralick_textural_1973,
	title = {Textural Features for Image Classification},
	volume = {{SMC}-3},
	issn = {0018-9472, 2168-2909},
	url = {http://ieeexplore.ieee.org/document/4309314/},
	doi = {10.1109/TSMC.1973.4309314},
	abstract = {Texture is one of the important characteristics used in identifying objects or regions of interest in an image, whether the image be a photomicrograph, an aerial photograph, or a satellite image. This paper describes some easily computable textural features based on graytone spatial dependancies, and illustrates their application in categoryidentification tasks of three different kinds of image data: photomicrographs of five kinds of sandstones, 1:20 000 panchromatic aerial photographs of eight land-use categories, and Earth Resources Technology Satellite ({ERTS}) multispecial imagery containing seven land-use categories. We use two kinds of decision rules: one for which the decision regions are convex polyhedra (a piecewise linear decision rule), and one for which the decision regions are rectangular parallelpipeds (a min-max decision rule). In each experiment the data set was divided into two parts, a training set and a test set. Test set identification accuracy is 89 percent for the photomicrographs, 82 percent for the aerial photographic imagery, and 83 percent for the satellite imagery. These results indicate that the easily computable textural features probably have a general applicability for a wide variety of image-classification applications.},
	pages = {610--621},
	number = {6},
	journaltitle = {{IEEE} Transactions on Systems, Man, and Cybernetics},
	shortjournal = {{IEEE} Trans. Syst., Man, Cybern.},
	author = {Haralick, Robert M. and Shanmugam, K. and Dinstein, Its'Hak},
	urldate = {2025-06-16},
	date = {1973-11},
	langid = {english},
	file = {PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\9SQF9J5X\\Haralick et al. - 1973 - Textural Features for Image Classification.pdf:application/pdf},
}

@article{oprisan_bounds_2023,
	title = {Bounds for Haralick features in synthetic images with sinusoidal gradients},
	volume = {3},
	issn = {2673-8198},
	url = {https://www.frontiersin.org/journals/signal-processing/articles/10.3389/frsip.2023.1271769/full},
	doi = {10.3389/frsip.2023.1271769},
	abstract = {Introduction: The gray-level co-occurrence matrix ({GLCM}) reduces the dimension of an image to a square matrix determined by the number of gray-level intensities present in that image. Since {GLCM} only measures the co-occurrence frequency of pairs of gray levels at a given distance from each other, it also stores information regarding the gradients of gray-level intensities in the original image.


Methods: The {GLCM} is a second-order statical method of encoding image information and dimensionality reduction. Image features are scalars that reduce {GLCM} dimensionality and allow fast texture classification. We used Haralick features to extract information regarding image gradients based on the {GLCM}.


Results: We demonstrate that a gradient of k gray levels per pixel in an image generates {GLCM} entries on the kth parallel line to the main diagonal. We find that, for synthetic sinusoidal periodic gradients with different wavelengths, the number of gray levels due to intensity quantization follows a power law that also transpires in some Haralick features. We estimate bounds for four of the most often used Haralick features: energy, contrast, correlation, and entropy. We find good agreement between our analytically predicted values of Haralick features and the numerical results from synthetic images of sinusoidal periodic gradients.


Discussion: This study opens the possibility of deriving bounds for Haralick features for targeted textures and provides a better selection mechanism for optimal features in texture analysis applications.},
	journaltitle = {Frontiers in Signal Processing},
	shortjournal = {Front. Signal Process.},
	author = {Oprisan, Ana and Oprisan, Sorinel Adrian},
	urldate = {2025-06-17},
	date = {2023-11-23},
	note = {Publisher: Frontiers},
	keywords = {bit depth reduction, Constant gradient, gray level cooccurrence matrix Frontiers, Haralick features, image processing, Signal processing, synthetic textures},
	file = {Full Text PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\B7TV4URW\\Oprisan e Oprisan - 2023 - Bounds for Haralick features in synthetic images with sinusoidal gradients.pdf:application/pdf},
}

@inproceedings{dalal_histograms_2005,
	title = {Histograms of oriented gradients for human detection},
	volume = {1},
	url = {https://ieeexplore.ieee.org/document/1467360/},
	doi = {10.1109/CVPR.2005.177},
	abstract = {We study the question of feature sets for robust visual object recognition; adopting linear {SVM} based human detection as a test case. After reviewing existing edge and gradient based descriptors, we show experimentally that grids of histograms of oriented gradient ({HOG}) descriptors significantly outperform existing feature sets for human detection. We study the influence of each stage of the computation on performance, concluding that fine-scale gradients, fine orientation binning, relatively coarse spatial binning, and high-quality local contrast normalization in overlapping descriptor blocks are all important for good results. The new approach gives near-perfect separation on the original {MIT} pedestrian database, so we introduce a more challenging dataset containing over 1800 annotated human images with a large range of pose variations and backgrounds.},
	eventtitle = {2005 {IEEE} Computer Society Conference on Computer Vision and Pattern Recognition ({CVPR}'05)},
	pages = {886--893 vol. 1},
	booktitle = {2005 {IEEE} Computer Society Conference on Computer Vision and Pattern Recognition ({CVPR}'05)},
	author = {Dalal, N. and Triggs, B.},
	urldate = {2025-06-17},
	date = {2005-06},
	note = {{ISSN}: 1063-6919},
	keywords = {Humans, Support vector machines, High performance computing, Histograms, Image databases, Image edge detection, Object detection, Object recognition, Robustness, Testing},
	file = {Full Text PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\BLPZ646W\\Dalal e Triggs - 2005 - Histograms of oriented gradients for human detection.pdf:application/pdf},
}

@article{mayerhoefer_introduction_2020,
	title = {Introduction to Radiomics},
	volume = {61},
	issn = {1535-5667},
	url = {http://dx.doi.org/10.2967/jnumed.118.222893},
	doi = {10.2967/jnumed.118.222893},
	abstract = {Radiomics is a rapidly evolving field of research concerned with the extraction of quantitative metrics-the so-called radiomic features-within medical images. Radiomic features capture tissue and lesion characteristics such as heterogeneity and shape and may, alone or in combination with demographic, histologic, genomic, or proteomic data, be used for clinical problem solving. The goal of this continuing education article is to provide an introduction to the field, covering the basic radiomics workflow: feature calculation and selection, dimensionality reduction, and data processing. Potential clinical applications in nuclear medicine that include {PET} radiomics-based prediction of treatment response and survival will be discussed. Current limitations of radiomics, such as sensitivity to acquisition parameter variations, and common pitfalls will also be covered.},
	pages = {488--495},
	number = {4},
	journaltitle = {J Nucl Med},
	author = {Mayerhoefer, Marius E and Materka, Andrzej and Langs, Georg and Häggström, Ida and Szczypiński, Piotr and Gibbs, Peter and Cook, Gary},
	date = {2020-02-14},
	note = {Place: United States},
	keywords = {machine learning, artificial intelligence, {PET}, radiomics, single-photon emission tomography},
}

@article{jassim_systematic_2022,
	title = {Systematic review for lung cancer detection and lung nodule classification: Taxonomy, challenges, and recommendation future works},
	volume = {31},
	url = {https://doi.org/10.1515/jisys-2022-0062},
	doi = {10.1515/jisys-2022-0062},
	series = {Journal of Intelligent Systems},
	pages = {944--964},
	number = {1},
	journaltitle = {Journal of Intelligent Systems},
	author = {Jassim, Mustafa Mohammed and Jaber, Mustafa Musa},
	urldate = {2025-06-17},
	date = {2022},
}

@inproceedings{naidu_review_2023,
	location = {Cham},
	title = {A Review of Evaluation Metrics in Machine Learning Algorithms},
	isbn = {978-3-031-35314-7},
	abstract = {With the increase in the adoption rate of machine learning algorithms in multiple sectors, the need for accurate measurement and assessment is imperative, especially when classifiers are applied to real world applications. Determining which are the most appropriate evaluation metrics to effectively assess and evaluate the performance of a binary, multi-class and multi-labelled classifier needs to be further understood. Another significant challenge impacting research is that results from models that are similar in nature cannot be adequately compared if the criteria for the measurement and evaluation of these models are not standardized. This review paper aims at highlighting the various evaluation metrics being applied in research and the non-standardization of evaluation metrics to measure the classification results of the model. Although Accuracy, Precision, Recall and F1-Score are the most applied evaluation metrics, there are certain limitations when considering these metrics in isolation. Other metrics such as {ROC}{\textbackslash}{AUC} and Kappa statistics have proven to provide additional insightful into the effectiveness of an algorithms adequacy and should also be considered when evaluating the effectiveness of binary, multi-class and multi-labelled classifiers. The adoption of a standardized and consistent evaluation methodology should be explored as an area of future work.},
	pages = {15--25},
	booktitle = {Artificial Intelligence Application in Networks and Systems},
	publisher = {Springer International Publishing},
	author = {Naidu, Gireen and Zuva, Tranos and Sibanda, Elias Mmbongeni},
	editor = {Silhavy, Radek and Silhavy, Petr},
	date = {2023},
}

@incollection{buzug_computed_2011,
	location = {Berlin, Heidelberg},
	title = {Computed Tomography},
	isbn = {978-3-540-74658-4},
	url = {https://doi.org/10.1007/978-3-540-74658-4_16},
	abstract = {In this chapter, historical milestones of computed tomography ({CT}) (Sect. 16.2), recent technology with a focus on generation and detection of x-rays (Sect. 16.3), as well as image reconstruction (Sect. 16.4) are discussed. Furthermore, the chapter includes aspects of applications (Sect.16.5), dose exposure in computed tomography (Sect. 16.6), and a brief overview on special {CT} developments (Sect. 16.7). Since this chapter gives a review, the interested reader is referred to recent literature on computed tomography including a detailed discussion of {CT} technology in the references section.},
	pages = {311--342},
	booktitle = {Springer Handbook of Medical Technology},
	publisher = {Springer Berlin Heidelberg},
	author = {Buzug, Thorsten M.},
	editor = {Kramme, Rüdiger and Hoffmann, Klaus-Peter and Pozos, Robert S.},
	date = {2011},
	langid = {english},
	doi = {10.1007/978-3-540-74658-4_16},
	file = {Full Text PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\ERK8SUTV\\Buzug - 2011 - Computed Tomography.pdf:application/pdf},
}

@article{fukushima_neocognitron_1980,
	title = {Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position},
	volume = {36},
	issn = {1432-0770},
	url = {https://doi.org/10.1007/BF00344251},
	doi = {10.1007/BF00344251},
	abstract = {A neural network model for a mechanism of visual pattern recognition is proposed in this paper. The network is self-organized by “learning without a teacher”, and acquires an ability to recognize stimulus patterns based on the geometrical similarity (Gestalt) of their shapes without affected by their positions. This network is given a nickname “neocognitron”. After completion of self-organization, the network has a structure similar to the hierarchy model of the visual nervous system proposed by Hubel and Wiesel. The network consits of an input layer (photoreceptor array) followed by a cascade connection of a number of modular structures, each of which is composed of two layers of cells connected in a cascade. The first layer of each module consists of “S-cells”, which show characteristics similar to simple cells or lower order hypercomplex cells, and the second layer consists of “C-cells” similar to complex cells or higher order hypercomplex cells. The afferent synapses to each S-cell have plasticity and are modifiable. The network has an ability of unsupervised learning: We do not need any “teacher” during the process of self-organization, and it is only needed to present a set of stimulus patterns repeatedly to the input layer of the network. The network has been simulated on a digital computer. After repetitive presentation of a set of stimulus patterns, each stimulus pattern has become to elicit an output only from one of the C-cell of the last layer, and conversely, this C-cell has become selectively responsive only to that stimulus pattern. That is, none of the C-cells of the last layer responds to more than one stimulus pattern. The response of the C-cells of the last layer is not affected by the pattern's position at all. Neither is it affected by a small change in shape nor in size of the stimulus pattern.},
	pages = {193--202},
	number = {4},
	journaltitle = {Biological Cybernetics},
	shortjournal = {Biological Cybernetics},
	author = {Fukushima, Kunihiko},
	date = {1980-04-01},
	file = {Full Text PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\UYW8SG7A\\Fukushima - 1980 - Neocognitron A self-organizing neural network model for a mechanism of pattern recognition unaffect.pdf:application/pdf},
}

@article{lecun_deep_2015,
	title = {Deep learning},
	volume = {521},
	issn = {1476-4687},
	url = {https://doi.org/10.1038/nature14539},
	doi = {10.1038/nature14539},
	abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
	pages = {436--444},
	number = {7553},
	journaltitle = {Nature},
	shortjournal = {Nature},
	author = {{LeCun}, Yann and Bengio, Yoshua and Hinton, Geoffrey},
	date = {2015-05-01},
}

@inproceedings{dai_introduction_2021,
	title = {An Introduction of {CNN}: Models and Training on Neural Network Models},
	doi = {10.1109/ICBAR55169.2021.00037},
	eventtitle = {2021 International Conference on Big Data, Artificial Intelligence and Risk Management ({ICBAR})},
	pages = {135--138},
	booktitle = {2021 International Conference on Big Data, Artificial Intelligence and Risk Management ({ICBAR})},
	author = {Dai, Dengyuhan},
	date = {2021-11-05},
	note = {Journal Abbreviation: 2021 International Conference on Big Data, Artificial Intelligence and Risk Management ({ICBAR})},
	keywords = {Deep Learning, Neural networks, Training, Deep learning, Computational modeling, Market research, component, Convolutional neural network, Loss function, Natural language processing, Predictive models},
}

@inproceedings{snoek_early_2005,
	location = {Hilton Singapore},
	title = {Early versus late fusion in semantic video analysis},
	isbn = {978-1-59593-044-6},
	url = {https://dl.acm.org/doi/10.1145/1101149.1101236},
	doi = {10.1145/1101149.1101236},
	eventtitle = {{MM}05: 2005 13th Annual {ACM} International Conference on Multimedia},
	pages = {399--402},
	booktitle = {Proceedings of the 13th annual {ACM} international conference on Multimedia},
	publisher = {{ACM}},
	author = {Snoek, Cees G. M. and Worring, Marcel and Smeulders, Arnold W. M.},
	urldate = {2025-06-23},
	date = {2005-11-06},
	langid = {english},
	file = {Full Text PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\X9N58HGE\\Snoek et al. - 2005 - Early versus late fusion in semantic video analysis.pdf:application/pdf},
}

@article{huang_fusion_2020,
	title = {Fusion of medical imaging and electronic health records using deep learning: a systematic review and implementation guidelines},
	volume = {3},
	issn = {2398-6352},
	url = {https://doi.org/10.1038/s41746-020-00341-z},
	doi = {10.1038/s41746-020-00341-z},
	abstract = {Advancements in deep learning techniques carry the potential to make significant contributions to healthcare, particularly in fields that utilize medical imaging for diagnosis, prognosis, and treatment decisions. The current state-of-the-art deep learning models for radiology applications consider only pixel-value information without data informing clinical context. Yet in practice, pertinent and accurate non-imaging data based on the clinical history and laboratory data enable physicians to interpret imaging findings in the appropriate clinical context, leading to a higher diagnostic accuracy, informative clinical decision making, and improved patient outcomes. To achieve a similar goal using deep learning, medical imaging pixel-based models must also achieve the capability to process contextual data from electronic health records ({EHR}) in addition to pixel data. In this paper, we describe different data fusion techniques that can be applied to combine medical imaging with {EHR}, and systematically review medical data fusion literature published between 2012 and 2020. We conducted a systematic search on {PubMed} and Scopus for original research articles leveraging deep learning for fusion of multimodality data. In total, we screened 985 studies and extracted data from 17 papers. By means of this systematic review, we present current knowledge, summarize important results and provide implementation guidelines to serve as a reference for researchers interested in the application of multimodal fusion in medical imaging.},
	pages = {136},
	number = {1},
	journaltitle = {npj Digital Medicine},
	shortjournal = {npj Digital Medicine},
	author = {Huang, Shih-Cheng and Pareek, Anuj and Seyyedi, Saeed and Banerjee, Imon and Lungren, Matthew P.},
	date = {2020-10-16},
}

@inproceedings{gadzicki_early_2020,
	title = {Early vs Late Fusion in Multimodal Convolutional Neural Networks},
	doi = {10.23919/FUSION45008.2020.9190246},
	pages = {1--6},
	booktitle = {2020 {IEEE} 23rd International Conference on Information Fusion ({FUSION})},
	author = {Gadzicki, Konrad and Khamsehashari, Razieh and Zetzsche, Christoph},
	date = {2020},
	keywords = {Feature extraction, Task analysis, Convolutional neural networks, Machine learning, Activity recognition, Correlation, Multi-layer neural network, Sensor fusion, Skeleton},
}

@misc{springenberg_striving_2015,
	title = {Striving for Simplicity: The All Convolutional Net},
	url = {http://arxiv.org/abs/1412.6806},
	doi = {10.48550/arXiv.1412.6806},
	shorttitle = {Striving for Simplicity},
	abstract = {Most modern convolutional neural networks ({CNNs}) used for object recognition are built using the same principles: Alternating convolution and max-pooling layers followed by a small number of fully connected layers. We re-evaluate the state of the art for object recognition from small images with convolutional networks, questioning the necessity of different components in the pipeline. We find that max-pooling can simply be replaced by a convolutional layer with increased stride without loss in accuracy on several image recognition benchmarks. Following this finding -- and building on other recent work for finding simple network structures -- we propose a new architecture that consists solely of convolutional layers and yields competitive or state of the art performance on several object recognition datasets ({CIFAR}-10, {CIFAR}-100, {ImageNet}). To analyze the network we introduce a new variant of the "deconvolution approach" for visualizing features learned by {CNNs}, which can be applied to a broader range of network structures than existing approaches.},
	number = {{arXiv}:1412.6806},
	publisher = {{arXiv}},
	author = {Springenberg, Jost Tobias and Dosovitskiy, Alexey and Brox, Thomas and Riedmiller, Martin},
	urldate = {2025-06-23},
	date = {2015-04-13},
	eprinttype = {arxiv},
	eprint = {1412.6806 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	file = {Full Text PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\RL6G8BEU\\Springenberg et al. - 2015 - Striving for Simplicity The All Convolutional Net.pdf:application/pdf;Snapshot:D\:\\Faculdade\\ZoteroStorage\\storage\\DIR2HEZT\\1412.html:text/html},
}

@article{he_deep_2015,
	title = {Deep Residual Learning for Image Recognition},
	volume = {abs/1512.03385},
	url = {http://arxiv.org/abs/1512.03385},
	journaltitle = {{CoRR}},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	urldate = {2025-06-23},
	date = {2015},
	eprinttype = {arxiv},
	eprint = {1512.03385},
	file = {Preprint PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\4LRNKD9C\\He et al. - 2015 - Deep Residual Learning for Image Recognition.pdf:application/pdf},
}

@article{shehab_efficient_2021,
	title = {An efficient brain tumor image segmentation based on deep residual networks ({ResNets})},
	volume = {33},
	issn = {1018-3639},
	url = {https://www.sciencedirect.com/science/article/pii/S1018363920302506},
	doi = {10.1016/j.jksues.2020.06.001},
	abstract = {Automatic segmentation of brain tumor from Magnetic Resonance Images ({MRI}) is one of the challenging tasks in computer vision. Many proposals investigate the use of Deep Neural Networks ({DNN}) in image segmentation as they have a high performance in automatic segmentation of brain tumors images. Due to the gradient diffusion problem and complexity, it generally takes a lot of time and extra computational power for training deeper neural networks. In this paper, we present an automatic technique for brain tumor segmentation depending on Deep Residual Learning Network ({ResNet}) to get over the gradient problem of {DNN}. {ResNets} accomplish more accuracy and can make the training process faster compared to their equivalent {DNN}. To achieve this enhancement, {ResNets} add a shortcut skip connection parallel to convolutional neural networks layers. Simulation examples have been carried out on dataset {BRATS} 2015 to verify the superiority of the proposed technique. Results verify that the proposed technique has an improved accuracy of 83\%, 90\%, and 85\% for the complete, core, and enhancing regions, respectively. Moreover, it has an average computation time (3 times) faster than other {DNN} techniques.},
	pages = {404--412},
	number = {6},
	journaltitle = {Journal of King Saud University - Engineering Sciences},
	shortjournal = {Journal of King Saud University - Engineering Sciences},
	author = {Shehab, Lamia H. and Fahmy, Omar M. and Gasser, Safa M. and El-Mahallawy, Mohamed S.},
	date = {2021-09-01},
	keywords = {Brain tumor segmentation, Deep Neural Networks ({DNN}), Deep Residual Learning Network ({ResNet}), Magnetic Resonance Imaging ({MRI})},
}

@misc{tan_efficientnet_2020,
	title = {{EfficientNet}: Rethinking Model Scaling for Convolutional Neural Networks},
	url = {http://arxiv.org/abs/1905.11946},
	doi = {10.48550/arXiv.1905.11946},
	shorttitle = {{EfficientNet}},
	abstract = {Convolutional Neural Networks ({ConvNets}) are commonly developed at a fixed resource budget, and then scaled up for better accuracy if more resources are available. In this paper, we systematically study model scaling and identify that carefully balancing network depth, width, and resolution can lead to better performance. Based on this observation, we propose a new scaling method that uniformly scales all dimensions of depth/width/resolution using a simple yet highly effective compound coefficient. We demonstrate the effectiveness of this method on scaling up {MobileNets} and {ResNet}. To go even further, we use neural architecture search to design a new baseline network and scale it up to obtain a family of models, called {EfficientNets}, which achieve much better accuracy and efficiency than previous {ConvNets}. In particular, our {EfficientNet}-B7 achieves state-of-the-art 84.3\% top-1 accuracy on {ImageNet}, while being 8.4x smaller and 6.1x faster on inference than the best existing {ConvNet}. Our {EfficientNets} also transfer well and achieve state-of-the-art accuracy on {CIFAR}-100 (91.7\%), Flowers (98.8\%), and 3 other transfer learning datasets, with an order of magnitude fewer parameters. Source code is at https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet.},
	number = {{arXiv}:1905.11946},
	publisher = {{arXiv}},
	author = {Tan, Mingxing and Le, Quoc V.},
	urldate = {2025-06-23},
	date = {2020-09-11},
	eprinttype = {arxiv},
	eprint = {1905.11946 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Full Text PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\3CXY6RUV\\Tan e Le - 2020 - EfficientNet Rethinking Model Scaling for Convolutional Neural Networks.pdf:application/pdf;Snapshot:D\:\\Faculdade\\ZoteroStorage\\storage\\V6FNCDE7\\1905.html:text/html},
}

@article{li_advances_2022,
	title = {Advances in lung cancer screening and early detection},
	volume = {19},
	issn = {2095-3941},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9196057/},
	doi = {10.20892/j.issn.2095-3941.2021.0690},
	abstract = {Lung cancer is associated with a heavy cancer-related burden in terms of patients’ physical and mental health worldwide. Two randomized controlled trials, the {US}-National Lung Screening Trial ({NLST}) and Nederlands-Leuvens Longkanker Screenings Onderzoek ({NELSON}), indicated that low-dose {CT} ({LDCT}) screening results in a statistically significant decrease in mortality in patients with lung cancer, {LDCT} has become the standard approach for lung cancer screening. However, many issues in lung cancer screening remain unresolved, such as the screening criteria, high false-positive rate, and radiation exposure. This review first summarizes recent studies on lung cancer screening from the {US}, Europe, and Asia, and discusses risk-based selection for screening and the related issues. Second, an overview of novel techniques for the differential diagnosis of pulmonary nodules, including artificial intelligence and molecular biomarker-based screening, is presented. Third, current explorations of strategies for suspected malignancy are summarized. Overall, this review aims to help clinicians understand recent progress in lung cancer screening and alleviate the burden of lung cancer.},
	pages = {591--608},
	number = {5},
	journaltitle = {Cancer Biology \& Medicine},
	shortjournal = {Cancer Biol Med},
	author = {Li, Caichen and Wang, Huiting and Jiang, Yu and Fu, Wenhai and Liu, Xiwen and Zhong, Ran and Cheng, Bo and Zhu, Feng and Xiang, Yang and He, Jianxing and Liang, Wenhua},
	urldate = {2025-06-26},
	date = {2022-05-15},
	pmid = {35535966},
	pmcid = {PMC9196057},
	file = {Texto Completo:D\:\\Faculdade\\ZoteroStorage\\storage\\FU8FJEPW\\Li et al. - 2022 - Advances in lung cancer screening and early detection.pdf:application/pdf},
}

@article{ning_early_2021,
	title = {Early diagnosis of lung cancer: which is the optimal choice?},
	volume = {13},
	issn = {1945-4589},
	url = {http://dx.doi.org/10.18632/aging.202504},
	doi = {10.18632/aging.202504},
	abstract = {The prognosis of lung cancer patients with different clinical stages is significantly different. The 5-year survival of stage {IA} groups can exceed 90\%, while patients with stage {IV} can be less than 10\%. Therefore, early diagnosis is extremely important for lung cancer patients. This research focused on various diagnosis methods of early lung cancer, including imaging screening, bronchoscopy, and emerging potential liquid biopsies, as well as volatile organic compounds, autoantibodies, aiming to improve the early diagnosis rate and explore feasible and effective early diagnosis strategies.},
	pages = {6214--6227},
	number = {4},
	journaltitle = {Aging (Albany {NY})},
	author = {Ning, Jing and Ge, Tao and Jiang, Minlin and Jia, Keyi and Wang, Lei and Li, Wei and Chen, Bin and Liu, Yu and Wang, Hao and Zhao, Sha and He, Yayi},
	date = {2021-02-11},
	note = {Place: United States},
	keywords = {lung cancer, bronchoscopy, diagnosis, {LDCT}, liquid biopsy},
}

@misc{liu_convnet_2022,
	title = {A {ConvNet} for the 2020s},
	url = {http://arxiv.org/abs/2201.03545},
	doi = {10.48550/arXiv.2201.03545},
	abstract = {The "Roaring 20s" of visual recognition began with the introduction of Vision Transformers ({ViTs}), which quickly superseded {ConvNets} as the state-of-the-art image classification model. A vanilla {ViT}, on the other hand, faces difficulties when applied to general computer vision tasks such as object detection and semantic segmentation. It is the hierarchical Transformers (e.g., Swin Transformers) that reintroduced several {ConvNet} priors, making Transformers practically viable as a generic vision backbone and demonstrating remarkable performance on a wide variety of vision tasks. However, the effectiveness of such hybrid approaches is still largely credited to the intrinsic superiority of Transformers, rather than the inherent inductive biases of convolutions. In this work, we reexamine the design spaces and test the limits of what a pure {ConvNet} can achieve. We gradually "modernize" a standard {ResNet} toward the design of a vision Transformer, and discover several key components that contribute to the performance difference along the way. The outcome of this exploration is a family of pure {ConvNet} models dubbed {ConvNeXt}. Constructed entirely from standard {ConvNet} modules, {ConvNeXts} compete favorably with Transformers in terms of accuracy and scalability, achieving 87.8\% {ImageNet} top-1 accuracy and outperforming Swin Transformers on {COCO} detection and {ADE}20K segmentation, while maintaining the simplicity and efficiency of standard {ConvNets}.},
	number = {{arXiv}:2201.03545},
	publisher = {{arXiv}},
	author = {Liu, Zhuang and Mao, Hanzi and Wu, Chao-Yuan and Feichtenhofer, Christoph and Darrell, Trevor and Xie, Saining},
	urldate = {2025-06-28},
	date = {2022-03-02},
	eprinttype = {arxiv},
	eprint = {2201.03545 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {Preprint PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\DICJI2C9\\Liu et al. - 2022 - A ConvNet for the 2020s.pdf:application/pdf;Snapshot:D\:\\Faculdade\\ZoteroStorage\\storage\\AUC2QJS3\\2201.html:text/html},
}

@article{ali_explainable_2023,
	title = {Explainable Artificial Intelligence ({XAI}): What we know and what is left to attain Trustworthy Artificial Intelligence},
	volume = {99},
	issn = {1566-2535},
	url = {https://www.sciencedirect.com/science/article/pii/S1566253523001148},
	doi = {10.1016/j.inffus.2023.101805},
	abstract = {Artificial intelligence ({AI}) is currently being utilized in a wide range of sophisticated applications, but the outcomes of many {AI} models are challenging to comprehend and trust due to their black-box nature. Usually, it is essential to understand the reasoning behind an {AI} model’s decision-making. Thus, the need for {eXplainable} {AI} ({XAI}) methods for improving trust in {AI} models has arisen. {XAI} has become a popular research subject within the {AI} field in recent years. Existing survey papers have tackled the concepts of {XAI}, its general terms, and post-hoc explainability methods but there have not been any reviews that have looked at the assessment methods, available tools, {XAI} datasets, and other related aspects. Therefore, in this comprehensive study, we provide readers with an overview of the current research and trends in this rapidly emerging area with a case study example. The study starts by explaining the background of {XAI}, common definitions, and summarizing recently proposed techniques in {XAI} for supervised machine learning. The review divides {XAI} techniques into four axes using a hierarchical categorization system: (i) data explainability, (ii) model explainability, (iii) post-hoc explainability, and (iv) assessment of explanations. We also introduce available evaluation metrics as well as open-source packages and datasets with future research directions. Then, the significance of explainability in terms of legal demands, user viewpoints, and application orientation is outlined, termed as {XAI} concerns. This paper advocates for tailoring explanation content to specific user types. An examination of {XAI} techniques and evaluation was conducted by looking at 410 critical articles, published between January 2016 and October 2022, in reputed journals and using a wide range of research databases as a source of information. The article is aimed at {XAI} researchers who are interested in making their {AI} models more trustworthy, as well as towards researchers from other disciplines who are looking for effective {XAI} methods to complete tasks with confidence while communicating meaning from data.},
	pages = {101805},
	journaltitle = {Information Fusion},
	shortjournal = {Information Fusion},
	author = {Ali, Sajid and Abuhmed, Tamer and El-Sappagh, Shaker and Muhammad, Khan and Alonso-Moral, Jose M. and Confalonieri, Roberto and Guidotti, Riccardo and Del Ser, Javier and Díaz-Rodríguez, Natalia and Herrera, Francisco},
	date = {2023-11-01},
	keywords = {{AI} principles, Data Fusion, Deep Learning, Explainable Artificial Intelligence, Interpretable machine learning, Post-hoc explainability, Trustworthy {AI}, {XAI} assessment},
	file = {Texto Completo:D\:\\Faculdade\\ZoteroStorage\\storage\\FWXBMA7G\\Ali et al. - 2023 - Explainable Artificial Intelligence (XAI) What we know and what is left to attain Trustworthy Artif.pdf:application/pdf},
}

@online{noauthor_regulation_nodate,
	title = {Regulation - 2016/679 - {EN} - gdpr - {EUR}-Lex},
	url = {https://eur-lex.europa.eu/eli/reg/2016/679/oj/eng},
	urldate = {2025-06-28},
	langid = {english},
	note = {Doc {ID}: 32016R0679
Doc Sector: 3
Doc Title: Regulation ({EU}) 2016/679 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95/46/{EC} (General Data Protection Regulation) (Text with {EEA} relevance)
Doc Type: R
Usr\_lan: en},
	file = {Snapshot:D\:\\Faculdade\\ZoteroStorage\\storage\\A96Q2EWY\\eng.html:text/html},
}

@inproceedings{selvaraju_grad-cam_2017,
	title = {Grad-{CAM}: Visual Explanations from Deep Networks via Gradient-Based Localization},
	isbn = {978-1-5386-1033-6},
	doi = {10.1109/ICCV.2017.74},
	eventtitle = {2017 {IEEE} International Conference on Computer Vision ({ICCV})},
	pages = {618--626},
	booktitle = {2017 {IEEE} International Conference on Computer Vision ({ICCV})},
	author = {Selvaraju, Ramprasaath R. and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
	date = {2017-10-22},
	keywords = {Cats, Computer architecture, Dogs, Knowledge discovery, Visualization},
	file = {Versão Submetida:D\:\\Faculdade\\ZoteroStorage\\storage\\GYUB9A6U\\R. R. Selvaraju et al. - 2017 - Grad-CAM Visual Explanations from Deep Networks via Gradient-Based Localization.pdf:application/pdf},
}

@inproceedings{chattopadhay_grad-cam_2018,
	title = {Grad-{CAM}++: Generalized Gradient-Based Visual Explanations for Deep Convolutional Networks},
	doi = {10.1109/WACV.2018.00097},
	pages = {839--847},
	booktitle = {2018 {IEEE} Winter Conference on Applications of Computer Vision ({WACV})},
	author = {Chattopadhay, Aditya and Sarkar, Anirban and Howlader, Prantik and Balasubramanian, Vineeth N},
	date = {2018},
	keywords = {Heating systems, Machine learning, Mathematical model, Neurons, Predictive models, Visualization},
}

@inproceedings{zhou_learning_2016,
	title = {Learning Deep Features for Discriminative Localization},
	doi = {10.1109/CVPR.2016.319},
	pages = {2921--2929},
	booktitle = {2016 {IEEE} Conference on Computer Vision and Pattern Recognition ({CVPR})},
	author = {Zhou, Bolei and Khosla, Aditya and Lapedriza, Agata and Oliva, Aude and Torralba, Antonio},
	date = {2016},
	keywords = {Computer vision, Detectors, Neural networks, Object recognition, Spatial resolution, Training, Visualization},
}

@misc{lundberg_unified_2017,
	title = {A Unified Approach to Interpreting Model Predictions},
	url = {http://arxiv.org/abs/1705.07874},
	doi = {10.48550/arXiv.1705.07874},
	abstract = {Understanding why a model makes a certain prediction can be as crucial as the prediction's accuracy in many applications. However, the highest accuracy for large modern datasets is often achieved by complex models that even experts struggle to interpret, such as ensemble or deep learning models, creating a tension between accuracy and interpretability. In response, various methods have recently been proposed to help users interpret the predictions of complex models, but it is often unclear how these methods are related and when one method is preferable over another. To address this problem, we present a unified framework for interpreting predictions, {SHAP} ({SHapley} Additive {exPlanations}). {SHAP} assigns each feature an importance value for a particular prediction. Its novel components include: (1) the identification of a new class of additive feature importance measures, and (2) theoretical results showing there is a unique solution in this class with a set of desirable properties. The new class unifies six existing methods, notable because several recent methods in the class lack the proposed desirable properties. Based on insights from this unification, we present new methods that show improved computational performance and/or better consistency with human intuition than previous approaches.},
	number = {{arXiv}:1705.07874},
	publisher = {{arXiv}},
	author = {Lundberg, Scott and Lee, Su-In},
	urldate = {2025-06-29},
	date = {2017-11-25},
	eprinttype = {arxiv},
	eprint = {1705.07874 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Full Text PDF:D\:\\Faculdade\\ZoteroStorage\\storage\\JXXFF2S4\\Lundberg e Lee - 2017 - A Unified Approach to Interpreting Model Predictions.pdf:application/pdf;Snapshot:D\:\\Faculdade\\ZoteroStorage\\storage\\AZTEK2QM\\1705.html:text/html},
}
