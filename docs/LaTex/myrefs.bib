
@article{national_lung_screening_trial_research_team_reduced_2011,
	title = {Reduced {Lung}-{Cancer} {Mortality} with {Low}-{Dose} {Computed} {Tomographic} {Screening}},
	volume = {365},
	issn = {0028-4793, 1533-4406},
	url = {https://europepmc.org/articles/PMC4356534},
	doi = {10.1056/nejmoa1102873},
	abstract = {\&lt;h4\&gt;Background\&lt;/h4\&gt;The aggressive and heterogeneous nature of lung cancer has thwarted efforts to reduce mortality from this cancer through the use of screening. The advent of low-dose helical computed tomography (CT) altered the landscape of lung-cancer screening, with studies indicating that low-dose CT detects many tumors at early stages. The National Lung Screening Trial (NLST) was conducted to determine whether screening with low-dose CT could reduce mortality from lung cancer.\&lt;h4\&gt;Methods\&lt;/h4\&gt;From August 2002 through April 2004, we enrolled 53,454 persons at high risk for lung cancer at 33 U.S. medical centers. Participants were randomly assigned to undergo three annual screenings with either low-dose CT (26,722 participants) or single-view posteroanterior chest radiography (26,732). Data were collected on cases of lung cancer and deaths from lung cancer that occurred through December 31, 2009.\&lt;h4\&gt;Results\&lt;/h4\&gt;The rate of adherence to screening was more than 90\%. The rate of positive screening tests was 24.2\% with low-dose CT and 6.9\% with radiography over all three rounds. A total of 96.4\% of the positive screening results in the low-dose CT group and 94.5\% in the radiography group were false positive results. The incidence of lung cancer was 645 cases per 100,000 person-years (1060 cancers) in the low-dose CT group, as compared with 572 cases per 100,000 person-years (941 cancers) in the radiography group (rate ratio, 1.13; 95\% confidence interval [CI], 1.03 to 1.23). There were 247 deaths from lung cancer per 100,000 person-years in the low-dose CT group and 309 deaths per 100,000 person-years in the radiography group, representing a relative reduction in mortality from lung cancer with low-dose CT screening of 20.0\% (95\% CI, 6.8 to 26.7; P=0.004). The rate of death from any cause was reduced in the low-dose CT group, as compared with the radiography group, by 6.7\% (95\% CI, 1.2 to 13.6; P=0.02).\&lt;h4\&gt;Conclusions\&lt;/h4\&gt;Screening with the use of low-dose CT reduces mortality from lung cancer. (Funded by the National Cancer Institute; National Lung Screening Trial ClinicalTrials.gov number, NCT00047385.).},
	language = {en},
	number = {5},
	journal = {The New England journal of medicine},
	author = {{National Lung Screening Trial Research Team} and Aberle, Denise R and Adams, Amanda M and Berg, Christine D and Black, William C and Clapp, Jonathan D and Fagerstrom, Richard M and Gareen, Ilana F and Gatsonis, Constantine and Marcus, Pamela M and Sicks, JoRean D},
	month = aug,
	year = {2011},
	pages = {395--409},
	file = {nihms320819:C\:\\Users\\janto\\Zotero\\storage\\L55L2G72\\nihms320819.pdf:application/pdf;Texto Completo:C\:\\Users\\janto\\Zotero\\storage\\JZM7PB4Z\\National Lung Screening Trial Research Team et al. - 2011 - Reduced lung-cancer mortality with low-dose computed tomographic screening.pdf:application/pdf},
}

@misc{world_health_organization_top_2024,
	title = {The {Top} 10 {Causes} of {Death}},
	url = {https://www.who.int/news-room/fact-sheets/detail/the-top-10-causes-of-death},
	language = {en},
	urldate = {2024-10-03},
	author = {{World Health Organization}},
	year = {2024},
	file = {Snapshot:C\:\\Users\\janto\\Zotero\\storage\\RH735VS5\\the-top-10-causes-of-death.html:text/html},
}

@misc{united_nations_17_2015,
	title = {{THE} 17 {GOALS} {\textbar} {Sustainable} {Development}},
	url = {https://sdgs.un.org/goals},
	urldate = {2024-10-06},
	author = {{United Nations}},
	year = {2015},
	file = {THE 17 GOALS | Sustainable Development:C\:\\Users\\janto\\Zotero\\storage\\9UWG66US\\goals.html:text/html},
}

@misc{armato_iii_data_2015,
	title = {Data {From} {LIDC}-{IDRI}},
	url = {https://doi.org/10.7937/K9/TCIA.2015.LO9QL9SX},
	publisher = {The Cancer Imaging Archive},
	author = {Armato III, Samuel G. and McLennan, Geoffrey and Bidaut, Luc and McNitt-Gray, Michael F. and Meyer, Charles R. and Reeves, Anthony P. and Zhao, Binsheng and Aberle, Denise R. and Henschke, Claudia I. and Hoffman, Eric A. and Kazerooni, Ella A. and MacMahon, Heber and Van Beek, Edwin J. R. and Yankelevitz, David and Biancardi, Anna M. and Bland, Paul H. and Brown, Martha S. and Engelmann, Robert M. and Laderach, Gregory E. and Max, David and Pais, Rosalia C. and Qing, Dan P. Y. and Roberts, Richard Y. and Smith, Andrew R. and Starkey, Adam and Batra, Prashant and Caligiuri, Philip and Farooqi, Aamer and Gladish, Gregory W. and Jude, Christopher M. and Munden, Reginald F. and Petkovska, Iva and Quint, Leland E. and Schwartz, Lawrence H. and Sundaram, Balaji and Dodd, Lori E. and Fenimore, Christopher and Gur, David and Petrick, Nicholas and Freymann, John and Kirby, Justin and Hughes, Bethany and Casteele, Arnaud Van and Gupte, Sachin and Sallam, Medhat and Heath, Michael D. and Kuhn, Michael H. and Dharaiya, Ekta and Burns, Ryan and Fryd, Deborah S. and Salganicoff, Marc and Anand, Vinay and Shreter, Uri and Vastagh, Gabor and Croft, Bryan Y. and Clarke, Laurence P.},
	year = {2015},
	doi = {10.7937/K9/TCIA.2015.LO9QL9SX},
	note = {Published: Dataset},
}

@misc{national_lung_screening_trial_research_team_data_2013,
	title = {Data from the {National} {Lung} {Screening} {Trial} ({NLST})},
	url = {https://doi.org/10.7937/TCIA.HMQ8-J677},
	publisher = {The Cancer Imaging Archive},
	author = {{National Lung Screening Trial Research Team}},
	year = {2013},
	doi = {10.7937/TCIA.HMQ8-J677},
	note = {Published: Dataset},
}

@article{saba_lung_2019,
	title = {Lung {Nodule} {Detection} based on {Ensemble} of {Hand} {Crafted} and {Deep} {Features}},
	volume = {43},
	abstract = {Lung cancer is considered as a deadliest disease worldwide due to which 1.76 million deaths occurred in the year 2018. Keeping in view its dreadful effect on humans, cancer detection at a premature stage is a more significant requirement to reduce the probability of mortality rate. This manuscript depicts an approach of finding lung nodule at an initial stage that comprises of three major phases: (1) lung nodule segmentation using Otsu threshold followed by morphological operation; (2) extraction of geometrical, texture and deep learning features for selecting optimal features; (3) The optimal features are fused serially for classification of lung nodule into two categories that is malignant and benign. The lung image database consortium image database resource initiative (LIDC-IDRI) is used for experimentation. The experimental outcomes show better performance of presented approach as compared with the existing methods.},
	number = {12},
	journal = {Journal of Medical Systems},
	author = {Saba, Tanzila and Sameh, Ahmed and Khan, Fatima and Shad, Shafqat Ali and Sharif, Muhammad},
	month = nov,
	year = {2019},
	pages = {332},
}

@article{ginneken_comparing_2010,
	title = {Comparing and combining algorithms for computer-aided detection of pulmonary nodules in computed tomography scans: {The} {ANODE09} study},
	volume = {14},
	issn = {1361-8415},
	url = {https://www.sciencedirect.com/science/article/pii/S1361841510000587},
	doi = {https://doi.org/10.1016/j.media.2010.05.005},
	abstract = {Numerous publications and commercial systems are available that deal with automatic detection of pulmonary nodules in thoracic computed tomography scans, but a comparative study where many systems are applied to the same data set has not yet been performed. This paper introduces ANODE09 ( http://anode09.isi.uu.nl), a database of 55 scans from a lung cancer screening program and a web-based framework for objective evaluation of nodule detection algorithms. Any team can upload results to facilitate benchmarking. The performance of six algorithms for which results are available are compared; five from academic groups and one commercially available system. A method to combine the output of multiple systems is proposed. Results show a substantial performance difference between algorithms, and demonstrate that combining the output of algorithms leads to marked performance improvements.},
	number = {6},
	journal = {Medical Image Analysis},
	author = {Ginneken, Bram van and Armato, Samuel G. and Hoop, Bartjan de and Vorst, Saskia van Amelsvoort-van de and Duindam, Thomas and Niemeijer, Meindert and Murphy, Keelin and Schilham, Arnold and Retico, Alessandra and Fantacci, Maria Evelina and Camarlinghi, Niccolò and Bagagli, Francesco and Gori, Ilaria and Hara, Takeshi and Fujita, Hiroshi and Gargano, Gianfranco and Bellotti, Roberto and Tangaro, Sabina and Bolaños, Lourdes and Carlo, Francesco De and Cerello, Piergiorgio and Cheran, Sorin Cristian and Torres, Ernesto Lopez and Prokop, Mathias},
	year = {2010},
	keywords = {Computed tomography, Computer-aided detection, Lung cancer, Lung nodules},
	pages = {707--722},
}

@article{agrawal_content-based_2022,
	title = {Content-based medical image retrieval system for lung diseases using deep {CNNs}},
	volume = {14},
	issn = {2511-2104, 2511-2112},
	url = {https://doi.org/10.1007/s41870-022-01007-7},
	doi = {10.1007/s41870-022-01007-7},
	abstract = {Content-based image retrieval (CBIR) systems are designed to retrieve images that are relevant, based on detailed analysis of latent image characteristics, thus eliminating the dependency of natural language tags, text descriptions, or keywords associated with the images. A CBIR system maintains high-level image visuals in the form of feature vectors, which the retrieval engine leverages for similarity-based matching and ranking for a given query image. In this paper, a CBIR system is proposed for the retrieval of medical images (CBMIR) for enabling the early detection and classification of lung diseases based on lung X-ray images. The proposed CBMIR system is built on the predictive power of deep neural models for the identification and classification of disease-specific features using transfer learning based models trained on standard COVID-19 Chest X-ray image datasets. Experimental evaluation on the standard dataset revealed that the proposed approach achieved an improvement of 49.71\% in terms of precision, averaging across various distance metrics. Also, an improvement of 26.55\% was observed in the area under precision-recall curve (AUPRC) values across all subclasses.},
	language = {en},
	number = {7},
	journal = {International Journal of Information Technology},
	author = {Agrawal, Shubham and Chowdhary, Aastha and Agarwala, Saurabh and Mayya, Veena and Kamath S., Sowmya},
	month = dec,
	year = {2022},
	pages = {3619--3627},
	file = {PDF:C\:\\Users\\janto\\Zotero\\storage\\X2XUXMU3\\Agrawal et al. - 2022 - Content-based medical image retrieval system for lung diseases using deep CNNs.pdf:application/pdf},
}

@article{singh_federated_2023,
	title = {Federated {Learning} to {Safeguard} {Patients} {Data}: {A} {Medical} {Image} {Retrieval} {Case}},
	volume = {7},
	issn = {2504-2289},
	url = {https://www.mdpi.com/2504-2289/7/1/18},
	doi = {10.3390/bdcc7010018},
	abstract = {Healthcare data are distributed and confidential, making it difficult to use centralized automatic diagnostic techniques. For example, different hospitals hold the electronic health records (EHRs) of different patient populations; however, transferring this data between hospitals is difficult due to the sensitive nature of the information. This presents a significant obstacle to the development of efficient and generalizable analytical methods that require a large amount of diverse Big Data. Federated learning allows multiple institutions to work together to develop a machine learning algorithm without sharing their data. We conducted a systematic study to analyze the current state of FL in the healthcare industry and explore both the limitations of this technology and its potential. Organizations share the parameters of their models with each other. This allows them to reap the benefits of a model developed with a richer data set while protecting the confidentiality of their data. Standard methods for large-scale machine learning, distributed optimization, and privacy-friendly data analytics need to be fundamentally rethought to address the new problems posed by training on diverse networks that may contain large amounts of data. In this article, we discuss the particular qualities and difficulties of federated learning, provide a comprehensive overview of current approaches, and outline several directions for future work that are relevant to a variety of research communities. These issues are important to many different research communities.},
	number = {1},
	journal = {Big Data and Cognitive Computing},
	author = {Singh, Gurtaj and Violi, Vincenzo and Fisichella, Marco},
	year = {2023},
}

@article{yaacob_application_2023,
	title = {Application of {Artificial} {Intelligence} {Techniques} for {Brain}–{Computer} {Interface} in {Mental} {Fatigue} {Detection}: {A} {Systematic} {Review} (2011–2022)},
	volume = {11},
	copyright = {https://creativecommons.org/licenses/by-nc-nd/4.0/},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/10185973/},
	doi = {10.1109/ACCESS.2023.3296382},
	language = {en},
	journal = {IEEE Access},
	author = {Yaacob, Hamwira and Hossain, Farhad and Shari, Sharunizam and Khare, Smith K. and Ooi, Chui Ping and Acharya, U. Rajendra},
	year = {2023},
	keywords = {Brain-computer interface (BCI), Brain-computer interfaces, Electrodes, electroencephalogram (EEG), Electroencephalography, Fatigue, Hardware, Mental disorders, mental fatigue detection, PRISMA, Sleep, Systematics},
	pages = {74736--74758},
	file = {PDF:C\:\\Users\\janto\\Zotero\\storage\\R2VPUS3L\\Yaacob et al. - 2023 - Application of Artificial Intelligence Techniques for Brain–Computer Interface in Mental Fatigue Det.pdf:application/pdf},
}

@misc{international_agency_for_research_on_cancer_trachea_2024,
	title = {Trachea, {Bronchus} and {Lung} {Cancer} {Fact} {Sheet}},
	url = {https://gco.iarc.who.int/media/globocan/factsheets/cancers/15-trachea-bronchus-and-lung-fact-sheet.pdf},
	author = {{International Agency for Research on Cancer}},
	year = {2024},
	file = {15-trachea-bronchus-and-lung-fact-sheet:C\:\\Users\\janto\\Zotero\\storage\\KMDX733D\\15-trachea-bronchus-and-lung-fact-sheet.pdf:application/pdf;Texto Completo:C\:\\Users\\janto\\Zotero\\storage\\L3SGXRK6\\Cancer - 2024 - Trachea, Bronchus and Lung Cancer Fact Sheet.pdf:application/pdf},
}

@article{shaffie_computer-assisted_2022,
	title = {Computer-assisted image processing system for early assessment of lung nodule malignancy},
	volume = {14},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2072-6694},
	url = {https://www.mdpi.com/2072-6694/14/5/1117},
	doi = {10.3390/cancers14051117},
	abstract = {Lung cancer is one of the most dreadful cancers, and its detection in the early stage is very important and challenging. This manuscript proposes a new computer-aided diagnosis system for lung cancer diagnosis from chest computed tomography scans. The proposed system extracts two different kinds of features, namely, appearance features and shape features. For the appearance features, a Histogram of oriented gradients, a Multi-view analytical Local Binary Pattern, and a Markov Gibbs Random Field are developed to give a good description of the lung nodule texture, which is one of the main distinguishing characteristics between benign and malignant nodules. For the shape features, Multi-view Peripheral Sum Curvature Scale Space, Spherical Harmonics Expansion, and a group of some fundamental morphological features are implemented to describe the outer contour complexity of the nodules, which is main factor in lung nodule diagnosis. Each feature is fed into a stacked auto-encoder followed by a soft-max classifier to generate the initial malignancy probability. Finally, all these probabilities are combined together and fed to the last network to give the final diagnosis. The system is validated using 727 nodules which are subset from the Lung Image Database Consortium (LIDC) dataset. The system shows very high performance measures and achieves 92.55\%, 91.70\%, and 93.40\% for the accuracy, sensitivity, and specificity, respectively. This high performance shows the ability of the system to distinguish between the malignant and benign nodules precisely.},
	language = {en},
	number = {5},
	journal = {Cancers (Basel)},
	author = {Shaffie, Ahmed and Soliman, Ahmed and Eledkawy, Amr and van Berkel, Victor and El-Baz, Ayman},
	month = feb,
	year = {2022},
	note = {Publisher: MDPI AG},
	keywords = {autoencoder, CSS, CT image, HOG, LBP, lung cancer, MGRF, spherical harmonics},
	pages = {1117},
	file = {PDF:C\:\\Users\\janto\\Zotero\\storage\\AGIK8VS3\\Shaffie et al. - 2022 - Computer-Assisted Image Processing System for Early Assessment of Lung Nodule Malignancy.pdf:application/pdf},
}

@article{alizadeh_novel_2023,
	title = {A novel {Siamese} deep hashing model for histopathology image retrieval},
	volume = {225},
	issn = {0957-4174},
	url = {https://www.sciencedirect.com/science/article/pii/S0957417423006711},
	doi = {https://doi.org/10.1016/j.eswa.2023.120169},
	abstract = {Content-based histopathology image retrieval can be a useful technique for help in diagnosing various diseases. The process of retrieving images is often time-consuming and challenging due to the need for high-dimensional features when trying to model complex content. Hashing methods can therefore be employed to resolve the challenge by producing binary codes of different lengths. Deep hashing methods are frequently superior to traditional machine learning approaches but are affected by the size of training sets. In addition, back-propagation learning can further complicate the generation of binary values. Hence, this paper proposes a novel Siamese deep hashing model, named histopathology Siamese deep hashing (HSDH), for histopathology image retrieval. Two designed deep hashing models with shared weights and structures are used to generate hash codes. A Hamming distance layer is then applied to evaluate the similarity of the generated values. A highly effective loss function is also introduced that incorporates a modified version of the standard contrastive loss function with an error estimation term to improve both the training and retrieval phases. In the retrieval phase, the trained model compares a query image with all the training images and ranks the most similar images. According to the experimental results on two publicly available databases, BreakHis and Kather, the HSDH model outperforms other state-of-the-art hashing-based methods in histopathology image retrieval.},
	language = {en},
	journal = {Expert Systems with Applications},
	author = {Alizadeh, Seyed Mohammad and Helfroush, Mohammad Sadegh and Müller, Henning},
	month = sep,
	year = {2023},
	keywords = {Convolutional neural networks, Deep hashing, Histopathology image retrieval, Pairwise similarity, Siamese networks},
	pages = {120169},
	file = {PDF:C\:\\Users\\janto\\Zotero\\storage\\YLIKAKWF\\Mohammad Alizadeh et al. - 2023 - A novel Siamese deep hashing model for histopathology image retrieval.pdf:application/pdf},
}

@article{wang_retccl_2023,
	title = {{RetCCL}: {Clustering}-guided contrastive learning for whole-slide image retrieval},
	volume = {83},
	issn = {1361-8415},
	url = {https://www.sciencedirect.com/science/article/pii/S1361841522002730},
	doi = {https://doi.org/10.1016/j.media.2022.102645},
	abstract = {Benefiting from the large-scale archiving of digitized whole-slide images (WSIs), computer-aided diagnosis has been well developed to assist pathologists in decision-making. Content-based WSI retrieval can be a new approach to find highly correlated WSIs in a historically diagnosed WSI archive, which has the potential usages for assisted clinical diagnosis, medical research, and trainee education. During WSI retrieval, it is particularly challenging to encode the semantic content of histopathological images and to measure the similarity between images for interpretable results due to the gigapixel size of WSIs. In this work, we propose a Retrieval with Clustering-guided Contrastive Learning (RetCCL) framework for robust and accurate WSI-level image retrieval, which integrates a novel self-supervised feature learning method and a global ranking and aggregation algorithm for much improved performance. The proposed feature learning method makes use of existing large-scale unlabeled histopathological image data, which helps learn universal features that could be used directly for subsequent WSI retrieval tasks without extra fine-tuning. The proposed WSI retrieval method not only returns a set of WSIs similar to a query WSI, but also highlights patches or sub-regions of each WSI that share high similarity with patches of the query WSI, which helps pathologists interpret the searching results. Our WSI retrieval framework has been evaluated on the tasks of anatomical site retrieval and cancer subtype retrieval using over 22,000 slides, and the performance exceeds other state-of-the-art methods significantly (around 10\% for the anatomic site retrieval in terms of average mMV@10). Besides, the patch retrieval using our learned feature representation offers a performance improvement of 24\% on the TissueNet dataset in terms of mMV@5 compared with using ImageNet pre-trained features, which further demonstrates the effectiveness of the proposed CCL feature learning method.},
	journal = {Medical Image Analysis},
	author = {Wang, Xiyue and Du, Yuexi and Yang, Sen and Zhang, Jun and Wang, Minghui and Zhang, Jing and Yang, Wei and Huang, Junzhou and Han, Xiao},
	year = {2023},
	keywords = {Feature extraction, Histopathology, Image retrieval, Self-supervised learning},
	pages = {102645},
}

@article{shaffie_generalized_2018,
	title = {A {Generalized} {Deep} {Learning}-{Based} {Diagnostic} {System} for {Early} {Diagnosis} of {Various} {Types} of {Pulmonary} {Nodules}},
	volume = {17},
	issn = {1533-0346, 1533-0338},
	url = {https://journals.sagepub.com/doi/10.1177/1533033818798800},
	doi = {10.1177/1533033818798800},
	abstract = {A novel framework for the classification of lung nodules using computed tomography scans is proposed in this article. To get an accurate diagnosis of the detected lung nodules, the proposed framework integrates the following 2 groups of features: (1) appearance features modeled using the higher order Markov Gibbs random field model that has the ability to describe the spatial inhomogeneities inside the lung nodule and (2) geometric features that describe the shape geometry of the lung nodules. The novelty of this article is to accurately model the appearance of the detected lung nodules using a new developed seventhorder Markov Gibbs random field model that has the ability to model the existing spatial inhomogeneities for both small and large detected lung nodules, in addition to the integration with the extracted geometric features. Finally, a deep autoencoder classifier is fed by the above 2 feature groups to distinguish between the malignant and benign nodules. To evaluate the proposed framework, we used the publicly available data from the Lung Image Database Consortium. We used a total of 727 nodules that were collected from 467 patients. The proposed system demonstrates the promise to be a valuable tool for the detection of lung cancer evidenced by achieving a nodule classification accuracy of 91.20\%.},
	language = {en},
	urldate = {2025-02-04},
	journal = {Technol. Cancer Res. Treat.},
	author = {Shaffie, Ahmed and Soliman, Ahmed and Fraiwan, Luay and Ghazal, Mohammed and Taher, Fatma and Dunlap, Neal and Wang, Brian and Van Berkel, Victor and Keynton, Robert and Elmaghraby, Adel and El-Baz, Ayman},
	month = jan,
	year = {2018},
	note = {Publisher: SAGE Publications},
	keywords = {autoencoder, computed tomography, computer-aided diagnosis, higher order MGRF, lung cancer, pulmonary nodule},
	pages = {1533033818798800},
	file = {PDF:C\:\\Users\\janto\\Zotero\\storage\\6MPUHLZ4\\Shaffie et al. - 2018 - A Generalized Deep Learning-Based Diagnostic System for Early Diagnosis of Various Types of Pulmonar.pdf:application/pdf},
}

@article{sanjeevaiah_k_content-based_2023,
	title = {Content-{Based} {Image} {Retrieval} {Using} {Hybrid} {Densenet121}-{Bilstm} and {Harris} {Hawks} {Optimization} {Algorithm}},
	volume = {11},
	copyright = {http://creativecommons.org/licenses/by/3.0/deed.en\_US},
	issn = {2166-7160, 2166-7179},
	shorttitle = {Content-{Based} {Image} {Retrieval} {Using} {Hybrid} {Densenet121}-{Bilstm} and {Harris} {Hawks} {Optimization} {Algorithm}},
	url = {https://services.igi-global.com/resolvedoi/resolve.aspx?doi=10.4018/IJSI.315661},
	doi = {10.4018/IJSI.315661},
	abstract = {In the field of digital data management, content-based image retrieval (CBIR) has become one of the most important research areas, and it is used in many fields. This system searches a database of images to retrieve most visually comparable photos to a query image. It is based on features derived directly from the image data, rather than on keywords or annotations. Currently, deep learning approaches have demonstrated a strong interest in picture recognition, particularly in extracting information about the features of the image. Therefore, a Densenet-121 is employed in this work to extract high-level and deep characteristics from the images. Afterwards, the training images are retrieved from the dataset and compared to the query image using a Bidirectional LSTM (BiLSTM) classifier to obtain the relevant images. The investigations are conducted using a publicly available dataset named Corel, and the f-measure, recall, and precision metrics are used for performance assessment. Investigation outcomes show that the proposed technique outperforms the existing image retrieval techniques.},
	language = {en},
	number = {1},
	urldate = {2025-02-04},
	journal = {International Journal of Software Innovation},
	author = {{Sanjeevaiah K.} and Reddy, Tatireddy Subba and Karthik, Sajja and Kumar, Mahesh and {Vivek D.}},
	month = jan,
	year = {2023},
	pages = {1--15},
	file = {PDF:C\:\\Users\\janto\\Zotero\\storage\\M5E65VK8\\Sanjeevaiah K. et al. - 2022 - Content-Based Image Retrieval Using Hybrid Densenet121-Bilstm and Harris Hawks Optimization Algorith.pdf:application/pdf},
}

@article{nasrullah_automated_2019,
	title = {Automated {Lung} {Nodule} {Detection} and {Classification} {Using} {Deep} {Learning} {Combined} with {Multiple} {Strategies}},
	volume = {19},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1424-8220},
	url = {https://pubmed.ncbi.nlm.nih.gov/31466261/},
	doi = {10.3390/s19173722},
	abstract = {Lung cancer is one of the major causes of cancer-related deaths due to its aggressive nature and delayed detections at advanced stages. Early detection of lung cancer is very important for the survival of an individual, and is a signiﬁcant challenging problem. Generally, chest radiographs (X-ray) and computed tomography (CT) scans are used initially for the diagnosis of the malignant nodules; however, the possible existence of benign nodules leads to erroneous decisions. At early stages, the benign and the malignant nodules show very close resemblance to each other. In this paper, a novel deep learning-based model with multiple strategies is proposed for the precise diagnosis of the malignant nodules. Due to the recent achievements of deep convolutional neural networks (CNN) in image analysis, we have used two deep three-dimensional (3D) customized mixed link network (CMixNet) architectures for lung nodule detection and classiﬁcation, respectively. Nodule detections were performed through faster R-CNN on eﬃciently-learned features from CMixNet and U-Net like encoder–decoder architecture. Classiﬁcation of the nodules was performed through a gradient boosting machine (GBM) on the learned features from the designed 3D CMixNet structure. To reduce false positives and misdiagnosis results due to diﬀerent types of errors, the ﬁnal decision was performed in connection with physiological symptoms and clinical biomarkers. With the advent of the internet of things (IoT) and electro-medical technology, wireless body area networks (WBANs) provide continuous monitoring of patients, which helps in diagnosis of chronic diseases—especially metastatic cancers. The deep learning model for nodules’ detection and classiﬁcation, combined with clinical factors, helps in the reduction of misdiagnosis and false positive (FP) results in early-stage lung cancer diagnosis. The proposed system was evaluated on LIDC-IDRI datasets in the form of sensitivity (94\%) and speciﬁcity (91\%), and better results were obatined compared to the existing methods.},
	language = {en},
	number = {17},
	urldate = {2025-02-04},
	journal = {Sensors (Basel, Switzerland)},
	author = {Nasrullah, Nasrullah and Sang, Jun and Alam, Mohammad S. and Mateen, Muhammad and Cai, Bin and Hu, Haibo},
	month = aug,
	year = {2019},
	keywords = {*Diagnosis, *Wireless Technology, Computer, Computer-Assisted, Computer-Assisted/methods, Databases, Deep Learning, Early Detection of Cancer, Factual, Humans, Image Processing, Internet of Things, Lung Neoplasms/*diagnosis/diagnostic imaging/pathology, Lung/diagnostic imaging/physiology, Neoplasms/*diagnosis/diagnostic imaging/pathology, Neural Networks, Radiographic Image Interpretation, Tomography, X-Ray Computed},
	pages = {3722},
	file = {PDF:C\:\\Users\\janto\\Zotero\\storage\\L48A8M3J\\Nasrullah et al. - 2019 - Automated Lung Nodule Detection and Classification Using Deep Learning Combined with Multiple Strate.pdf:application/pdf},
}

@article{yuan_multi-modal_2023,
	title = {Multi-{Modal} {Feature} {Fusion}-{Based} {Multi}-{Branch} {Classification} {Network} for {Pulmonary} {Nodule} {Malignancy} {Suspiciousness} {Diagnosis}},
	volume = {36},
	issn = {1618-727X},
	url = {https://doi.org/10.1007/s10278-022-00747-z},
	doi = {10.1007/s10278-022-00747-z},
	abstract = {Detecting and identifying malignant nodules on chest computed tomography (CT) plays an important role in the early diagnosis and timely treatment of lung cancer, which can greatly reduce the number of deaths worldwide. In view of the existing methods in pulmonary nodule diagnosis, the importance of clinical radiological structured data (laboratory examination, radiological data) is ignored for the accuracy judgment of patients’ condition. Hence, a multi-modal fusion multi-branch classification network is constructed to detect and classify pulmonary nodules in this work: (1) Radiological data of pulmonary nodules are used to construct structured features of length 9. (2) A multi-branch fusion-based effective attention mechanism network is designed for 3D CT Patch unstructured data, which uses 3D ECA-ResNet to dynamically adjust the extracted features. In addition, feature maps with different receptive fields from multi-layer are fully fused to obtain representative multi-scale unstructured features. (3) Multi-modal feature fusion of structured data and unstructured data is performed to distinguish benign and malignant nodules. Numerous experimental results show that this advanced network can effectively classify the benign and malignant pulmonary nodules for clinical diagnosis, which achieves the highest accuracy (94.89\%), sensitivity (94.91\%), and F1-score (94.65\%) and lowest false positive rate (5.55\%).},
	language = {en},
	number = {2},
	journal = {Journal of Digital Imaging},
	author = {Yuan, Haiying and Wu, Yanrui and Dai, Mengfan},
	month = apr,
	year = {2023},
	pages = {617--626},
	file = {PDF:C\:\\Users\\janto\\Zotero\\storage\\HX4M7Z3A\\Yuan et al. - 2023 - Multi-Modal Feature Fusion-Based Multi-Branch Classification Network for Pulmonary Nodule Malignancy.pdf:application/pdf},
}

@article{survarachakan_deep_2022,
	title = {Deep learning for image-based liver analysis — {A} comprehensive review focusing on malignant lesions},
	volume = {130},
	issn = {0933-3657},
	url = {https://www.sciencedirect.com/science/article/pii/S0933365722000963},
	doi = {https://doi.org/10.1016/j.artmed.2022.102331},
	abstract = {Deep learning-based methods, in particular, convolutional neural networks and fully convolutional networks are now widely used in the medical image analysis domain. The scope of this review focuses on the analysis using deep learning of focal liver lesions, with a special interest in hepatocellular carcinoma and metastatic cancer; and structures like the parenchyma or the vascular system. Here, we address several neural network architectures used for analyzing the anatomical structures and lesions in the liver from various imaging modalities such as computed tomography, magnetic resonance imaging and ultrasound. Image analysis tasks like segmentation, object detection and classification for the liver, liver vessels and liver lesions are discussed. Based on the qualitative search, 91 papers were filtered out for the survey, including journal publications and conference proceedings. The papers reviewed in this work are grouped into eight categories based on the methodologies used. By comparing the evaluation metrics, hybrid models performed better for both the liver and the lesion segmentation tasks, ensemble classifiers performed better for the vessel segmentation tasks and combined approach performed better for both the lesion classification and detection tasks. The performance was measured based on the Dice score for the segmentation, and accuracy for the classification and detection tasks, which are the most commonly used metrics.},
	language = {en},
	urldate = {2025-02-04},
	journal = {Artificial Intelligence in Medicine},
	author = {Survarachakan, Shanmugapriya and Prasad, Pravda Jith Ray and Naseem, Rabia and Pérez De Frutos, Javier and Kumar, Rahul Prasanna and Langø, Thomas and Alaya Cheikh, Faouzi and Elle, Ole Jakob and Lindseth, Frank},
	month = aug,
	year = {2022},
	keywords = {Deep-learning, Hepatic vessels, Lesions, Liver, Segmentation},
	pages = {102331},
	file = {PDF:C\:\\Users\\janto\\Zotero\\storage\\524ABR4R\\Survarachakan et al. - 2022 - Deep learning for image-based liver analysis — A comprehensive review focusing on malignant lesions.pdf:application/pdf},
}

@article{yang_deep_2020,
	title = {A deep metric learning approach for histopathological image retrieval},
	volume = {179},
	issn = {1046-2023},
	url = {https://www.sciencedirect.com/science/article/pii/S1046202320300815},
	doi = {https://doi.org/10.1016/j.ymeth.2020.05.015},
	abstract = {To distinguish ambiguous images during specimen slides viewing, pathologists usually spend lots of time to seek guidance from conﬁrmed similar images or cases, which is ineﬃcient. Therefore, several histopathological image retrieval methods have been proposed for pathologists to easily obtain images sharing similar content with the query images. However, these methods cannot ensure a reasonable similarity metric, and some of them need lots of annotated images to train a feature extractor to represent images. Motivated by this circumstance, we propose the ﬁrst deep metric learning-based histopathological image retrieval method in this paper and construct a deep neural network based on the mixed attention mechanism to learn an embedding function under the supervision of image category information. With the learned embedding function, original images are mapped into the predeﬁned metric space where similar images from the same category are close to each other, so that the distance between image pairs in the metric space can be regarded as a reasonable metric for image similarity. We evaluate the proposed method on two histopathological image retrieval datasets: our self-established dataset and a public dataset called Kimia Path24, on which the proposed method achieves recall in top-1 recommendation (Recall@1) of 84.04\% and 97.89\% respectively. Moreover, further experiments conﬁrm that the proposed method can achieve comparable performance to several published methods with less training data, which hedges the shortage of annotated medical image data to some extent. Code is available at https://github.com/ easonyang1996/DML\_HistoImgRetrieval.},
	language = {en},
	urldate = {2025-02-04},
	journal = {Methods},
	author = {Yang, Pengshuai and Zhai, Yupeng and Li, Lin and Lv, Hairong and Wang, Jigang and Zhu, Chengzhan and Jiang, Rui},
	month = jul,
	year = {2020},
	keywords = {Content base image retrieval, Deep metric learning, Histopathological image analysis},
	pages = {14--25},
	file = {PDF:C\:\\Users\\janto\\Zotero\\storage\\KTT6JBJ9\\Yang et al. - 2020 - A deep metric learning approach for histopathological image retrieval.pdf:application/pdf},
}

@article{sohan_systematic_2023,
	title = {A {Systematic} {Review} on {Federated} {Learning} in {Medical} {Image} {Analysis}},
	volume = {11},
	copyright = {https://creativecommons.org/licenses/by/4.0/legalcode},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/10077569/},
	doi = {10.1109/ACCESS.2023.3260027},
	abstract = {Federated Learning (FL) obtained a lot of attention to the academic and industrial stakeholders from the beginning of its invention. The eye-catching feature of FL is handling data in a decentralized manner which creates a privacy preserving environment in Artificial Intelligence (AI) applications. As we know medical data includes marginal private information of patients which demands excessive data protection from disclosure to unexpected destinations. In this paper, we performed a Systematic Literature Review (SLR) of published research articles on FL based medical image analysis. Firstly, we have collected articles from different databases followed by PRISMA guidelines, then synthesized data from the selected articles, and finally we provided a comprehensive overview on the topic. In order to do that we extracted core information associated with the implementation of FL in medical imaging from the articles. In our findings we briefly presented characteristics of federated data and models, performance achieved by the models and exclusively results comparison with traditional ML models. In addition, we discussed the open issues and challenges of implementing FL and mentioned our recommendations for future direction of this particular research field. We believe this SLR has successfully summarized the state-of-the-art FL methods for medical image analysis using deep learning.},
	language = {en},
	urldate = {2025-02-04},
	journal = {IEEE Access},
	author = {Sohan, Md Fahimuzzman and Basalamah, Anas},
	year = {2023},
	keywords = {Biomedical imaging, Data models, data privacy, Federated learning, Hospitals, Image analysis, machine learning, Medical diagnostic imaging, medical image analysis, Servers, systematic literature review, Task analysis},
	pages = {28628--28644},
	file = {PDF:C\:\\Users\\janto\\Zotero\\storage\\D9J9TJ2C\\Sohan e Basalamah - 2023 - A Systematic Review on Federated Learning in Medical Image Analysis.pdf:application/pdf},
}

@article{masood_automated_2020,
	title = {Automated {Decision} {Support} {System} for {Lung} {Cancer} {Detection} and {Classification} via {Enhanced} {RFCN} {With} {Multilayer} {Fusion} {RPN}},
	volume = {16},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {1551-3203, 1941-0050},
	url = {https://ieeexplore.ieee.org/document/9006938/},
	doi = {10.1109/TII.2020.2972918},
	abstract = {Detection of lung cancer at early stages is critical, in most of the cases radiologists read computed tomography (CT) images to prescribe follow-up treatment. The conventional method for detecting nodule presence in CT images is tedious. In this article, we propose an enhanced multidimensional region-based fully convolutional network (mRFCN) based automated decision support system for lung nodule detection and classiﬁcation. The mRFCN is used as an image classiﬁer backbone for feature extraction along with the novel multilayer fusion region proposal network (mLRPN) with position-sensitive score maps being explored. We applied a median intensity projection to leverage three-dimensional information from CT scans and introduced deconvolutional layer to adopt proposed mLRPN in our architecture to automatically select the potential region of interest. Our system has been trained and evaluated using LIDC dataset, and the experimental results showed promising detection performance in comparison to the state-of-the-art nodule detection/classiﬁcation methods, achieving a sensitivity of 98.1\% and classiﬁcation accuracy of 97.91\%.},
	language = {en},
	number = {12},
	urldate = {2025-02-04},
	journal = {IEEE Transactions on Industrial Informatics},
	author = {Masood, Anum and Sheng, Bin and Yang, Po and Li, Ping and Li, Huating and Kim, Jinman and Feng, David Dagan},
	month = dec,
	year = {2020},
	keywords = {Cancer, Computed tomography, Computer-aided systems, convolutional neural network (CNN), Feature extraction, Informatics, Lung, lung cancer, nodule classification, Proposals, Training},
	pages = {7791--7801},
	file = {PDF:C\:\\Users\\janto\\Zotero\\storage\\C6ED7GVG\\Masood et al. - 2020 - Automated Decision Support System for Lung Cancer Detection and Classification via Enhanced RFCN Wit.pdf:application/pdf},
}

@article{sousa_single_2023,
	title = {Single {Modality} vs. {Multimodality}: {What} {Works} {Best} for {Lung} {Cancer} {Screening}?},
	volume = {23},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1424-8220},
	shorttitle = {Single {Modality} vs. {Multimodality}},
	url = {https://www.mdpi.com/1424-8220/23/12/5597},
	doi = {10.3390/s23125597},
	abstract = {In a clinical context, physicians usually take into account information from more than one data modality when making decisions regarding cancer diagnosis and treatment planning. Artiﬁcial intelligence-based methods should mimic the clinical method and take into consideration different sources of data that allow a more comprehensive analysis of the patient and, as a consequence, a more accurate diagnosis. Lung cancer evaluation, in particular, can beneﬁt from this approach since this pathology presents high mortality rates due to its late diagnosis. However, many related works make use of a single data source, namely imaging data. Therefore, this work aims to study the prediction of lung cancer when using more than one data modality. The National Lung Screening Trial dataset that contains data from different sources, speciﬁcally, computed tomography (CT) scans and clinical data, was used for the study, the development and comparison of single-modality and multimodality models, that may explore the predictive capability of these two types of data to their full potential. A ResNet18 network was trained to classify 3D CT nodule regions of interest (ROI), whereas a random forest algorithm was used to classify the clinical data, with the former achieving an area under the ROC curve (AUC) of 0.7897 and the latter 0.5241. Regarding the multimodality approaches, three strategies, based on intermediate and late fusion, were implemented to combine the information from the 3D CT nodule ROIs and the clinical data. From those, the best model—a fully connected layer that receives as input a combination of clinical data and deep imaging features, given by a ResNet18 inference model—presented an AUC of 0.8021. Lung cancer is a complex disease, characterized by a multitude of biological and physiological phenomena and inﬂuenced by multiple factors. It is thus imperative that the models are capable of responding to that need. The results obtained showed that the combination of different types may have the potential to produce more comprehensive analyses of the disease by the models.},
	language = {en},
	number = {12},
	urldate = {2025-02-04},
	journal = {Sensors},
	author = {Sousa, Joana Vale and Matos, Pedro and Silva, Francisco and Freitas, Pedro and Oliveira, Hélder P. and Pereira, Tania},
	month = jun,
	year = {2023},
	pages = {5597},
	file = {PDF:C\:\\Users\\janto\\Zotero\\storage\\MSW5QYPN\\Sousa et al. - 2023 - Single Modality vs. Multimodality What Works Best for Lung Cancer Screening.pdf:application/pdf},
}

@article{lin_radiomics_2022,
	title = {A radiomics approach for lung nodule detection in thoracic {CT} images based on the dynamic patterns of morphological variation},
	volume = {32},
	issn = {1432-1084},
	url = {https://doi.org/10.1007/s00330-021-08456-x},
	doi = {10.1007/s00330-021-08456-x},
	abstract = {To propose and evaluate a set of radiomic features, called morphological dynamics features, for pulmonary nodule detection, which were rooted in the dynamic patterns of morphological variation and needless precise lesion segmentation.},
	language = {en},
	number = {6},
	urldate = {2025-02-04},
	journal = {European Radiology},
	author = {Lin, Fan-Ya and Chang, Yeun-Chung and Huang, Hsuan-Yu and Li, Chia-Chen and Chen, Yi-Chang and Chen, Chung-Ming},
	month = jun,
	year = {2022},
	keywords = {Deep learning, Lung, Machine learning, Multiple pulmonary nodules, X-ray computed tomography},
	pages = {3767--3777},
	file = {Full Text PDF:C\:\\Users\\janto\\Zotero\\storage\\FGQPAIQP\\Lin et al. - 2022 - A radiomics approach for lung nodule detection in thoracic CT images based on the dynamic patterns o.pdf:application/pdf},
}

@article{ali_deep_2021,
	title = {Deep {Feature} {Selection} and {Decision} {Level} {Fusion} for {Lungs} {Nodule} {Classification}},
	volume = {9},
	copyright = {https://creativecommons.org/licenses/by/4.0/legalcode},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/9335996/},
	doi = {10.1109/ACCESS.2021.3054735},
	language = {en},
	journal = {IEEE Access},
	author = {Ali, Imdad and Muzammil, Muhammad and Haq, Ihsan Ul and Amir, Muhammad and Abdullah, Suheel},
	year = {2021},
	keywords = {AdaBoostM2, biomedical image processing, Computed tomography, computer aided diagnosis, deep convolutional neural network, deep features, DICOM, Feature extraction, Lung, Lung cancer, lung nodule, LUNGx challenge, Solid model..., Solid modeling, support vector machine, Support vector machines},
	pages = {18962--18973},
	file = {PDF:C\:\\Users\\janto\\Zotero\\storage\\TB639G37\\Ali et al. - 2021 - Deep Feature Selection and Decision Level Fusion for Lungs Nodule Classification.pdf:application/pdf},
}

@article{muzammil_pulmonary_2021,
	title = {Pulmonary {Nodule} {Classification} {Using} {Feature} and {Ensemble} {Learning}-{Based} {Fusion} {Techniques}},
	volume = {9},
	copyright = {https://creativecommons.org/licenses/by/4.0/legalcode},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/9507437/},
	doi = {10.1109/ACCESS.2021.3102707},
	language = {en},
	journal = {IEEE Access},
	author = {Muzammil, Muhammad and Ali, Imdad and Haq, Ihsan Ul and Amir, Muhammad and Abdullah, Suheel},
	year = {2021},
	keywords = {Cancer, computed tomography, Computed tomography, computer aided diagnosis, Dee..., Deep convolutional neural network, deep feature fusion, deep features, ensemble learner, Feature extraction, LUNA16 challenge, Lung, Lung cancer, nodule classification, pulmonary nodule, support vector machine, Support vector machines, Tumors},
	pages = {113415--113427},
	file = {PDF:C\:\\Users\\janto\\Zotero\\storage\\LPK26Y2U\\Muzammil et al. - 2021 - Pulmonary Nodule Classification Using Feature and Ensemble Learning-Based Fusion Techniques.pdf:application/pdf},
}

@article{avola_multimodal_2022,
	title = {Multimodal {Feature} {Fusion} and {Knowledge}-{Driven} {Learning} via {Experts} {Consult} for {Thyroid} {Nodule} {Classification}},
	volume = {32},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {1051-8215, 1558-2205},
	url = {https://ieeexplore.ieee.org/document/9409170/},
	doi = {10.1109/TCSVT.2021.3074414},
	language = {en},
	number = {5},
	journal = {IEEE Transactions on Circuits and Systems for Video Technology},
	author = {Avola, Danilo and Cinque, Luigi and Fagioli, Alessio and Filetti, Sebastiano and Grani, Giorgio and Rodolà, Emanuele},
	month = may,
	year = {2022},
	keywords = {computer-aided diagnosis, deep learning, Discrete wavelet transforms, ensemble learning, feature fusion, Knowledge engineering, Medical diagnostic ima..., Medical diagnostic imaging, Neural networks, Task analysis, Thyroid, Thyroid nodule classification, Training, transfer learning},
	pages = {2527--2534},
	file = {PDF:C\:\\Users\\janto\\Zotero\\storage\\RLHZH3QS\\Avola et al. - 2022 - Multimodal Feature Fusion and Knowledge-Driven Learning via Experts Consult for Thyroid Nodule Class.pdf:application/pdf;Versão Submetida:C\:\\Users\\janto\\Zotero\\storage\\55RG9KUU\\Avola et al. - 2022 - Multimodal Feature Fusion and Knowledge-Driven Learning via Experts Consult for Thyroid Nodule Class.pdf:application/pdf},
}

@article{saihood_multi-orientation_2023,
	title = {Multi-{Orientation} {Local} {Texture} {Features} for {Guided} {Attention}-{Based} {Fusion} in {Lung} {Nodule} {Classification}},
	volume = {11},
	copyright = {https://creativecommons.org/licenses/by-nc-nd/4.0/},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/10046305/},
	doi = {10.1109/ACCESS.2023.3243104},
	language = {en},
	journal = {IEEE Access},
	author = {Saihood, Ahmed and Karshenas, Hossein and Naghsh-Nilchi, Ahmad Reza},
	year = {2023},
	keywords = {Cancer, co-occurrence pattern, Computed tomography, Data mining, Data mining..., Deep learning, Feature extraction, long-range dependency, Lung cancer classification, Lungs, non-local guided attention, Recurrent neural networks, texture feature descriptor, Three-dimensional displays},
	pages = {17555--17568},
	file = {PDF:C\:\\Users\\janto\\Zotero\\storage\\9C67PIA7\\Saihood et al. - 2023 - Multi-Orientation Local Texture Features for Guided Attention-Based Fusion in Lung Nodule Classifica.pdf:application/pdf},
}

@article{ali_efficient_2020,
	title = {Efficient {Lung} {Nodule} {Classification} {Using} {Transferable} {Texture} {Convolutional} {Neural} {Network}},
	volume = {8},
	copyright = {https://creativecommons.org/licenses/by/4.0/legalcode},
	url = {https://ieeexplore.ieee.org/document/9204580/},
	doi = {10.1109/ACCESS.2020.3026080},
	language = {en},
	journal = {IEEE Access},
	author = {Ali, Imdad and Muzammil, Muhammad and Haq, Ihsan Ul and Amir, Muhammad and Abdullah, Suheel},
	year = {2020},
	keywords = {Biomedical imaging, Cancer, cancer detection, CNN, Com..., Computed tomography, computer aided diagnosis, Databases, Feature extraction, image classification, LIDC-IDRI, Lung, lung nodule, LUNGx challenge, machine learning, Task analysis, transfer learning},
	pages = {175859--175870},
	file = {PDF:C\:\\Users\\janto\\Zotero\\storage\\FK5HU8Y5\\Ali et al. - 2020 - Efficient Lung Nodule Classification Using Transferable Texture Convolutional Neural Network.pdf:application/pdf},
}

@article{halder_lung_2020,
	title = {Lung {Nodule} {Detection} from {Feature} {Engineering} to {Deep} {Learning} in {Thoracic} {CT} {Images}: a {Comprehensive} {Review}},
	volume = {33},
	issn = {1618-727X},
	url = {https://doi.org/10.1007/s10278-020-00320-6},
	doi = {10.1007/s10278-020-00320-6},
	abstract = {This paper presents a systematic review of the literature focused on the lung nodule detection in chest computed tomography (CT) images. Manual detection of lung nodules by the radiologist is a sequential and time-consuming process. The detection is subjective and depends on the radiologist’s experiences. Owing to the variation in shapes and appearances of a lung nodule, it is very difficult to identify the proper location of the nodule from a huge number of slices generated by the CT scanner. Small nodules ({\textless}10mm in diameter) may be missed by this manual detection process. Therefore, computer-aided diagnosis (CAD) system acts as a “second opinion” for the radiologists, by making final decision quickly with higher accuracy and greater confidence. The goal of this survey work is to present the current state of the artworks and their progress towards lung nodule detection to the researchers and readers in this domain. This review paper has covered the published works from 2009 to April 2018. Different nodule detection approaches are described elaborately in this work. Recently, it is observed that deep learning (DL)-based approaches are applied extensively for nodule detection and characterization. Therefore, emphasis has been given to convolutional neural network (CNN)-based DL approaches by describing different CNN-based networks.},
	language = {en},
	number = {3},
	journal = {Journal of Digital Imaging},
	author = {Halder, Amitava and Dey, Debangshu and Sadhu, Anup K.},
	month = jun,
	year = {2020},
	pages = {655--677},
	file = {PDF:C\:\\Users\\janto\\Zotero\\storage\\SYXAG9EH\\Halder et al. - 2020 - Lung Nodule Detection from Feature Engineering to Deep Learning in Thoracic CT Images a Comprehensi.pdf:application/pdf},
}

@article{li_research_2022,
	title = {Research on lung nodule recognition algorithm based on deep feature fusion and {MKL}-{SVM}-{IPSO}},
	volume = {12},
	issn = {2045-2322},
	url = {https://doi.org/10.1038/s41598-022-22442-3},
	doi = {10.1038/s41598-022-22442-3},
	abstract = {Lung CAD system can provide auxiliary third-party opinions for doctors, improve the accuracy of lung nodule recognition. The selection and fusion of nodule features and the advancement of recognition algorithms are crucial improving lung CAD systems. Based on the HDL model, this paper mainly focuses on the three key algorithms of feature extraction, feature fusion and nodule recognition of lung CAD system. First, CBAM is embedded into VGG16 and VGG19, and feature extraction models AE-VGG16 and AE-VGG19 are constructed, so that the network can pay more attention to the key feature information in nodule description. Then, feature dimensionality reduction based on PCA and feature fusion based on CCA are sequentially performed on the extracted depth features to obtain low-dimensional fusion features. Finally, the fusion features are input into the proposed MKL-SVM-IPSO model based on the improved Particle Swarm Optimization algorithm to speed up the training speed, get the global optimal parameter group. The public dataset LUNA16 was selected for the experiment. The results show that the accuracy of lung nodule recognition of the proposed lung CAD system can reach 99.56\%, and the sensitivity and F1-score can reach 99.3\% and 0.9965, respectively, which can reduce the possibility of false detection and missed detection of nodules.},
	language = {en},
	number = {1},
	journal = {Scientific Reports},
	author = {Li, Yang and Zheng, Hewei and Huang, Xiaoyu and Chang, Jiayue and Hou, Debiao and Lu, Huimin},
	month = oct,
	year = {2022},
	pages = {17403},
	file = {Full Text PDF:C\:\\Users\\janto\\Zotero\\storage\\3TMBTGMC\\Li et al. - 2022 - Research on lung nodule recognition algorithm based on deep feature fusion and MKL-SVM-IPSO.pdf:application/pdf},
}

@article{liu_artificial_2022,
	title = {Artificial {Intelligence} ({AI}) for {Lung} {Nodules}, {From} the {AJR} {Special} {Series} on {AI} {Applications}},
	volume = {219},
	issn = {0361-803X, 1546-3141},
	url = {https://doi.org/10.2214/AJR.22.27487},
	doi = {10.2214/AJR.22.27487},
	abstract = {Please see the Editorial Comment by Vicky Goh discussing this article. Interest in artificial intelligence (AI) applications for lung nodules continues to grow among radiologists, particularly with the expanding eligibility criteria and clinical utilization of lung cancer screening CT. AI has been heavily investigated for detecting and characterizing lung nodules and for guiding prognostic assessment. AI tools have also been used for image postprocessing (e.g., rib suppression on radiography or vessel suppression on CT) and for noninterpretive aspects of reporting and workflow, including management of nodule follow-up. Despite growing interest in and rapid development of AI tools and FDA approval of AI tools for pulmonary nodule evaluation, integration into clinical practice has been limited. Challenges to clinical adoption have included concerns about generalizability, regulatory issues, technical hurdles in implementation, and human skepticism. Further validation of AI tools for clinical use and demonstration of benefit in terms of patient-oriented outcomes also are needed. This article provides an overview of potential applications of AI tools in the imaging evaluation of lung nodules and discusses the challenges faced by practices interested in clinical implementation of such tools.},
	language = {en},
	number = {5},
	journal = {American Journal of Roentgenology},
	author = {Liu, Jonathan A. and Yang, Issac Y. and Tsai, Emily B.},
	month = nov,
	year = {2022},
	pmid = {35544377},
	pages = {703--712},
	file = {PDF:C\:\\Users\\janto\\Zotero\\storage\\MGKDQ4YJ\\Liu et al. - 2022 - Artificial Intelligence (AI) for Lung Nodules, From the AJR Special Series on AI Applications.pdf:application/pdf},
}

@article{liu_study_2022,
	title = {Study on the {Prediction} {Method} of {Long}-term {Benign} and {Malignant} {Pulmonary} {Lesions} {Based} on {LSTM}},
	volume = {10},
	issn = {2296-4185},
	url = {https://www.frontiersin.org/articles/10.3389/fbioe.2022.791424/full},
	doi = {10.3389/fbioe.2022.791424},
	abstract = {In order to more accurately and comprehensively characterize the changes and development rules of lesion characteristics in pulmonary medical images in different periods, the study was conducted to predict the evolution of pulmonary nodules in the longitudinal dimension of time, and a benign and malignant prediction model of pulmonary lesions in different periods was constructed under multiscale three-dimensional (3D) feature fusion. According to the sequence of computed tomography (CT) images of patients at different stages, 3D interpolation was conducted to generate 3D lung CT images. The 3D features of different size lesions in the lungs were extracted using 3D convolutional neural networks for fusion features. A time-modulated long short-term memory was constructed to predict the benign and malignant lesions by using the improved time-length memory method to learn the feature vectors of lung lesions with temporal and spatial characteristics in different periods. The experiment shows that the area under the curve of the proposed method is 92.71\%, which is higher than that of the traditional method.},
	language = {en},
	journal = {Frontiers in Bioengineering and Biotechnology},
	author = {Liu, Xindong and Wang, Mengnan and Aftab, Rukhma},
	month = mar,
	year = {2022},
	pages = {791424},
	file = {PDF:C\:\\Users\\janto\\Zotero\\storage\\IZSWHZR2\\Liu et al. - 2022 - Study on the Prediction Method of Long-term Benign and Malignant Pulmonary Lesions Based on LSTM.pdf:application/pdf},
}

@article{zhao_pulmonary_2022,
	title = {Pulmonary {Nodule} {Detection} {Based} on {Multiscale} {Feature} {Fusion}},
	volume = {2022},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1748-6718, 1748-670X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1155/2022/8903037},
	doi = {https://doi.org/10.1155/2022/8903037},
	abstract = {As cancer with the highest morbidity and mortality in the world, lung cancer is characterized by pulmonary nodules in the early stage. The detection of pulmonary nodules is an important method for the early detection of lung cancer, which can greatly improve the survival rate of lung cancer patients. However, the accuracy of conventional detection methods for lung nodules is low. With the development of medical imaging technology, deep learning plays an increasingly important role in medical image detection, and pulmonary nodules can be accurately detected by CT images. Based on the above, a pulmonary nodule detection method based on deep learning is proposed. In the candidate nodule detection stage, the multiscale features and Faster R-CNN, a general-purpose detection framework based on deep learning, were combined together to improve the detection of small-sized lung nodules. In the false-positive nodule filtration stage, a 3D convolutional neural network based on multiscale fusion is designed to reduce false-positive nodules. The experiment results show that the candidate nodule detection model based on Faster R-CNN integrating multiscale features has achieved a sensitivity of 98.6\%, 10\% higher than that of the other single-scale model, the proposed method achieved a sensitivity of 90.5\% at the level of 4 false-positive nodules per scan, and the CPM score reached 0.829. The results are higher than methods in other works of literature. It can be seen that the detection method of pulmonary nodules based on multiscale fusion has a higher detection rate for small nodules and improves the classification performance of true and false-positive pulmonary nodules. This will help doctors when making a lung cancer diagnosis.},
	language = {en},
	number = {1},
	journal = {Computational and Mathematical Methods in Medicine},
	author = {Zhao, Yue and Wang, Zhongyang and Liu, Xinyao and Chen, Qi and Li, Chuangang and Zhao, Hongshuo and Wang, Zhiqiong},
	month = dec,
	year = {2022},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1155/2022/8903037},
	pages = {1--13},
	file = {PDF:C\:\\Users\\janto\\Zotero\\storage\\ID7PGKMM\\Zhao et al. - 2022 - Pulmonary Nodule Detection Based on Multiscale Feature Fusion.pdf:application/pdf},
}

@article{gu_survey_2021,
	title = {A survey of computer-aided diagnosis of lung nodules from {CT} scans using deep learning},
	volume = {137},
	issn = {0010-4825},
	url = {https://www.sciencedirect.com/science/article/pii/S0010482521006004},
	doi = {https://doi.org/10.1016/j.compbiomed.2021.104806},
	abstract = {Lung cancer has one of the highest mortalities of all cancers. According to the National Lung Screening Trial, patients who underwent low-dose computed tomography (CT) scanning once a year for 3 years showed a 20\% decline in lung cancer mortality. To further improve the survival rate of lung cancer patients, computer-aided diagnosis (CAD) technology shows great potential. In this paper, we summarize existing CAD approaches applying deep learning to CT scan data for pre-processing, lung segmentation, false positive reduction, lung nodule detection, segmentation, classification and retrieval. Selected papers are drawn from academic journals and conferences up to November 2020. We discuss the development of deep learning, describe several important aspects of lung nodule CAD systems and assess the performance of the selected studies on various datasets, which include LIDC-IDRI, LUNA16, LIDC, DSB2017, NLST, TianChi, and ELCAP. Overall, in the detection studies reviewed, the sensitivity of these techniques is found to range from 61.61\% to 98.10\%, and the value of the FPs per scan is between 0.125 and 32. In the selected classification studies, the accuracy ranges from 75.01\% to 97.58\%. The precision of the selected retrieval studies is between 71.43\% and 87.29\%. Based on performance, deep learning based CAD technologies for detection and classification of pulmonary nodules achieve satisfactory results. However, there are still many challenges and limitations remaining including over-fitting, lack of interpretability and insufficient annotated data. This review helps researchers and radiologists to better understand CAD technology for pulmonary nodule detection, segmentation, classification and retrieval. We summarize the performance of current techniques, consider the challenges, and propose directions for future high-impact research.},
	language = {en},
	journal = {Computers in Biology and Medicine},
	author = {Gu, Yu and Chi, Jingqian and Liu, Jiaqi and Yang, Lidong and Zhang, Baohua and Yu, Dahua and Zhao, Ying and Lu, Xiaoqi},
	month = oct,
	year = {2021},
	keywords = {Computer-aided diagnosis (CAD) technology, CT images, Deep learning, Lung cancer, Lung nodule classification, Lung nodule detection},
	pages = {104806},
	file = {PDF:C\:\\Users\\janto\\Zotero\\storage\\B6AM8JKM\\Gu et al. - 2021 - A survey of computer-aided diagnosis of lung nodules from CT scans using deep learning.pdf:application/pdf},
}

@article{zhao_new_2015,
	title = {A {New} {Method} of {Detecting} {Pulmonary} {Nodules} with {PET}/{CT} {Based} on an {Improved} {Watershed} {Algorithm}},
	volume = {10},
	issn = {1932-6203},
	url = {https://doi.org/10.1371/journal.pone.0123694},
	doi = {10.1371/journal.pone.0123694},
	abstract = {Background Integrated 18F-fluorodeoxyglucose positron emission tomography/computed tomography (18F-FDG PET/CT) is widely performed for staging solitary pulmonary nodules (SPNs). However, the diagnostic efficacy of SPNs based on PET/CT is not optimal. Here, we propose a method of detection based on PET/CT that can differentiate malignant and benign SPNs with few false-positives. Method Our proposed method combines the features of positron-emission tomography (PET) and computed tomography (CT). A dynamic threshold segmentation method was used to identify lung parenchyma in CT images and suspicious areas in PET images. Then, an improved watershed method was used to mark suspicious areas on the CT image. Next, the support vector machine (SVM) method was used to classify SPNs based on textural features of CT images and metabolic features of PET images to validate the proposed method. Results Our proposed method was more efficient than traditional methods and methods based on the CT or PET features alone (sensitivity 95.6\%; average of 2.9 false positives per scan).},
	language = {en},
	number = {4},
	journal = {PLOS ONE},
	author = {Zhao, Juanjuan and Ji, Guohua and Qiang, Yan and Han, Xiaohong and Pei, Bo and Shi, Zhenghao},
	month = apr,
	year = {2015},
	note = {Publisher: Public Library of Science},
	pages = {1--15},
	file = {PDF:C\:\\Users\\janto\\Zotero\\storage\\3XVDC7MJ\\Zhao et al. - 2015 - A New Method of Detecting Pulmonary Nodules with PETCT Based on an Improved Watershed Algorithm.pdf:application/pdf},
}

@article{mahmoud_chest_2022,
	title = {Chest {Radiographs} {Images} {Retrieval} {Using} {Deep} {Learning} {Networks}},
	volume = {11},
	copyright = {https://creativecommons.org/licenses/by-sa/4.0},
	issn = {2302-9285, 2089-3191},
	url = {https://beei.org/index.php/EEI/article/view/3478},
	doi = {10.11591/eei.v11i3.3478},
	language = {en},
	number = {3},
	journal = {Bulletin of Electrical Engineering and Informatics},
	author = {Mahmoud, Sawsan and Al-Jubouri, Hanan and Abdulabbas, Tawfeeq},
	month = jun,
	year = {2022},
	pages = {1358--1369},
	file = {PDF:C\:\\Users\\janto\\Zotero\\storage\\7VLVJDVP\\Mahmoud et al. - 2022 - Chest Radiographs Images Retrieval Using Deep Learning Networks.pdf:application/pdf},
}

@article{bahmer_benefits_2011,
	title = {Benefits and {Harms} of {CT} {Screening} for {Lung} {Cancer}: {A} {Systematic} {Review}},
	volume = {307},
	url = {https://jamanetwork.com/journals/jama/article-abstract/1163892},
	doi = {10.1001/jama.2012.5521},
	number = {22},
	journal = {JAMA},
	author = {Bahmer, Kirsten M. and Schoenfeld, Andrew J. and Aberle, Denise R.},
	year = {2011},
	pages = {2418--2429},
}

@inproceedings{munoz_3d-morphomics_2022,
	address = {Cham},
	title = {{3D}-{Morphomics}, {Morphological} {Features} on {CT} {Scans} for {Lung} {Nodule} {Malignancy} {Diagnosis}},
	isbn = {978-3-031-17979-2},
	url = {http://arxiv.org/abs/2207.13830},
	doi = {10.48550/arXiv.2207.13830},
	abstract = {Pathologies systematically induce morphological changes, thus providing a major but yet insufficiently quantified source of observables for diagnosis. The study develops a predictive model of the pathological states based on morphological features (3D-morphomics) on Computed Tomography (CT) volumes. A complete workflow for mesh extraction and simplification of an organ's surface is developed, and coupled with an automatic extraction of morphological features given by the distribution of mean curvature and mesh energy. An XGBoost supervised classifier is then trained and tested on the 3D-morphomics to predict the pathological states. This framework is applied to the prediction of the malignancy of lung's nodules. On a subset of NLST database with malignancy confirmed biopsy, using 3D-morphomics only, the classification model of lung nodules into malignant vs. benign achieves 0.964 of AUC. Three other sets of classical features are trained and tested, (1) clinical relevant features gives an AUC of 0.58, (2) 111 radiomics gives an AUC of 0.976, (3) radiologist ground truth (GT) containing the nodule size, attenuation and spiculation qualitative annotations gives an AUC of 0.979. We also test the Brock model and obtain an AUC of 0.826. Combining 3D-morphomics and radiomics features achieves state-of-the-art results with an AUC of 0.978 where the 3D-morphomics have some of the highest predictive powers. As a validation on a public independent cohort, models are applied to the LIDC dataset, the 3D-morphomics achieves an AUC of 0.906 and the 3D-morphomics+radiomics achieves an AUC of 0.958, which ranks second in the challenge among deep models. It establishes the curvature distributions as efficient features for predicting lung nodule malignancy and a new method that can be applied directly to arbitrary computer aided diagnosis task.},
	language = {en},
	booktitle = {Cancer {Prevention} {Through} {Early} {Detection}},
	publisher = {Springer Nature Switzerland},
	author = {Munoz, Elias and Baudot, Pierre and Le, Van-Khoa and Voyton, Charles and Renoust, Benjamin and Francis, Danny and Groza, Vladimir and Brisset, Jean-Christophe and Geremia, Ezequiel and Iannessi, Antoine and Liu, Yan and Huet, Benoit},
	editor = {Ali, Sharib and van der Sommen, Fons and Papie{\textbackslash}.z, Bartłomiej Władysław and van Eijnatten, Maureen and Jin, Yueming and Kolenbrander, Iris},
	year = {2022},
	note = {Section: 0},
	keywords = {Computational anatomy, Computed tomography, Computer aided diagnosis, Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing, Lung cancer screening, Mesh, Quantitative Biology - Quantitative Methods, Radiomics},
	pages = {3--13},
	file = {Full Text PDF:C\:\\Users\\janto\\Zotero\\storage\\BLW6G4UQ\\Munoz et al. - 2022 - 3D-Morphomics, Morphological Features on CT Scans for Lung Nodule Malignancy Diagnosis.pdf:application/pdf;PDF:C\:\\Users\\janto\\Zotero\\storage\\8I78SZ5W\\Munoz et al. - 2022 - 3D-Morphomics, Morphological Features on CT scans for lung nodule malignancy diagnosis.pdf:application/pdf;Snapshot:C\:\\Users\\janto\\Zotero\\storage\\JU5LPQ25\\2207.html:text/html},
}

@article{farag_feature_2017,
	title = {Feature fusion for lung nodule classification},
	volume = {12},
	issn = {1861-6410, 1861-6429},
	url = {http://link.springer.com/10.1007/s11548-017-1626-1},
	doi = {10.1007/s11548-017-1626-1},
	abstract = {PURPOSE: This article examines feature-based nodule description for the purpose of nodule classification in chest computed tomography scanning. METHODS: Three features based on (i) Gabor filter, (ii) multi-resolution local binary pattern (LBP) texture features and (iii) signed distance fused with LBP which generates a combinational shape and texture feature are utilized to provide feature descriptors of malignant and benign nodules and non-nodule regions of interest. Support vector machines (SVMs) and k-nearest neighbor (kNN) classifiers in serial and two-tier cascade frameworks are optimized and analyzed for optimal classification results of nodules. RESULTS: A total of 1191 nodule and non-nodule samples from the Lung Image Data Consortium database is used for analysis. Classification using SVM and kNN classifiers is examined. The classification results from the two-tier cascade SVM using Gabor features showed overall better results for identifying non-nodules, malignant and benign nodules with average area under the receiver operating characteristics (AUC-ROC) curves of 0.99 and average f1-score of 0.975 over the two tiers. CONCLUSION: In the results, higher overall AUCs and f1-scores were obtained for the non-nodules cases using any of the three features, showing the greatest distinguishability over nodules (benign/malignant). SVM and kNN classifiers were used for benign, malignant and non-nodule classification, where Gabor proved to be the most effective of the features for classification. The cascaded framework showed the greatest distinguishability between benign and malignant nodules.},
	language = {en},
	number = {10},
	journal = {Int J Comput Assist Radiol Surg},
	author = {Farag, Amal A and Ali, Asem and Elshazly, Salwa and Farag, Aly A},
	month = oct,
	year = {2017},
	note = {Place: Germany},
	keywords = {Classification, Computed tomography, Features extraction, Gabor, LBP, Lung nodules},
	pages = {1809--1818},
	file = {PDF:C\:\\Users\\janto\\Zotero\\storage\\EVGI4784\\Farag et al. - 2017 - Feature fusion for lung nodule classification.pdf:application/pdf},
}

@article{iqbal_fusion_2023,
	title = {Fusion of {Textural} and {Visual} {Information} for {Medical} {Image} {Modality} {Retrieval} {Using} {Deep} {Learning}-{Based} {Feature} {Engineering}},
	volume = {11},
	copyright = {https://creativecommons.org/licenses/by-nc-nd/4.0/},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/10234403/},
	doi = {10.1109/ACCESS.2023.3310245},
	language = {en},
	journal = {IEEE Access},
	author = {Iqbal, Saeed and Qureshi, Adnan N. and Alhussein, Musaed and Choudhry, Imran Arshad and Aurangzeb, Khursheed and Khan, Tariq M.},
	year = {2023},
	keywords = {Biomedical imaging, convolutional neural network, Convolutional neural networks, Databases, deep learning, Deep learning, feature engineering, Feature extraction, Image retrieval, Medical diagnostic imaging, Medical image retrieval, Medical services, modality retrieval, textural information, visual information, Visualization},
	pages = {93238--93253},
	file = {PDF:C\:\\Users\\janto\\Zotero\\storage\\U2YYXV7C\\Iqbal et al. - 2023 - Fusion of Textural and Visual Information for Medical Image Modality Retrieval Using Deep Learning-B.pdf:application/pdf},
}

@inproceedings{shaffie_novel_2021,
	address = {Nice, France},
	title = {A {Novel} {Framework} for {Accurate} and {Non}-{Invasive} {Pulmonary} {Nodule} {Diagnosis} by {Integrating} {Texture} and {Contour} {Descriptors}},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	isbn = {978-1-6654-1246-9},
	url = {https://ieeexplore.ieee.org/document/9433830/},
	doi = {10.1109/ISBI48211.2021.9433830},
	language = {en},
	booktitle = {2021 {IEEE} 18th {International} {Symposium} on {Biomedical} {Imaging} ({ISBI})},
	publisher = {IEEE},
	author = {Shaffie, Ahmed and Soliman, Ahmed and Khalifeh, Hadil Abu and Ghazal, Mohammed and Taher, Fatma and Elmaghraby, Adel and El-Baz, Ayman},
	month = apr,
	year = {2021},
	note = {Section: 0},
	keywords = {CAD, Computed tomography, Computer Tomography, Lung, Lung cancer, M..., Markov Gibbs Random Field, Sensitivity and specificity, Shape, Solid modeling, Tools, Various-views MACSS},
	pages = {1883--1886},
	file = {PDF:C\:\\Users\\janto\\Zotero\\storage\\UE3RT22Z\\Shaffie et al. - 2021 - A Novel Framework for Accurate and Non-Invasive Pulmonary Nodule Diagnosis by Integrating Texture an.pdf:application/pdf},
}

@misc{mathumetha_feature_2024,
	title = {Feature {Extraction} {Methods} and {Deep} {Learning} {Models} for {Detection} of {Cancerous} {Lung} {Nodules} at an {Early} {Stage} – {Recent} {Trends} and {Challenges}},
	doi = {10.2139/ssrn.4756114},
	language = {en},
	publisher = {SSRN},
	author = {Mathumetha, P. and Sivakumar, R. and Chintanpalli, Ananthakrishna},
	year = {2024},
	note = {Place: Vellore, India
Publisher: Vellore Institute of Technology},
	file = {PDF:C\:\\Users\\janto\\Zotero\\storage\\X53MGWNK\\Mathumetha et al. - 2024 - Feature Extraction Methods and Deep Learning Models for Detection of Cancerous Lung Nodules at an Ea.pdf:application/pdf},
}

@article{alksas_novel_2023,
	title = {A novel higher order appearance texture analysis to diagnose lung cancer based on a modified local ternary pattern},
	volume = {240},
	issn = {0169-2607},
	url = {https://www.sciencedirect.com/science/article/pii/S0169260723003577},
	doi = {https://doi.org/10.1016/j.cmpb.2023.107692},
	abstract = {Background and Objective Lung cancer is an important cause of death and morbidity around the world. Two of the primary computed tomography (CT) imaging markers that can be used to differentiate malignant and benign lung nodules are the inhomogeneity of the nodules’ texture and nodular morphology. The objective of this paper is to present a new model that can capture the inhomogeneity of the detected lung nodules as well as their morphology. Methods We modified the local ternary pattern to use three different levels (instead of two) and a new pattern identification algorithm to capture the nodule’s inhomogeneity and morphology in a more accurate and flexible way. This modification aims to address the wide Hounsfield unit value range of the detected nodules which decreases the ability of the traditional local binary/ternary pattern to accurately classify nodules’ inhomogeneity. The cut-off values defining these three levels of the novel technique are estimated empirically from the training data. Subsequently, the extracted imaging markers are fed to a hyper-tuned stacked generalization-based classification architecture to classify the nodules as malignant or benign. The proposed system was evaluated on in vivo datasets of 679 CT scans (364 malignant nodules and 315 benign nodules) from the benchmark Lung Image Database Consortium and Image Database Resource Initiative (LIDC-IDRI) and an external dataset of 100 CT scans (50 malignant and 50 benign). The performance of the classifier was quantitatively assessed using a Leave-one-out cross-validation approach and externally validated using the unseen external dataset based on sensitivity, specificity, and accuracy. Results The overall accuracy of the system is 96.17\% with 97.14\% sensitivity and 95.33\% specificity. The area under the receiver-operating characteristic curve was 0.98, which highlights the robustness of the system. Using the unseen external dataset for validating the system led to consistent results showing the generalization abilities of the proposed approach. Moreover, applying the original local binary/ternary pattern or using other classification structures achieved inferior performance when compared against the proposed approach. Conclusions These experimental results demonstrate the feasibility of the proposed model as a novel tool to assist physicians and radiologists for lung nodules’ early assessment based on the new comprehensive imaging markers.},
	language = {en},
	journal = {Computer Methods and Programs in Biomedicine},
	author = {Alksas, Ahmed and Shaffie, Ahmed and Ghazal, Mohammed and Taher, Fatma and Khelifi, Adel and Yaghi, Maha and Soliman, Ahmed and Bogaert, Eric VAN and El-Baz, Ayman},
	month = oct,
	year = {2023},
	keywords = {CT, Higher order appearance, LBP, Lung cancer, Modified local ternary pattern, Stacked generalization classification, Texture analysis},
	pages = {107692},
	file = {Alksas2023:C\:\\Users\\janto\\Zotero\\storage\\BLS5SFIF\\Alksas2023.pdf:application/pdf},
}

@article{xie_fusing_2018,
	title = {Fusing texture, shape and deep model-learned information at decision level for automated classification of lung nodules on chest {CT}},
	volume = {42},
	issn = {1566-2535},
	url = {https://www.sciencedirect.com/science/article/pii/S1566253516301063},
	doi = {https://doi.org/10.1016/j.inffus.2017.10.005},
	abstract = {The separation of malignant from benign lung nodules on chest computed tomography (CT) is important for the early detection of lung cancer, since early detection and management offer the best chance for cure. Although deep learning methods have recently produced a marked improvement in image classification there are still challenges as these methods contain myriad parameters and require large-scale training sets that are not usually available for most routine medical imaging studies. In this paper, we propose an algorithm for lung nodule classification that fuses the texture, shape and deep model-learned information (Fuse-TSD) at the decision level. This algorithm employs a gray level co-occurrence matrix (GLCM)-based texture descriptor, a Fourier shape descriptor to characterize the heterogeneity of nodules and a deep convolutional neural network (DCNN) to automatically learn the feature representation of nodules on a slice-by-slice basis. It trains an AdaBoosted back propagation neural network (BPNN) using each feature type and fuses the decisions made by three classifiers to differentiate nodules. We evaluated this algorithm against three approaches on the LIDC-IDRI dataset. When the nodules with a composite malignancy rate 3 were discarded, regarded as benign or regarded as malignant, our Fuse-TSD algorithm achieved an AUC of 96.65\%, 94.45\% and 81.24\%, respectively, which was substantially higher than the AUC obtained by other approaches.},
	language = {en},
	journal = {Information Fusion},
	author = {Xie, Yutong and Zhang, Jianpeng and Xia, Yong and Fulham, Michael and Zhang, Yanning},
	month = jul,
	year = {2018},
	keywords = {AdaBoost, Back propagation neural network (BPNN), Chest CT, Deep convolutional neural network (DCNN), information fusion, Lung nodule classification},
	pages = {102--110},
	file = {PDF:C\:\\Users\\janto\\Zotero\\storage\\TDHILT5X\\Xie et al. - 2018 - Fusing texture, shape and deep model-learned information at decision level for automated classificat.pdf:application/pdf},
}

@misc{setio_luna16_2016,
	title = {{LUNA16}: {A} {Challenge} for {Automatic} {Nodule} {Detection} in {Low}-{Dose} {CT} {Scans}},
	url = {https://luna16.grand-challenge.org/},
	author = {Setio, Arnaud Arindra Adiyoso and Traverso, Andrea and de Bel, Tom and Berens, Maria S. and van den Bogaard, Casper and Cerello, Piergiorgio and Chen, Huanjun and Dou, Qi and Fantacci, Maria Enrica and Geurts, Bart and van der Gugten, Rogier and Jacobs, Colin and Jirapatnakul, Aruch and Litjens, Geert and Maldonado, Sergio Gomez and Mucherino, Sacha and Pedersen, Jesper Hjorth and Penzkofer, Tobias and Scholten, Eduard T. and Stieren, Michelle and Tan, Freek and Walsh, Sean and Wei, Xiaochen and van Ginneken, Bram and van Klaveren, René and van der Laak, Jeroen and Schaefer-Prokop, Cornelia and Prokop, Mathias and Meijer, Fred and Ardila, David and Farre, Xavier Ribo and Ypsilantis, Panagiotis P. and Montuenga, Luis M. and Sánchez-Salcedo, Alejandro and Nogueira, Jose Garcia and Pu, Jian and Niemeijer, Meindert},
	year = {2016},
}

@article{li_comparison_2022,
	title = {Comparison of {Traditional} {Radiomics}, {Deep} {Learning} {Radiomics} and {Fusion} {Methods} for {Axillary} {Lymph} {Node} {Metastasis} {Prediction} in {Breast} {Cancer}},
	volume = {30},
	abstract = {RATIONALE AND OBJECTIVES: Accurate identification of axillary lymph node (ALN) status in breast cancer patients is important for determining treatment options and avoiding axillary overtreatments. Our study aims to comprehensively compare the performance of the traditional radiomics model, deep learning radiomics model, and the fusion models in evaluating breast cancer ALN status based on dynamic contrast-enhanced-magnetic resonance imaging (DCE-MRI) images. MATERIALS AND METHODS: The handcrafted radiomics features and deep features were extracted from 3062 DCE-MRI images. The feature selection was performed by applying mutual information and feature recursive elimination algorithms. The traditional radiomics model and deep learning radiomics model were built using the optimal features and machine learning classifiers, respectively. The fusion models for distinguishing axillary lymph node status were constructed using two fusion strategies. The performance of the models with MRI-reported lymphadenopathy or suspicious nodes to evaluate axillary lymph node status was also compared. RESULTS: The decision fusion model, with the integration of the radiomics features and deep learning features at the decision level, achieved an area under the curve (AUC) of 0.91 (95\% confidence interval (CI): 0.879-0.937), which was higher than that of the traditional radiomics model and deep learning radiomics model. The results of the decision fusion model with clinical characteristic yielded an AUC of 0.93 (95\% CI: 0.899-0.951), which was also superior to other models incorporating clinical characteristic. CONCLUSION: This study demonstrates the effectiveness of the fusion models for predicting axillary lymph node metastasis in breast cancer.},
	language = {en},
	number = {7},
	journal = {Acad Radiol},
	author = {Li, Xue and Yang, Lifeng and Jiao, Xiong},
	month = nov,
	year = {2022},
	note = {Place: United States},
	keywords = {Axillary lymph node metastasis, Breast cancer, Information fusion, Radiomics},
	pages = {1281--1287},
}

@article{kirby_lungx_2016,
	title = {{LUNGx} {Challenge} for computerized lung nodule classification},
	volume = {3},
	url = {https://doi.org/10.1117/1.JMI.3.4.044506},
	doi = {10.1117/1.JMI.3.4.044506},
	abstract = {The purpose of this work is to describe the LUNGx Challenge for the computerized classification of lung nodules on diagnostic computed tomography (CT) scans as benign or malignant and report the performance of participants’ computerized methods along with that of six radiologists who participated in an observer study performing the same Challenge task on the same dataset. The Challenge provided sets of calibration and testing scans, established a performance assessment process, and created an infrastructure for case dissemination and result submission. Ten groups applied their own methods to 73 lung nodules (37 benign and 36 malignant) that were selected to achieve approximate size matching between the two cohorts. Area under the receiver operating characteristic curve (AUC) values for these methods ranged from 0.50 to 0.68; only three methods performed statistically better than random guessing. The radiologists’ AUC values ranged from 0.70 to 0.85; three radiologists performed statistically better than the best-performing computer method. The LUNGx Challenge compared the performance of computerized methods in the task of differentiating benign from malignant lung nodules on CT scans, placed in the context of the performance of radiologists on the same task. The continued public availability of the Challenge cases will provide a valuable resource for the medical imaging research community.},
	number = {4},
	journal = {Journal of Medical Imaging},
	author = {Kirby, Justin S. and Armato, Samuel G. and Drukker, Karen and Li, Feng and Hadjiiski, Lubomir and Tourassi, Georgia D. and Clarke, Laurence P. and Engelmann, Roger M. and Giger, Maryellen L. and Redmond, George and Farahani, Keyvan},
	year = {2016},
	note = {Publisher: SPIE},
	keywords = {Algorithm development, Calibration, Cancer, challenge, classification, computed tomography, Computed tomography, Computer aided design, Computer aided diagnosis and therapy, computer-aided diagnosis, Diagnostics, image analysis, Lung, lung nodule, Medical imaging, Medical research},
	pages = {044506},
}

@article{zhao_combining_2020,
	title = {Combining multi-scale feature fusion with multi-attribute grading, a {CNN} model for benign and malignant classification of pulmonary nodules},
	volume = {33},
	issn = {1618-727X},
	url = {https://doi.org/10.1007/s10278-020-00333-1},
	doi = {10.1007/s10278-020-00333-1},
	abstract = {Lung cancer has the highest mortality rate of all cancers, and early detection can improve survival rates. In the recent years, low-dose CT has been widely used to detect lung cancer. However, the diagnosis is limited by the subjective experience of doctors. Therefore, the main purpose of this study is to use convolutional neural network to realize the benign and malignant classification of pulmonary nodules in CT images. We collected 1004 cases of pulmonary nodules from LIDC-IDRI dataset, among which 554 cases were benign and 450 cases were malignant. According to the doctors' annotates on the center coordinates of the nodules, two 3D CT image patches of pulmonary nodules with different scales were extracted. In this study, our work focuses on two aspects. Firstly, we constructed a multi-stream multi-task network (MSMT), which combined multi-scale feature with multi-attribute classification for the first time, and applied it to the classification of benign and malignant pulmonary nodules. Secondly, we proposed a new loss function to balance the relationship between different attributes. The final experimental results showed that our model was effective compared with the same type of study. The area under ROC curve, accuracy, sensitivity, and specificity were 0.979, 93.92\%, 92.60\%, and 96.25\%, respectively.},
	number = {4},
	journal = {Journal of Digital Imaging},
	author = {Zhao, Jumin and Zhang, Chen and Li, Dengao and Niu, Jing},
	month = aug,
	year = {2020},
	pages = {869--878},
}

@article{naqi_multistage_2018,
	title = {Multistage segmentation model and {SVM}-ensemble for precise lung nodule detection},
	volume = {13},
	issn = {1861-6429},
	url = {https://doi.org/10.1007/s11548-018-1715-9},
	doi = {10.1007/s11548-018-1715-9},
	abstract = {Lung cancer detection at its initial stages increases the survival chances of patients. Automatic detection of lung nodules facilitates radiologists during the diagnosis. However, there is a challenge of false positives in automated systems which may lead to wrong findings. Precise segmentation facilitates to accurately extract nodules from lung CT images in order to improve performance of the diagnostic method.},
	number = {7},
	journal = {International Journal of Computer Assisted Radiology and Surgery},
	author = {Naqi, Syed Muhammad and Sharif, Muhammad and Yasmin, Mussarat},
	month = jul,
	year = {2018},
	pages = {1083--1095},
}

@article{ma_novel_2023,
	title = {A novel fusion algorithm for benign-malignant lung nodule classification on {CT} images},
	volume = {23},
	issn = {1471-2466},
	url = {https://doi.org/10.1186/s12890-023-02708-w},
	doi = {10.1186/s12890-023-02708-w},
	abstract = {The accurate recognition of malignant lung nodules on CT images is critical in lung cancer screening, which can offer patients the best chance of cure and significant reductions in mortality from lung cancer. Convolutional Neural Network (CNN) has been proven as a powerful method in medical image analysis. Radiomics which is believed to be of interest based on expert opinion can describe high-throughput extraction from CT images. Graph Convolutional Network explores the global context and makes the inference on both graph node features and relational structures. In this paper, we propose a novel fusion algorithm, RGD, for benign-malignant lung nodule classification by incorporating Radiomics study and Graph learning into the multiple Deep CNNs to form a more complete and distinctive feature representation, and ensemble the predictions for robust decision-making. The proposed method was conducted on the publicly available LIDC-IDRI dataset in a 10-fold cross-validation experiment and it obtained an average accuracy of 93.25\%, a sensitivity of 89.22\%, a specificity of 95.82\%, precision of 92.46\%, F1 Score of 0.9114 and AUC of 0.9629. Experimental results illustrate that the RGD model achieves superior performance compared with the state-of-the-art methods. Moreover, the effectiveness of the fusion strategy has been confirmed by extensive ablation studies. In the future, the proposed model which performs well on the pulmonary nodule classification on CT images will be applied to increase confidence in the clinical diagnosis of lung cancer.},
	number = {1},
	journal = {BMC Pulmonary Medicine},
	author = {Ma, Ling and Wan, Chuangye and Hao, Kexin and Cai, Annan and Liu, Lizhi},
	month = nov,
	year = {2023},
	pages = {474},
	file = {PDF:C\:\\Users\\janto\\Zotero\\storage\\49NJLSJS\\Ma et al. - 2023 - A novel fusion algorithm for benign-malignant lung nodule classification on CT images.pdf:application/pdf},
}

@article{wu_ai-enhanced_2024,
	title = {{AI}-{Enhanced} {CAD} in {Low}-{Dose} {CT}: {Balancing} {Accuracy}, {Efficiency}, and {Overdiagnosis} in {Lung} {Cancer} {Screening}},
	volume = {16},
	issn = {1759-7714 (Electronic)},
	url = {https://pubmed.ncbi.nlm.nih.gov/39600243/},
	doi = {10.1111/1759-7714.15499},
	language = {en},
	number = {1},
	journal = {Thoracic Cancer},
	author = {Wu, Yun-Ju and Wu, Fu-Zong},
	month = nov,
	year = {2024},
	note = {Place: Singapore
Publisher: Department of Radiology, Kaohsiung Veterans General Hospital, Kaohsiung, Taiwan.; Department of Software Engineering and Management, National Kaohsiung Normal University, Kaohsiung, Taiwan.; Department of Radiology, Kaohsiung Veterans General Hospital, Kaohsiung, Taiwan.},
	pages = {e15499},
	file = {PDF:C\:\\Users\\janto\\Zotero\\storage\\FLSPL5HY\\Wu e Wu - 2025 - AI ‐Enhanced CA.pdf:application/pdf},
}

@inproceedings{liu_classification_2023,
	title = {Classification of {Benign} and {Malignant} {Pulmonary} {Nodules} {Based} on {Mixed} {Features}},
	doi = {10.23919/CCC58697.2023.10240557},
	abstract = {Lung cancer is a pervasive malignancy that remains the leading cause of cancer-related mortality worldwide[1]. Accurate diagnosis of benign and malignant lung nodules is crucial for the prevention and treatment of lung cancer. However, traditional methods of manually designed features face challenges in extracting and analyzing deep-level features using mathematical models. Meanwhile, methods using convolutional neural networks can extract deep-level features, but lack interpretability and are not as effective as manually designed feature methods for shallow visual features. To address these challenges, we propose a lung nodule classification method that combines shallow visual and deep learning features. We construct shallow visual and deep learning networks to extract and classify shallow visual features and deep learning features, respectively. Finally, we use a multi-model fusion strategy to achieve benign and malignant classification of lung nodules. In particular, we employ a neural network architecture search to build a deep learning network with better interpretability and performance. We conducted extensive experiments on the LIDC-IDRI dataset and compared our method with the state-of-the-art research. Our results show that our method outperforms existing methods with an accuracy and F1 score of 91.21\% and 91.04, respectively. demonstrating the effectiveness and superiority of our algorithm.},
	booktitle = {2023 42nd {Chinese} {Control} {Conference} ({CCC})},
	author = {Liu, Shaojun and Wang, Shujing and Wang, Qixiang and Luo, Junhua},
	month = jul,
	year = {2023},
	note = {ISSN: 1934-1768},
	keywords = {benign and malignant classification, Deep learning, Feature extraction, Lung, Lung cancer, Mathematical models, mixed features, Neural networks, Pulmonary nodules, Visualization},
	pages = {8803--8808},
}
